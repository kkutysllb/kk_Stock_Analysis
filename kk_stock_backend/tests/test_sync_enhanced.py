#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“åŒæ­¥åŠŸèƒ½æµ‹è¯•è„šæœ¬ - å¢å¼ºç‰ˆ
æµ‹è¯•ä¿®å¤åçš„å¢é‡åŒæ­¥ã€å…¨é‡åŒæ­¥ã€å¹¶å‘å®‰å…¨ç­‰åŠŸèƒ½

è¿è¡Œæ–¹å¼ï¼š
python test_sync_enhanced.py [test_type]

test_typeå¯é€‰å€¼ï¼š
- all: è¿è¡Œæ‰€æœ‰æµ‹è¯•
- incremental: åªæµ‹è¯•å¢é‡åŒæ­¥
- full: åªæµ‹è¯•å…¨é‡åŒæ­¥
- concurrent: åªæµ‹è¯•å¹¶å‘å®‰å…¨
- performance: åªæµ‹è¯•æ€§èƒ½
"""

import os
import sys
import time
import random
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
import threading

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

from database_manager import DatabaseManager
from data_collector_new.db_handler import DBHandler

class SyncTester:
    def __init__(self):
        self.db_manager = DatabaseManager()
        self.db_handler = DBHandler()
        self.test_collection = 'test_sync_collection'
        self.test_results = []
        
    def setup_test_data(self, count=1000):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        print(f"ğŸ”§ è®¾ç½®æµ‹è¯•æ•°æ® ({count:,} æ¡è®°å½•)...")
        
        # æ¸…ç†æµ‹è¯•é›†åˆ
        self._cleanup_test_collections()
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_data = []
        base_date = datetime(2024, 1, 1)
        
        for i in range(count):
            doc = {
                'ts_code': f'00000{i % 100:02d}.SZ',
                'trade_date': (base_date + timedelta(days=i % 365)).strftime('%Y%m%d'),
                'open': round(random.uniform(10, 100), 2),
                'high': round(random.uniform(10, 100), 2),
                'low': round(random.uniform(10, 100), 2),
                'close': round(random.uniform(10, 100), 2),
                'vol': random.randint(1000, 1000000),
                'amount': round(random.uniform(1000000, 100000000), 2),
                'created_at': datetime.utcnow(),
                'seq_id': i
            }
            test_data.append(doc)
        
        # æ’å…¥åˆ°äº‘ç«¯æ•°æ®åº“
        if self.db_manager.cloud_available:
            cloud_collection = self.db_handler.get_cloud_collection(self.test_collection)
            cloud_collection.insert_many(test_data)
            print(f"   â˜ï¸  äº‘ç«¯æ’å…¥å®Œæˆ: {count:,} æ¡")
        
        # æ’å…¥éƒ¨åˆ†æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“ï¼ˆæ¨¡æ‹Ÿä¸åŒæ­¥çŠ¶æ€ï¼‰
        if self.db_manager.local_available:
            local_collection = self.db_handler.get_local_collection(self.test_collection)
            partial_data = test_data[:count//2]  # åªæ’å…¥ä¸€åŠæ•°æ®
            local_collection.insert_many(partial_data)
            print(f"   ğŸ  æœ¬åœ°æ’å…¥å®Œæˆ: {len(partial_data):,} æ¡")
        
        return True
    
    def test_incremental_sync(self):
        """æµ‹è¯•å¢é‡åŒæ­¥åŠŸèƒ½"""
        print("\nğŸ“ˆ æµ‹è¯•å¢é‡åŒæ­¥åŠŸèƒ½...")
        
        try:
            # æ‰§è¡Œå¢é‡åŒæ­¥
            start_time = time.time()
            result = self.db_manager.sync_data_incremental(
                direction='cloud-to-local',
                collection_name=self.test_collection,
                confirm=True
            )
            end_time = time.time()
            
            success = result and self._verify_sync_result()
            
            self.test_results.append({
                'test': 'incremental_sync',
                'success': success,
                'duration': end_time - start_time,
                'details': f"å¢é‡åŒæ­¥{'æˆåŠŸ' if success else 'å¤±è´¥'}"
            })
            
            print(f"   {'âœ…' if success else 'âŒ'} å¢é‡åŒæ­¥æµ‹è¯•: {'é€šè¿‡' if success else 'å¤±è´¥'}")
            print(f"   â±ï¸  è€—æ—¶: {end_time - start_time:.2f} ç§’")
            
            return success
            
        except Exception as e:
            print(f"   âŒ å¢é‡åŒæ­¥æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_full_sync(self):
        """æµ‹è¯•å…¨é‡åŒæ­¥åŠŸèƒ½"""
        print("\nğŸ”„ æµ‹è¯•å…¨é‡åŒæ­¥åŠŸèƒ½...")
        
        try:
            # æ¸…ç©ºæœ¬åœ°é›†åˆ
            if self.db_manager.local_available:
                local_collection = self.db_handler.get_local_collection(self.test_collection)
                local_collection.drop()
            
            # æ‰§è¡Œå…¨é‡åŒæ­¥
            start_time = time.time()
            result = self.db_manager.sync_data(
                direction='cloud-to-local',
                collection_name=self.test_collection,
                confirm=True
            )
            end_time = time.time()
            
            success = result and self._verify_sync_result()
            
            self.test_results.append({
                'test': 'full_sync',
                'success': success,
                'duration': end_time - start_time,
                'details': f"å…¨é‡åŒæ­¥{'æˆåŠŸ' if success else 'å¤±è´¥'}"
            })
            
            print(f"   {'âœ…' if success else 'âŒ'} å…¨é‡åŒæ­¥æµ‹è¯•: {'é€šè¿‡' if success else 'å¤±è´¥'}")
            print(f"   â±ï¸  è€—æ—¶: {end_time - start_time:.2f} ç§’")
            
            return success
            
        except Exception as e:
            print(f"   âŒ å…¨é‡åŒæ­¥æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_concurrent_sync(self):
        """æµ‹è¯•å¹¶å‘åŒæ­¥å®‰å…¨æ€§"""
        print("\nâš¡ æµ‹è¯•å¹¶å‘åŒæ­¥å®‰å…¨æ€§...")
        
        try:
            # åˆ›å»ºå¤šä¸ªæµ‹è¯•é›†åˆ
            test_collections = [f'{self.test_collection}_{i}' for i in range(3)]
            
            # ä¸ºæ¯ä¸ªé›†åˆå‡†å¤‡æµ‹è¯•æ•°æ®
            for coll_name in test_collections:
                self._prepare_collection_data(coll_name, 500)
            
            # å¹¶å‘æ‰§è¡ŒåŒæ­¥
            start_time = time.time()
            success_count = 0
            
            def sync_collection(coll_name):
                try:
                    return self.db_manager.sync_data_incremental(
                        direction='cloud-to-local',
                        collection_name=coll_name,
                        confirm=True
                    )
                except Exception as e:
                    print(f"   âš ï¸  å¹¶å‘åŒæ­¥å¤±è´¥ {coll_name}: {e}")
                    return False
            
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = [executor.submit(sync_collection, coll) for coll in test_collections]
                results = [future.result() for future in futures]
                success_count = sum(results)
            
            end_time = time.time()
            
            success = success_count == len(test_collections)
            
            self.test_results.append({
                'test': 'concurrent_sync',
                'success': success,
                'duration': end_time - start_time,
                'details': f"å¹¶å‘åŒæ­¥ {success_count}/{len(test_collections)} æˆåŠŸ"
            })
            
            print(f"   {'âœ…' if success else 'âŒ'} å¹¶å‘åŒæ­¥æµ‹è¯•: {'é€šè¿‡' if success else 'å¤±è´¥'}")
            print(f"   ğŸ“Š æˆåŠŸç‡: {success_count}/{len(test_collections)}")
            print(f"   â±ï¸  è€—æ—¶: {end_time - start_time:.2f} ç§’")
            
            # æ¸…ç†æµ‹è¯•é›†åˆ
            for coll_name in test_collections:
                self._cleanup_collection(coll_name)
            
            return success
            
        except Exception as e:
            print(f"   âŒ å¹¶å‘åŒæ­¥æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_performance(self):
        """æµ‹è¯•åŒæ­¥æ€§èƒ½"""
        print("\nğŸš€ æµ‹è¯•åŒæ­¥æ€§èƒ½...")
        
        try:
            # æµ‹è¯•ä¸åŒæ•°æ®é‡çš„åŒæ­¥æ€§èƒ½
            test_sizes = [100, 1000, 5000]
            performance_results = []
            
            for size in test_sizes:
                print(f"   ğŸ“Š æµ‹è¯•æ•°æ®é‡: {size:,} æ¡")
                
                # è®¾ç½®æµ‹è¯•æ•°æ®
                self.setup_test_data(size)
                
                # æµ‹è¯•å¢é‡åŒæ­¥æ€§èƒ½
                start_time = time.time()
                result = self.db_manager.sync_data_incremental(
                    direction='cloud-to-local',
                    collection_name=self.test_collection,
                    confirm=True
                )
                end_time = time.time()
                
                duration = end_time - start_time
                throughput = size / duration if duration > 0 else 0
                
                performance_results.append({
                    'size': size,
                    'duration': duration,
                    'throughput': throughput,
                    'success': result
                })
                
                print(f"      â±ï¸  è€—æ—¶: {duration:.2f} ç§’")
                print(f"      ğŸ“ˆ ååé‡: {throughput:.0f} æ¡/ç§’")
            
            # è®¡ç®—å¹³å‡æ€§èƒ½
            avg_throughput = sum(r['throughput'] for r in performance_results) / len(performance_results)
            success = all(r['success'] for r in performance_results)
            
            self.test_results.append({
                'test': 'performance',
                'success': success,
                'duration': sum(r['duration'] for r in performance_results),
                'details': f"å¹³å‡ååé‡: {avg_throughput:.0f} æ¡/ç§’"
            })
            
            print(f"   {'âœ…' if success else 'âŒ'} æ€§èƒ½æµ‹è¯•: {'é€šè¿‡' if success else 'å¤±è´¥'}")
            print(f"   ğŸ“ˆ å¹³å‡ååé‡: {avg_throughput:.0f} æ¡/ç§’")
            
            return success
            
        except Exception as e:
            print(f"   âŒ æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_error_recovery(self):
        """æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶"""
        print("\nğŸ›¡ï¸ æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶...")
        
        try:
            # æ¨¡æ‹Ÿç½‘ç»œä¸­æ–­ç­‰é”™è¯¯æƒ…å†µ
            original_method = self.db_handler.get_local_collection
            
            def failing_method(name):
                if name == self.test_collection and random.random() < 0.3:
                    raise Exception("æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯")
                return original_method(name)
            
            # ä¸´æ—¶æ›¿æ¢æ–¹æ³•
            self.db_handler.get_local_collection = failing_method
            
            start_time = time.time()
            try:
                result = self.db_manager.sync_data_incremental(
                    direction='cloud-to-local',
                    collection_name=self.test_collection,
                    confirm=True
                )
            finally:
                # æ¢å¤åŸæ–¹æ³•
                self.db_handler.get_local_collection = original_method
            
            end_time = time.time()
            
            # éªŒè¯é”™è¯¯æ¢å¤åçš„æ•°æ®ä¸€è‡´æ€§
            success = self._verify_sync_result()
            
            self.test_results.append({
                'test': 'error_recovery',
                'success': success,
                'duration': end_time - start_time,
                'details': f"é”™è¯¯æ¢å¤æµ‹è¯•{'æˆåŠŸ' if success else 'å¤±è´¥'}"
            })
            
            print(f"   {'âœ…' if success else 'âŒ'} é”™è¯¯æ¢å¤æµ‹è¯•: {'é€šè¿‡' if success else 'å¤±è´¥'}")
            print(f"   â±ï¸  è€—æ—¶: {end_time - start_time:.2f} ç§’")
            
            return success
            
        except Exception as e:
            print(f"   âŒ é”™è¯¯æ¢å¤æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _verify_sync_result(self):
        """éªŒè¯åŒæ­¥ç»“æœ"""
        try:
            if not (self.db_manager.cloud_available and self.db_manager.local_available):
                print("   âš ï¸  åŒæ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡éªŒè¯")
                return True
            
            cloud_collection = self.db_handler.get_cloud_collection(self.test_collection)
            local_collection = self.db_handler.get_local_collection(self.test_collection)
            
            cloud_count = cloud_collection.count_documents({})
            local_count = local_collection.count_documents({})
            
            print(f"   ğŸ“Š æ•°æ®é‡å¯¹æ¯”: äº‘ç«¯ {cloud_count:,} vs æœ¬åœ° {local_count:,}")
            
            # éªŒè¯æ•°æ®é‡æ˜¯å¦ä¸€è‡´
            if cloud_count != local_count:
                print(f"   âŒ æ•°æ®é‡ä¸ä¸€è‡´")
                return False
            
            # æŠ½æ ·éªŒè¯æ•°æ®å†…å®¹
            sample_size = min(10, cloud_count)
            if sample_size > 0:
                cloud_samples = list(cloud_collection.find().limit(sample_size))
                for sample in cloud_samples:
                    query = {'ts_code': sample['ts_code'], 'trade_date': sample['trade_date']}
                    local_doc = local_collection.find_one(query)
                    if not local_doc:
                        print(f"   âŒ æœ¬åœ°ç¼ºå¤±è®°å½•: {query}")
                        return False
            
            print(f"   âœ… æ•°æ®éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"   âŒ éªŒè¯å¤±è´¥: {e}")
            return False
    
    def _prepare_collection_data(self, collection_name, count):
        """ä¸ºæŒ‡å®šé›†åˆå‡†å¤‡æµ‹è¯•æ•°æ®"""
        test_data = []
        base_date = datetime(2024, 1, 1)
        
        for i in range(count):
            doc = {
                'ts_code': f'{collection_name}_{i % 10:02d}',
                'trade_date': (base_date + timedelta(days=i % 30)).strftime('%Y%m%d'),
                'value': random.uniform(1, 100),
                'created_at': datetime.utcnow()
            }
            test_data.append(doc)
        
        # æ’å…¥åˆ°äº‘ç«¯
        if self.db_manager.cloud_available:
            cloud_collection = self.db_handler.get_cloud_collection(collection_name)
            cloud_collection.insert_many(test_data)
    
    def _cleanup_collection(self, collection_name):
        """æ¸…ç†æŒ‡å®šé›†åˆ"""
        try:
            if self.db_manager.cloud_available:
                self.db_handler.get_cloud_collection(collection_name).drop()
            if self.db_manager.local_available:
                self.db_handler.get_local_collection(collection_name).drop()
        except Exception:
            pass
    
    def _cleanup_test_collections(self):
        """æ¸…ç†æ‰€æœ‰æµ‹è¯•é›†åˆ"""
        test_collections = [self.test_collection]
        
        for collection_name in test_collections:
            self._cleanup_collection(collection_name)
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹æ•°æ®åº“åŒæ­¥åŠŸèƒ½æµ‹è¯•")
        print("=" * 60)
        
        # æ£€æŸ¥æ•°æ®åº“å¯ç”¨æ€§
        if not (self.db_manager.cloud_available and self.db_manager.local_available):
            print("âŒ éœ€è¦äº‘ç«¯å’Œæœ¬åœ°æ•°æ®åº“éƒ½å¯ç”¨æ‰èƒ½è¿›è¡Œæµ‹è¯•")
            return False
        
        # è®¾ç½®åˆå§‹æµ‹è¯•æ•°æ®
        self.setup_test_data(1000)
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        tests = [
            ('å¢é‡åŒæ­¥', self.test_incremental_sync),
            ('å…¨é‡åŒæ­¥', self.test_full_sync),
            ('å¹¶å‘å®‰å…¨', self.test_concurrent_sync),
            ('æ€§èƒ½æµ‹è¯•', self.test_performance),
            ('é”™è¯¯æ¢å¤', self.test_error_recovery)
        ]
        
        passed_tests = 0
        total_tests = len(tests)
        
        for test_name, test_func in tests:
            print(f"\nğŸ”¬ å¼€å§‹æµ‹è¯•: {test_name}")
            try:
                if test_func():
                    passed_tests += 1
                    print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
                else:
                    print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
            except Exception as e:
                print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        self._cleanup_test_collections()
        
        # æ˜¾ç¤ºæµ‹è¯•æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        
        for result in self.test_results:
            status = "âœ… é€šè¿‡" if result['success'] else "âŒ å¤±è´¥"
            print(f"{result['test']:<20} {status:<10} {result['duration']:.2f}s  {result['details']}")
        
        print(f"\nğŸ“ˆ æ€»ä½“ç»“æœ: {passed_tests}/{total_tests} é¡¹æµ‹è¯•é€šè¿‡")
        success_rate = (passed_tests / total_tests) * 100
        print(f"ğŸ“Š æˆåŠŸç‡: {success_rate:.1f}%")
        
        if success_rate >= 80:
            print("ğŸ‰ æµ‹è¯•ç»“æœè‰¯å¥½ï¼ŒåŒæ­¥åŠŸèƒ½åŸºæœ¬æ­£å¸¸ï¼")
        elif success_rate >= 60:
            print("âš ï¸  æµ‹è¯•ç»“æœä¸€èˆ¬ï¼Œå»ºè®®æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•é¡¹")
        else:
            print("âŒ æµ‹è¯•ç»“æœè¾ƒå·®ï¼Œéœ€è¦é‡ç‚¹ä¿®å¤åŒæ­¥åŠŸèƒ½")
        
        return success_rate >= 80

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="æ•°æ®åº“åŒæ­¥åŠŸèƒ½æµ‹è¯•")
    parser.add_argument('test_type', nargs='?', default='all',
                       choices=['all', 'incremental', 'full', 'concurrent', 'performance', 'error'],
                       help="æµ‹è¯•ç±»å‹")
    
    args = parser.parse_args()
    
    tester = SyncTester()
    
    if args.test_type == 'all':
        success = tester.run_all_tests()
    elif args.test_type == 'incremental':
        tester.setup_test_data(1000)
        success = tester.test_incremental_sync()
        tester._cleanup_test_collections()
    elif args.test_type == 'full':
        tester.setup_test_data(1000)
        success = tester.test_full_sync()
        tester._cleanup_test_collections()
    elif args.test_type == 'concurrent':
        success = tester.test_concurrent_sync()
    elif args.test_type == 'performance':
        success = tester.test_performance()
        tester._cleanup_test_collections()
    elif args.test_type == 'error':
        tester.setup_test_data(1000)
        success = tester.test_error_recovery()
        tester._cleanup_test_collections()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main() 