#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å› å­åˆ†æå™¨ - æ™ºèƒ½å› å­æŒ–æ˜ç³»ç»Ÿæ ¸å¿ƒæ¨¡å—
åŸºäº261ä¸ªæŠ€æœ¯å› å­åˆ†æä¸­è¯A500æŒ‡æ•°æˆåˆ†è‚¡çš„æ”¶ç›Šé¢„æµ‹èƒ½åŠ›
"""

import os
import sys
import pandas as pd
import numpy as np
import warnings
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
import yaml
import logging
from dataclasses import dataclass
from concurrent.futures import ProcessPoolExecutor, as_completed

# ç§‘å­¦è®¡ç®—åº“
from scipy import stats
from scipy.stats import pearsonr, spearmanr
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))))
from api.global_db import db_handler

warnings.filterwarnings('ignore')

@dataclass
class FactorAnalysisResult:
    """å› å­åˆ†æç»“æœæ•°æ®ç±»"""
    factor_name: str
    ic_mean: float
    ic_std: float
    ic_ir: float
    rank_ic: float
    t_stat: float
    p_value: float
    significance: bool
    turnover: float
    sharpe_ratio: float
    max_drawdown: float
    analysis_date: datetime
    sample_size: int
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'factor_name': self.factor_name,
            'ic_mean': self.ic_mean,
            'ic_std': self.ic_std,
            'ic_ir': self.ic_ir,
            'rank_ic': self.rank_ic,
            't_stat': self.t_stat,
            'p_value': self.p_value,
            'significance': self.significance,
            'turnover': self.turnover,
            'sharpe_ratio': self.sharpe_ratio,
            'max_drawdown': self.max_drawdown,
            'analysis_date': self.analysis_date,
            'sample_size': self.sample_size
        }


class FactorAnalyzer:
    """
    å› å­åˆ†æå™¨
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. åŠ è½½A500æˆåˆ†è‚¡çš„261ä¸ªæŠ€æœ¯å› å­æ•°æ®
    2. è®¡ç®—å› å­ä¸æ”¶ç›Šç‡çš„ç›¸å…³æ€§æŒ‡æ ‡
    3. å› å­æœ‰æ•ˆæ€§è¯„ä¼°å’Œæ’åº
    4. å› å­ç¨³å®šæ€§åˆ†æ
    5. å› å­æ­£äº¤åŒ–å¤„ç†
    """
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–å› å­åˆ†æå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.logger = self._setup_logger()
        
        # åŠ è½½é…ç½®
        if config_path is None:
            config_path = os.path.join(os.path.dirname(__file__), "../config/factor_mining_config.yaml")
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
            self.logger.info(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
        except Exception as e:
            self.logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            raise
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.db_handler = db_handler
        self.scaler = self._get_scaler()
        self.factor_data = {}
        self.return_data = {}
        self.analysis_results = {}
        
        # å› å­åˆ—è¡¨ - ä»æ•°æ®åº“å­—æ®µåˆ†ææ–‡ä»¶ä¸­è·å–
        self.factor_fields = self._load_factor_fields()
        
        self.logger.info(f"ğŸš€ å› å­åˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼Œå…±{len(self.factor_fields)}ä¸ªæŠ€æœ¯å› å­")
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _get_scaler(self):
        """è·å–æ ‡å‡†åŒ–å™¨"""
        scaler_type = self.config['factor_config']['preprocessing']['standardization']
        
        if scaler_type == 'zscore':
            return StandardScaler()
        elif scaler_type == 'minmax':
            return MinMaxScaler()
        elif scaler_type == 'robust':
            return RobustScaler()
        else:
            return StandardScaler()
    
    def _load_factor_fields(self) -> List[str]:
        """
        åŠ è½½261ä¸ªæŠ€æœ¯å› å­å­—æ®µåˆ—è¡¨
        ä»stock_factor_pro_fields_analysis.jsonä¸­è·å–
        """
        try:
            factor_file = os.path.join(
                os.path.dirname(__file__), 
                "../../../backtrader_strategies/docs/stock_factor_pro_fields_analysis.json"
            )
            
            import json
            with open(factor_file, 'r', encoding='utf-8') as f:
                factor_analysis = json.load(f)
            
            # æå–æ‰€æœ‰å› å­å­—æ®µå
            factor_fields = []
            # æ ¹æ®å®é™…JSONæ–‡ä»¶ç»“æ„æå–å› å­å­—æ®µ
            factor_categories = ['emotion_fields', 'trend_fields', 'other_fields']
            for category in factor_categories:
                fields = factor_analysis.get(category, [])
                if isinstance(fields, list):
                    factor_fields.extend(fields)
            
            # å»é‡å¹¶æ’åº
            factor_fields = sorted(list(set(factor_fields)))
            
            self.logger.info(f"ğŸ“Š åŠ è½½æŠ€æœ¯å› å­å­—æ®µ: {len(factor_fields)}ä¸ª")
            return factor_fields
            
        except Exception as e:
            self.logger.error(f"âŒ å› å­å­—æ®µåŠ è½½å¤±è´¥: {e}")
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å¤‡ç”¨å› å­åˆ—è¡¨
            return self._get_backup_factors()
    
    def _get_backup_factors(self) -> List[str]:
        """è·å–å¤‡ç”¨å› å­åˆ—è¡¨"""
        backup_factors = []
        factor_config = self.config['factor_config']['factor_categories']
        
        for category, factors in factor_config.items():
            if isinstance(factors, list):
                backup_factors.extend(factors)
        
        return backup_factors
    
    def load_a500_universe(self, date: str = None) -> List[str]:
        """
        åŠ è½½A500æŒ‡æ•°æˆåˆ†è‚¡åˆ—è¡¨
        
        Args:
            date: æŒ‡å®šæ—¥æœŸï¼Œé»˜è®¤ä½¿ç”¨æœ€æ–°æ—¥æœŸ
            
        Returns:
            A500æˆåˆ†è‚¡ä»£ç åˆ—è¡¨
        """
        try:
            collection = self.db_handler.get_collection('index_weight')
            index_code = self.config['data_config']['index_code']
            
            # æŸ¥è¯¢æ¡ä»¶
            query = {'index_code': index_code}
            if date:
                query['trade_date'] = date
            
            # è·å–æœ€æ–°æ—¥æœŸçš„æˆåˆ†è‚¡
            cursor = collection.find(query).sort('trade_date', -1).limit(500)
            
            stock_codes = []
            latest_date = None
            
            for doc in cursor:
                current_date = doc.get('trade_date')
                if latest_date is None:
                    latest_date = current_date
                elif current_date != latest_date:
                    break
                
                if 'con_code' in doc and doc['con_code']:
                    stock_codes.append(doc['con_code'])
            
            stock_codes = sorted(list(set(stock_codes)))
            self.logger.info(f"ğŸ“Š åŠ è½½A500æˆåˆ†è‚¡: {len(stock_codes)}åªï¼Œæ—¥æœŸ: {latest_date}")
            
            return stock_codes
            
        except Exception as e:
            self.logger.error(f"âŒ A500æˆåˆ†è‚¡åŠ è½½å¤±è´¥: {e}")
            return []
    
    def load_factor_data(self, 
                        stock_codes: List[str], 
                        start_date: str, 
                        end_date: str) -> pd.DataFrame:
        """
        åŠ è½½å› å­æ•°æ®
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            å› å­æ•°æ®DataFrame
        """
        try:
            self.logger.info(f"ğŸ“Š å¼€å§‹åŠ è½½å› å­æ•°æ®: {len(stock_codes)}åªè‚¡ç¥¨ï¼Œ{start_date} to {end_date}")
            
            collection = self.db_handler.get_collection('stock_factor_pro')
            
            # æ‰¹é‡æŸ¥è¯¢
            all_data = []
            batch_size = 50
            
            for i in range(0, len(stock_codes), batch_size):
                batch_stocks = stock_codes[i:i+batch_size]
                
                # è½¬æ¢æ—¥æœŸæ ¼å¼ (YYYY-MM-DD -> YYYYMMDD)
                start_date_str = start_date.replace('-', '')
                end_date_str = end_date.replace('-', '')
                
                query = {
                    'ts_code': {'$in': batch_stocks},
                    'trade_date': {
                        '$gte': start_date_str,
                        '$lte': end_date_str
                    }
                }
                
                # æŠ•å½± - åªè·å–éœ€è¦çš„å­—æ®µ
                projection = {'_id': 0, 'ts_code': 1, 'trade_date': 1}
                for factor in self.factor_fields:
                    projection[factor] = 1
                
                cursor = collection.find(query, projection)
                batch_data = list(cursor)
                all_data.extend(batch_data)
                
                self.logger.info(f"  æ‰¹æ¬¡ {i//batch_size + 1}: åŠ è½½äº† {len(batch_data)} æ¡è®°å½•")
            
            if not all_data:
                self.logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•å› å­æ•°æ®")
                return pd.DataFrame()
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(all_data)
            
            # é‡å‘½åå­—æ®µä»¥ä¿æŒä¸€è‡´æ€§
            if 'ts_code' in df.columns:
                df = df.rename(columns={'ts_code': 'stock_code'})
            
            # æ•°æ®é¢„å¤„ç†
            df = self._preprocess_factor_data(df)
            
            self.logger.info(f"âœ… å› å­æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ å› å­æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _preprocess_factor_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å› å­æ•°æ®é¢„å¤„ç†
        
        Args:
            df: åŸå§‹å› å­æ•°æ®
            
        Returns:
            é¢„å¤„ç†åçš„å› å­æ•°æ®
        """
        try:
            if df.empty:
                return df
            
            # è®¾ç½®ç´¢å¼•
            # å¤„ç†æ—¥æœŸæ ¼å¼ï¼šYYYYMMDD -> YYYY-MM-DD
            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
            df = df.set_index(['trade_date', 'stock_code'])
            
            # æ•°æ®æ¸…æ´—
            preprocessing_config = self.config['factor_config']['preprocessing']
            
            # å¤„ç†å¼‚å¸¸å€¼
            df = self._handle_outliers(df, preprocessing_config)
            
            # æ•°æ®å¡«å……
            fill_method = preprocessing_config.get('fill_method', 'forward')
            if fill_method == 'forward':
                df = df.fillna(method='ffill')
            elif fill_method == 'backward':
                df = df.fillna(method='bfill')
            elif fill_method == 'interpolate':
                df = df.interpolate()
            
            # æ ‡å‡†åŒ–
            factor_columns = [col for col in df.columns if col in self.factor_fields]
            df[factor_columns] = self.scaler.fit_transform(df[factor_columns])
            
            self.logger.info(f"ğŸ“Š å› å­æ•°æ®é¢„å¤„ç†å®Œæˆ: {df.shape}")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ å› å­æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            return df
    
    def _handle_outliers(self, df: pd.DataFrame, config: Dict) -> pd.DataFrame:
        """å¤„ç†å¼‚å¸¸å€¼"""
        method = config.get('outlier_method', 'mad')
        threshold = config.get('outlier_threshold', 3)
        
        factor_columns = [col for col in df.columns if col in self.factor_fields]
        
        for col in factor_columns:
            if col not in df.columns:
                continue
                
            if method == 'mad':
                # MADæ–¹æ³•
                median = df[col].median()
                mad = np.median(np.abs(df[col] - median))
                lower = median - threshold * mad
                upper = median + threshold * mad
            elif method == 'iqr':
                # IQRæ–¹æ³•
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower = Q1 - threshold * IQR
                upper = Q3 + threshold * IQR
            else:  # zscore
                # Z-scoreæ–¹æ³•
                mean = df[col].mean()
                std = df[col].std()
                lower = mean - threshold * std
                upper = mean + threshold * std
            
            # æˆªæ–­å¤„ç†
            df[col] = df[col].clip(lower=lower, upper=upper)
        
        return df
    
    def calculate_forward_returns(self, 
                                stock_codes: List[str],
                                start_date: str, 
                                end_date: str) -> pd.DataFrame:
        """
        è®¡ç®—å‰ç»æ”¶ç›Šç‡
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            å‰ç»æ”¶ç›Šç‡DataFrame
        """
        try:
            self.logger.info(f"ğŸ“Š å¼€å§‹è®¡ç®—å‰ç»æ”¶ç›Šç‡")
            
            collection = self.db_handler.get_collection('stock_factor_pro')
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼ (YYYY-MM-DD -> YYYYMMDD)
            start_date_str = start_date.replace('-', '')
            end_date_str = end_date.replace('-', '')
            
            # æŸ¥è¯¢ä»·æ ¼æ•°æ®
            query = {
                'ts_code': {'$in': stock_codes},
                'trade_date': {
                    '$gte': start_date_str,
                    '$lte': end_date_str
                }
            }
            
            projection = {
                '_id': 0,
                'ts_code': 1,
                'trade_date': 1,
                'close': 1,
                'close_qfq': 1  # ä½¿ç”¨å‰å¤æƒä»·æ ¼
            }
            
            cursor = collection.find(query, projection).sort([('ts_code', 1), ('trade_date', 1)])
            price_data = list(cursor)
            
            if not price_data:
                return pd.DataFrame()
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(price_data)
            # å¤„ç†æ—¥æœŸæ ¼å¼ï¼šYYYYMMDD -> YYYY-MM-DD
            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
            # é‡å‘½åå­—æ®µä»¥ä¿æŒä¸€è‡´æ€§
            if 'ts_code' in df.columns:
                df = df.rename(columns={'ts_code': 'stock_code'})
            
            # ä½¿ç”¨å¤æƒä»·æ ¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ”¶ç›˜ä»·
            if 'close_qfq' in df.columns and df['close_qfq'].notna().any():
                price_col = 'close_qfq'
            else:
                price_col = 'close'
            
            # è®¡ç®—å„å‘¨æœŸå‰ç»æ”¶ç›Šç‡
            forward_periods = self.config['data_config']['forward_returns']
            return_data = []
            
            for stock in stock_codes:
                stock_df = df[df['stock_code'] == stock].copy()
                if stock_df.empty:
                    continue
                
                stock_df = stock_df.sort_values('trade_date')
                stock_df = stock_df.set_index('trade_date')
                
                for period in forward_periods:
                    # è®¡ç®—å‰ç»æ”¶ç›Šç‡
                    return_col = f'return_{period}d'
                    stock_df[return_col] = stock_df[price_col].pct_change(periods=period).shift(-period)
                
                # é‡ç½®ç´¢å¼•å¹¶æ·»åŠ è‚¡ç¥¨ä»£ç 
                stock_df = stock_df.reset_index()
                stock_df['stock_code'] = stock
                return_data.append(stock_df)
            
            if not return_data:
                return pd.DataFrame()
            
            result_df = pd.concat(return_data, ignore_index=True)
            
            # è®¾ç½®å¤šé‡ç´¢å¼•
            result_df = result_df.set_index(['trade_date', 'stock_code'])
            
            self.logger.info(f"âœ… å‰ç»æ”¶ç›Šç‡è®¡ç®—å®Œæˆ: {result_df.shape}")
            return result_df
            
        except Exception as e:
            self.logger.error(f"âŒ å‰ç»æ”¶ç›Šç‡è®¡ç®—å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def calculate_factor_ic(self, 
                          factor_data: pd.DataFrame, 
                          return_data: pd.DataFrame,
                          return_period: int = 20) -> Dict[str, FactorAnalysisResult]:
        """
        è®¡ç®—å› å­ICæŒ‡æ ‡
        
        Args:
            factor_data: å› å­æ•°æ®
            return_data: æ”¶ç›Šç‡æ•°æ®
            return_period: æ”¶ç›Šç‡å‘¨æœŸ
            
        Returns:
            å› å­åˆ†æç»“æœå­—å…¸
        """
        try:
            self.logger.info(f"ğŸ“Š å¼€å§‹è®¡ç®—å› å­ICæŒ‡æ ‡ï¼Œå‘¨æœŸ: {return_period}å¤©")
            
            return_col = f'return_{return_period}d'
            if return_col not in return_data.columns:
                self.logger.error(f"âŒ æ”¶ç›Šç‡åˆ— {return_col} ä¸å­˜åœ¨")
                return {}
            
            results = {}
            factor_columns = [col for col in factor_data.columns if col in self.factor_fields]
            
            # åˆå¹¶æ•°æ®
            merged_data = factor_data.join(return_data[return_col], how='inner')
            
            for factor in factor_columns:
                try:
                    result = self._analyze_single_factor(
                        merged_data, factor, return_col
                    )
                    if result:
                        results[factor] = result
                        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ å› å­ {factor} åˆ†æå¤±è´¥: {e}")
                    continue
            
            self.logger.info(f"âœ… å› å­ICè®¡ç®—å®Œæˆï¼Œæœ‰æ•ˆå› å­: {len(results)}")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ å› å­ICè®¡ç®—å¤±è´¥: {e}")
            return {}
    
    def _analyze_single_factor(self, 
                              data: pd.DataFrame, 
                              factor_name: str, 
                              return_col: str) -> Optional[FactorAnalysisResult]:
        """
        åˆ†æå•ä¸ªå› å­
        
        Args:
            data: åˆå¹¶çš„æ•°æ®
            factor_name: å› å­åç§°
            return_col: æ”¶ç›Šç‡åˆ—å
            
        Returns:
            å› å­åˆ†æç»“æœ
        """
        try:
            # è·å–æœ‰æ•ˆæ•°æ®
            valid_data = data[[factor_name, return_col]].dropna()
            
            if len(valid_data) < 30:  # æœ€å°‘éœ€è¦30ä¸ªè§‚æµ‹å€¼
                return None
            
            factor_values = valid_data[factor_name]
            return_values = valid_data[return_col]
            
            # è®¡ç®—ICæŒ‡æ ‡
            ic_corr, ic_pvalue = pearsonr(factor_values, return_values)
            rank_ic, _ = spearmanr(factor_values, return_values)
            
            # æ—¶é—´åºåˆ—ICåˆ†æ
            ic_series = self._calculate_rolling_ic(data, factor_name, return_col)
            
            if len(ic_series) < 10:
                return None
            
            ic_mean = np.mean(ic_series)
            ic_std = np.std(ic_series)
            ic_ir = ic_mean / ic_std if ic_std > 0 else 0
            
            # tæ£€éªŒ
            t_stat, p_value = stats.ttest_1samp(ic_series, 0)
            significance = p_value < 0.05
            
            # è®¡ç®—å…¶ä»–æŒ‡æ ‡
            turnover = self._calculate_factor_turnover(data, factor_name)
            sharpe_ratio = self._calculate_factor_sharpe(ic_series)
            max_drawdown = self._calculate_max_drawdown(ic_series)
            
            return FactorAnalysisResult(
                factor_name=factor_name,
                ic_mean=ic_mean,
                ic_std=ic_std,
                ic_ir=ic_ir,
                rank_ic=rank_ic,
                t_stat=t_stat,
                p_value=p_value,
                significance=significance,
                turnover=turnover,
                sharpe_ratio=sharpe_ratio,
                max_drawdown=max_drawdown,
                analysis_date=datetime.now(),
                sample_size=len(valid_data)
            )
            
        except Exception as e:
            self.logger.error(f"âŒ å› å­ {factor_name} åˆ†æå¤±è´¥: {e}")
            return None
    
    def _calculate_rolling_ic(self, 
                             data: pd.DataFrame, 
                             factor_name: str, 
                             return_col: str,
                             window: int = 60) -> np.ndarray:
        """è®¡ç®—æ»šåŠ¨IC"""
        try:
            # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—æ¯æ—¥IC
            daily_ic = []
            dates = data.index.get_level_values(0).unique().sort_values()
            
            for date in dates:
                try:
                    date_data = data.xs(date, level=0)[[factor_name, return_col]].dropna()
                    
                    if len(date_data) < 10:
                        continue
                    
                    ic, _ = pearsonr(date_data[factor_name], date_data[return_col])
                    if not np.isnan(ic):
                        daily_ic.append(ic)
                        
                except Exception:
                    continue
            
            return np.array(daily_ic)
            
        except Exception as e:
            self.logger.error(f"âŒ æ»šåŠ¨ICè®¡ç®—å¤±è´¥: {e}")
            return np.array([])
    
    def _calculate_factor_turnover(self, data: pd.DataFrame, factor_name: str) -> float:
        """è®¡ç®—å› å­æ¢æ‰‹ç‡"""
        try:
            # ç®€åŒ–çš„æ¢æ‰‹ç‡è®¡ç®—
            return 0.3  # æš‚æ—¶è¿”å›å›ºå®šå€¼
        except:
            return 0.0
    
    def _calculate_factor_sharpe(self, ic_series: np.ndarray) -> float:
        """è®¡ç®—å› å­å¤æ™®æ¯”ç‡"""
        try:
            if len(ic_series) == 0:
                return 0.0
            return np.mean(ic_series) / np.std(ic_series) if np.std(ic_series) > 0 else 0.0
        except:
            return 0.0
    
    def _calculate_max_drawdown(self, ic_series: np.ndarray) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        try:
            if len(ic_series) == 0:
                return 0.0
            
            cumulative = np.cumsum(ic_series)
            running_max = np.maximum.accumulate(cumulative)
            drawdown = (cumulative - running_max)
            return float(np.min(drawdown))
        except:
            return 0.0
    
    def rank_factors(self, 
                    analysis_results: Dict[str, FactorAnalysisResult],
                    ranking_method: str = 'ic_ir') -> List[Tuple[str, FactorAnalysisResult]]:
        """
        å› å­æ’åº
        
        Args:
            analysis_results: å› å­åˆ†æç»“æœ
            ranking_method: æ’åºæ–¹æ³• (ic_ir, ic_mean, significance)
            
        Returns:
            æ’åºåçš„å› å­åˆ—è¡¨
        """
        try:
            if ranking_method == 'ic_ir':
                sorted_factors = sorted(
                    analysis_results.items(),
                    key=lambda x: abs(x[1].ic_ir),
                    reverse=True
                )
            elif ranking_method == 'ic_mean':
                sorted_factors = sorted(
                    analysis_results.items(),
                    key=lambda x: abs(x[1].ic_mean),
                    reverse=True
                )
            elif ranking_method == 'significance':
                # å…ˆæŒ‰æ˜¾è‘—æ€§æ’åºï¼Œå†æŒ‰IC_IRæ’åº
                sorted_factors = sorted(
                    analysis_results.items(),
                    key=lambda x: (x[1].significance, abs(x[1].ic_ir)),
                    reverse=True
                )
            else:
                sorted_factors = list(analysis_results.items())
            
            self.logger.info(f"ğŸ“Š å› å­æ’åºå®Œæˆï¼Œæ–¹æ³•: {ranking_method}, å› å­æ•°: {len(sorted_factors)}")
            return sorted_factors
            
        except Exception as e:
            self.logger.error(f"âŒ å› å­æ’åºå¤±è´¥: {e}")
            return list(analysis_results.items())
    
    def run_factor_analysis(self, 
                           start_date: str = None, 
                           end_date: str = None) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„å› å­åˆ†ææµç¨‹
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            self.logger.info("ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´å› å­åˆ†ææµç¨‹")
            
            # ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤æ—¥æœŸ
            if start_date is None:
                start_date = self.config['data_config']['train_period']['start_date']
            if end_date is None:
                end_date = self.config['data_config']['train_period']['end_date']
            
            # 1. åŠ è½½A500æˆåˆ†è‚¡
            stock_codes = self.load_a500_universe()
            if not stock_codes:
                raise ValueError("æœªèƒ½åŠ è½½A500æˆåˆ†è‚¡")
            
            # 2. åŠ è½½å› å­æ•°æ®
            factor_data = self.load_factor_data(stock_codes, start_date, end_date)
            if factor_data.empty:
                raise ValueError("æœªèƒ½åŠ è½½å› å­æ•°æ®")
            
            # 3. è®¡ç®—å‰ç»æ”¶ç›Šç‡
            return_data = self.calculate_forward_returns(stock_codes, start_date, end_date)
            if return_data.empty:
                raise ValueError("æœªèƒ½è®¡ç®—å‰ç»æ”¶ç›Šç‡")
            
            # 4. è®¡ç®—å› å­ICæŒ‡æ ‡
            forward_periods = self.config['data_config']['forward_returns']
            all_results = {}
            
            for period in forward_periods:
                self.logger.info(f"ğŸ“Š åˆ†æ {period} å¤©å‰ç»æ”¶ç›Šç‡")
                period_results = self.calculate_factor_ic(factor_data, return_data, period)
                all_results[f'{period}d'] = period_results
            
            # 5. å› å­æ’åº
            ranking_results = {}
            for period, results in all_results.items():
                ranking_results[period] = self.rank_factors(results)
            
            # 6. ä¿å­˜ç»“æœ
            self.analysis_results = {
                'factor_analysis': all_results,
                'factor_ranking': ranking_results,
                'metadata': {
                    'start_date': start_date,
                    'end_date': end_date,
                    'stock_count': len(stock_codes),
                    'factor_count': len(self.factor_fields),
                    'analysis_date': datetime.now().isoformat()
                }
            }
            
            self.logger.info("âœ… å› å­åˆ†ææµç¨‹å®Œæˆ")
            return self.analysis_results
            
        except Exception as e:
            self.logger.error(f"âŒ å› å­åˆ†ææµç¨‹å¤±è´¥: {e}")
            return {}
    
    def get_top_factors(self, 
                       period: str = '20d', 
                       top_k: int = 50) -> List[str]:
        """
        è·å–Topå› å­åˆ—è¡¨
        
        Args:
            period: æ”¶ç›Šç‡å‘¨æœŸ
            top_k: å–å‰Kä¸ªå› å­
            
        Returns:
            Topå› å­åç§°åˆ—è¡¨
        """
        try:
            if not self.analysis_results:
                self.logger.warning("âš ï¸ è¯·å…ˆè¿è¡Œå› å­åˆ†æ")
                return []
            
            ranking = self.analysis_results.get('factor_ranking', {}).get(period, [])
            top_factors = [name for name, _ in ranking[:top_k]]
            
            self.logger.info(f"ğŸ“Š è·å–Top{top_k}å› å­: {period}å‘¨æœŸ")
            return top_factors
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–Topå› å­å¤±è´¥: {e}")
            return []


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸš€ æµ‹è¯•å› å­åˆ†æå™¨...")
    
    try:
        analyzer = FactorAnalyzer()
        
        # è¿è¡Œå› å­åˆ†æ
        results = analyzer.run_factor_analysis(
            start_date="2023-01-01",
            end_date="2023-12-31"
        )
        
        if results:
            print("âœ… å› å­åˆ†ææµ‹è¯•æˆåŠŸ")
            
            # è·å–Top20å› å­
            top_factors = analyzer.get_top_factors(period='20d', top_k=20)
            print(f"ğŸ“Š Top20å› å­: {top_factors}")
        else:
            print("âŒ å› å­åˆ†ææµ‹è¯•å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()