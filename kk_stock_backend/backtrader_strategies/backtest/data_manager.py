#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®ç®¡ç†å™¨
è´Ÿè´£ä»æ•°æ®åº“åŠ è½½å†å²æ•°æ®ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®æ¥å£
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from api.global_db import db_handler
from backtrader_strategies.config import DatabaseConfig


class DataManager:
    """
    æ•°æ®ç®¡ç†å™¨
    è´Ÿè´£åŠ è½½å’Œç®¡ç†å†å²å¸‚åœºæ•°æ®
    """
    
    def __init__(self, db_config: Optional[DatabaseConfig] = None):
        """
        åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        
        Args:
            db_config: æ•°æ®åº“é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.db_config = db_config or DatabaseConfig()
        self.db_handler = db_handler
        self.data_cache = {}  # æ•°æ®ç¼“å­˜
        self.stock_universe = []  # è‚¡ç¥¨æ± 
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
    def load_stock_universe(self, index_code: str = "000510.CSI") -> List[str]:
        """
        åŠ è½½è‚¡ç¥¨æ± ï¼ˆé»˜è®¤ä¸­è¯A500ï¼‰
        
        Args:
            index_code: æŒ‡æ•°ä»£ç 
            
        Returns:
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        try:
            self.logger.info(f"åŠ è½½è‚¡ç¥¨æ± : {index_code}")
            
            # è·å–æŒ‡æ•°æƒé‡é›†åˆ
            index_collection = self.db_handler.get_collection('index_weight')
            
            # æŸ¥è¯¢æœ€æ–°çš„æˆåˆ†è‚¡
            query = {'index_code': index_code}
            cursor = index_collection.find(query).sort('trade_date', -1).limit(1000)
            
            stock_codes = []
            latest_date = None
            
            for doc in cursor:
                current_date = doc.get('trade_date')
                if latest_date is None:
                    latest_date = current_date
                elif current_date != latest_date:
                    break  # åªå–æœ€æ–°æ—¥æœŸçš„æ•°æ®
                    
                if 'con_code' in doc and doc['con_code']:
                    stock_codes.append(doc['con_code'])
            
            # å»é‡å¹¶æ’åº
            self.stock_universe = sorted(list(set(stock_codes)))
            
            self.logger.info(f"åŠ è½½å®Œæˆï¼Œè‚¡ç¥¨æ•°é‡: {len(self.stock_universe)}")
            return self.stock_universe
            
        except Exception as e:
            self.logger.error(f"åŠ è½½è‚¡ç¥¨æ± å¤±è´¥: {e}")
            # è¿”å›ä¸€äº›é»˜è®¤è‚¡ç¥¨ç”¨äºæµ‹è¯•
            self.stock_universe = ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000858.SZ']
            return self.stock_universe
    
    def load_stock_data(self, 
                       stock_code: str, 
                       start_date: str, 
                       end_date: str,
                       include_indicators: bool = True) -> pd.DataFrame:
        """
        åŠ è½½å•åªè‚¡ç¥¨çš„å†å²æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            include_indicators: æ˜¯å¦åŒ…å«æŠ€æœ¯æŒ‡æ ‡
            
        Returns:
            è‚¡ç¥¨å†å²æ•°æ®DataFrame
        """
        cache_key = f"{stock_code}_{start_date}_{end_date}_{include_indicators}"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.data_cache:
            return self.data_cache[cache_key].copy()
        
        try:
            collection = self.db_handler.get_collection(self.db_config.factor_collection)
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            start_date_str = start_date.replace('-', '')
            end_date_str = end_date.replace('-', '')
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {
                'ts_code': stock_code,
                'trade_date': {
                    '$gte': start_date_str,
                    '$lte': end_date_str
                }
            }
            
            # æŸ¥è¯¢æ•°æ®
            cursor = collection.find(query).sort('trade_date', 1)
            data_list = list(cursor)
            
            if not data_list:
                self.logger.warning(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} åœ¨ {start_date} åˆ° {end_date} æœŸé—´çš„æ•°æ®")
                return pd.DataFrame()
            
            # è°ƒè¯•è¾“å‡ºï¼šæ£€æŸ¥WRæŒ‡æ ‡æ˜¯å¦å­˜åœ¨
            if stock_code in ['002003.SZ', '600761.SH'] and data_list:
                sample_data = data_list[0]
                field_mapping = self.db_config.field_mapping
                wr1_source = field_mapping.get('wr1', 'wr1_bfq')
                wr2_source = field_mapping.get('wr2', 'wr_bfq')
                
                print(f"ğŸ” {stock_code} WRæŒ‡æ ‡æ£€æŸ¥:")
                print(f"   wr1å­—æ®µ: {wr1_source} ({'å­˜åœ¨' if wr1_source in sample_data else 'ä¸å­˜åœ¨'})")
                print(f"   wr2å­—æ®µ: {wr2_source} ({'å­˜åœ¨' if wr2_source in sample_data else 'ä¸å­˜åœ¨'})")
                if wr1_source in sample_data:
                    print(f"   wr1æ ·æœ¬å€¼: {sample_data.get(wr1_source)}")
                if wr2_source in sample_data:
                    print(f"   wr2æ ·æœ¬å€¼: {sample_data.get(wr2_source)}")
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data_list)
            
            # å¤„ç†æ—¥æœŸåˆ—
            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
            df.set_index('trade_date', inplace=True)
            
            # å­—æ®µæ˜ å°„å’Œé‡å‘½å
            field_mapping = self.db_config.field_mapping
            
            # åŸºç¡€OHLCVæ•°æ®å’Œå…³é”®å­—æ®µ
            required_fields = {
                'open': field_mapping.get('open', 'open'),
                'high': field_mapping.get('high', 'high'),
                'low': field_mapping.get('low', 'low'),
                'close': field_mapping.get('close', 'close'),
                'volume': field_mapping.get('volume', 'vol'),
                'amount': field_mapping.get('amount', 'amount'),
                'pre_close': field_mapping.get('pre_close', 'pre_close'),  # å‰æ”¶ç›˜ä»·
                'circ_mv': field_mapping.get('circ_mv', 'circ_mv')          # æµé€šå¸‚å€¼
            }
            
            # æ£€æŸ¥å¹¶é‡å‘½ååŸºç¡€å­—æ®µ
            result_df = pd.DataFrame(index=df.index)
            for target_field, source_field in required_fields.items():
                if source_field in df.columns:
                    result_df[target_field] = df[source_field]
                else:
                    self.logger.warning(f"ç¼ºå°‘å­—æ®µ: {source_field}")
                    result_df[target_field] = np.nan
            
            # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
            if include_indicators:
                indicator_fields = {
                    'ma5': field_mapping.get('ma5', 'ma_bfq_5'),
                    'ma10': field_mapping.get('ma10', 'ma_bfq_10'),
                    'ma20': field_mapping.get('ma20', 'ma_bfq_20'),
                    'ma60': field_mapping.get('ma60', 'ma_bfq_60'),
                    'ma120': field_mapping.get('ma120', 'ma_bfq_120'),
                    'ma250': field_mapping.get('ma250', 'ma_bfq_250'),
                    'ema5': field_mapping.get('ema5', 'ema_bfq_5'),
                    'ema10': field_mapping.get('ema10', 'ema_bfq_10'),
                    'ema20': field_mapping.get('ema20', 'ema_bfq_20'),
                    'macd_dif': field_mapping.get('macd_dif', 'macd_dif_bfq'),
                    'macd_dea': field_mapping.get('macd_dea', 'macd_dea_bfq'),
                    'macd_macd': field_mapping.get('macd_macd', 'macd_bfq'),
                    'kdj_k': field_mapping.get('kdj_k', 'kdj_k_bfq'),
                    'kdj_d': field_mapping.get('kdj_d', 'kdj_d_bfq'),
                    'kdj_j': field_mapping.get('kdj_j', 'kdj_bfq'),
                    'rsi6': field_mapping.get('rsi6', 'rsi_bfq_6'),
                    'rsi12': field_mapping.get('rsi12', 'rsi_bfq_12'),
                    'rsi24': field_mapping.get('rsi24', 'rsi_bfq_24'),
                    'boll_upper': field_mapping.get('boll_upper', 'boll_upper_bfq'),
                    'boll_mid': field_mapping.get('boll_mid', 'boll_mid_bfq'),
                    'boll_lower': field_mapping.get('boll_lower', 'boll_lower_bfq'),
                    'wr1': field_mapping.get('wr1', 'wr1_bfq'),
                    'wr2': field_mapping.get('wr2', 'wr_bfq'),
                    'turnover_rate': field_mapping.get('turnover_rate', 'turnover_rate'),
                    'volume_ratio': field_mapping.get('volume_ratio', 'volume_ratio'),
                    # volume_ma20 å°†é€šè¿‡è®¡ç®—å¾—å‡ºï¼Œä¸ä»æ•°æ®åº“å­—æ®µæ˜ å°„
                }
                
                for target_field, source_field in indicator_fields.items():
                    if target_field == 'volume_ma20':
                        continue  # volume_ma20å°†åœ¨åé¢è®¡ç®—
                    elif isinstance(source_field, str) and source_field in df.columns:
                        result_df[target_field] = df[source_field]
                    else:
                        result_df[target_field] = np.nan
            
            # æ•°æ®æ¸…ç† - åªå¯¹å¿…éœ€çš„ä»·æ ¼æ•°æ®åšä¸¥æ ¼æ£€æŸ¥
            result_df = result_df.dropna(subset=['open', 'high', 'low', 'close', 'volume'])
            
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'amount', 'pre_close', 'circ_mv']
            if include_indicators:
                numeric_columns.extend([
                    'ma5', 'ma10', 'ma20', 'ma60', 'ma120', 'ma250',
                    'ema5', 'ema10', 'ema20',
                    'macd_dif', 'macd_dea', 'macd_macd',
                    'kdj_k', 'kdj_d', 'kdj_j',
                    'rsi6', 'rsi12', 'rsi24',
                    'boll_upper', 'boll_mid', 'boll_lower',
                    'wr1', 'wr2',
                    'turnover_rate', 'volume_ratio', 'volume_ma20'
                ])
            
            for col in numeric_columns:
                if col in result_df.columns:
                    result_df[col] = pd.to_numeric(result_df[col], errors='coerce')
            
            # æœ€ç»ˆæ•°æ®éªŒè¯
            result_df = result_df.dropna(subset=['open', 'high', 'low', 'close'])
            
            # è°ƒè¯•è¾“å‡ºï¼šæ£€æŸ¥æœ€ç»ˆWRæ•°æ®
            if stock_code in ['002003.SZ', '600761.SH'] and not result_df.empty:
                print(f"ğŸ” {stock_code} æœ€ç»ˆWRæ•°æ®:")
                print(f"   wr1: {result_df['wr1'].iloc[0] if 'wr1' in result_df.columns else 'N/A'}")
                print(f"   wr2: {result_df['wr2'].iloc[0] if 'wr2' in result_df.columns else 'N/A'}")
                print(f"   volume_ma20: {result_df['volume_ma20'].iloc[0] if 'volume_ma20' in result_df.columns else 'N/A'}")
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            if include_indicators:
                # è®¡ç®—20æ—¥æˆäº¤é‡ç§»åŠ¨å¹³å‡
                result_df['volume_ma20'] = result_df['volume'].rolling(window=20, min_periods=1).mean()
                
                # è°ƒè¯•è¾“å‡ºï¼šæˆäº¤é‡è®¡ç®—å®Œæˆ
                if stock_code in ['002003.SZ', '600761.SH']:
                    print(f"   æˆäº¤é‡å‡çº¿è®¡ç®—å®Œæˆ: ç¬¬1å¤©{result_df['volume_ma20'].iloc[0]:.0f}")
            
            # æ·»åŠ å‰ä¸€æ—¥æ”¶ç›˜ä»·
            result_df['prev_close'] = result_df['close'].shift(1)
            
            # è®¡ç®—æ¶¨è·Œå¹…
            result_df['pct_change'] = result_df['close'].pct_change()
            
            # åˆå¹¶è´¢åŠ¡æ•°æ®
            result_df = self._merge_financial_data(result_df, stock_code, start_date, end_date)
            
            # æ·»åŠ åˆ°ç¼“å­˜
            self.data_cache[cache_key] = result_df.copy()
            
            self.logger.info(f"æˆåŠŸåŠ è½½è‚¡ç¥¨ {stock_code} æ•°æ®: {len(result_df)} æ¡è®°å½•")
            return result_df
            
        except Exception as e:
            self.logger.error(f"åŠ è½½è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
    
    def load_market_data(self, 
                        stock_codes: List[str], 
                        start_date: str, 
                        end_date: str,
                        max_stocks: int = 100,
                        strategy_scorer=None) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡åŠ è½½å¤šåªè‚¡ç¥¨çš„å†å²æ•°æ®
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_stocks: æœ€å¤§è‚¡ç¥¨æ•°é‡
            strategy_scorer: ç­–ç•¥è¯„åˆ†å‡½æ•°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è‚¡ç¥¨ä»£ç åˆ°æ•°æ®çš„æ˜ å°„å­—å…¸
        """
        market_data = {}
        
        # å¦‚æœæä¾›äº†ç­–ç•¥è¯„åˆ†å‡½æ•°ï¼Œä½¿ç”¨è¯„åˆ†é€‰æ‹©è‚¡ç¥¨
        if strategy_scorer and len(stock_codes) > max_stocks:
            self.logger.info(f"ä½¿ç”¨ç­–ç•¥è¯„åˆ†é€‰æ‹©æœ€ä¼˜ {max_stocks} åªè‚¡ç¥¨...")
            selected_stocks = self._select_stocks_by_strategy_score(
                stock_codes, start_date, end_date, max_stocks, strategy_scorer
            )
        else:
            # å¦åˆ™ä½¿ç”¨åˆ†å±‚é‡‡æ ·ç¡®ä¿ä¸åŒæ¿å—çš„è‚¡ç¥¨
            selected_stocks = self._select_stocks_by_sampling(stock_codes, max_stocks)
        
        self.logger.info(f"å¼€å§‹åŠ è½½ {len(selected_stocks)} åªè‚¡ç¥¨çš„å†å²æ•°æ®...")
        
        success_count = 0
        for i, stock_code in enumerate(selected_stocks):
            try:
                df = self.load_stock_data(
                    stock_code=stock_code,
                    start_date=start_date,
                    end_date=end_date,
                    include_indicators=True
                )
                
                if not df.empty and len(df) > 20:  # è‡³å°‘éœ€è¦20ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                    market_data[stock_code] = df
                    success_count += 1
                    
                    if (i + 1) % 10 == 0:  # æ¯10åªè‚¡ç¥¨è¾“å‡ºä¸€æ¬¡è¿›åº¦
                        self.logger.info(f"è¿›åº¦: {i+1}/{len(selected_stocks)}, æˆåŠŸ: {success_count}")
                else:
                    self.logger.warning(f"è‚¡ç¥¨ {stock_code} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                    
            except Exception as e:
                self.logger.error(f"åŠ è½½è‚¡ç¥¨ {stock_code} å¤±è´¥: {e}")
                continue
        
        self.logger.info(f"æ•°æ®åŠ è½½å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(selected_stocks)}")
        return market_data
    
    def get_trading_dates(self, start_date: str, end_date: str) -> List[str]:
        """
        è·å–æŒ‡å®šæœŸé—´çš„äº¤æ˜“æ—¥åˆ—è¡¨
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            äº¤æ˜“æ—¥åˆ—è¡¨
        """
        try:
            # ä»æ•°æ®åº“è·å–äº¤æ˜“æ—¥å†
            collection = self.db_handler.get_collection(self.db_config.factor_collection)
            
            start_date_str = start_date.replace('-', '')
            end_date_str = end_date.replace('-', '')
            
            # æŸ¥è¯¢æŒ‡å®šæœŸé—´çš„æ‰€æœ‰äº¤æ˜“æ—¥
            pipeline = [
                {
                    '$match': {
                        'trade_date': {
                            '$gte': start_date_str,
                            '$lte': end_date_str
                        }
                    }
                },
                {
                    '$group': {
                        '_id': '$trade_date'
                    }
                },
                {
                    '$sort': {'_id': 1}
                }
            ]
            
            cursor = collection.aggregate(pipeline)
            trading_dates = []
            
            for doc in cursor:
                date_str = doc['_id']
                formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
                trading_dates.append(formatted_date)
            
            self.logger.info(f"è·å–äº¤æ˜“æ—¥: {len(trading_dates)} å¤©")
            return trading_dates
            
        except Exception as e:
            self.logger.error(f"è·å–äº¤æ˜“æ—¥å¤±è´¥: {e}")
            # è¿”å›ç®€å•çš„å·¥ä½œæ—¥åˆ—è¡¨ä½œä¸ºå¤‡é€‰
            date_range = pd.date_range(start_date, end_date, freq='B')  # Bè¡¨ç¤ºå·¥ä½œæ—¥
            return [date.strftime('%Y-%m-%d') for date in date_range]
    
    def _select_stocks_by_strategy_score(self, stock_codes: List[str], start_date: str, 
                                       end_date: str, max_stocks: int, strategy_scorer) -> List[str]:
        """
        åŸºäºç­–ç•¥è¯„åˆ†é€‰æ‹©è‚¡ç¥¨
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_stocks: æœ€å¤§è‚¡ç¥¨æ•°é‡
            strategy_scorer: ç­–ç•¥è¯„åˆ†å‡½æ•°
            
        Returns:
            é€‰ä¸­çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        self.logger.info("æ­£åœ¨è®¡ç®—è‚¡ç¥¨ç­–ç•¥è¯„åˆ†...")
        stock_scores = []
        
        # è·å–è¯„åˆ†è®¡ç®—çš„å‚è€ƒæ—¥æœŸï¼ˆå¼€å§‹æ—¥æœŸå60å¤©ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ï¼‰
        from datetime import datetime, timedelta
        score_date = (datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=60)).strftime('%Y-%m-%d')
        
        # æ‰©å¤§æ•°æ®åŠ è½½èŒƒå›´ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿçš„æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        score_start_date = (datetime.strptime(start_date, '%Y-%m-%d') - timedelta(days=60)).strftime('%Y-%m-%d')
        
        # ä¸ºæ¯åªè‚¡ç¥¨è®¡ç®—è¯„åˆ†
        for i, stock_code in enumerate(stock_codes):
            try:
                # åŠ è½½è‚¡ç¥¨æ•°æ®ç”¨äºè¯„åˆ†ï¼ˆæ‰©å¤§èŒƒå›´ä»¥ç¡®ä¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æ­£ç¡®ï¼‰
                stock_data_df = self.load_stock_data(stock_code, score_start_date, score_date, include_indicators=True)
                
                if not stock_data_df.empty and len(stock_data_df) > 20:
                    # è·å–è¯„åˆ†æ—¥æœŸçš„æ•°æ®
                    score_date_data = self.get_stock_data_on_date(stock_code, score_date, {stock_code: stock_data_df})
                    
                    if score_date_data:
                        # è®¡ç®—ç­–ç•¥è¯„åˆ†
                        score = strategy_scorer(stock_code, score_date_data)
                        # è®°å½•æ‰€æœ‰è¯„åˆ†ï¼Œä¸ç®¡æ˜¯å¦æ»¡è¶³ä¹°å…¥æ¡ä»¶
                        stock_scores.append((stock_code, score))
                        if len(stock_scores) <= 10:  # è®°å½•å‰10ä¸ªè¯„åˆ†ç”¨äºè°ƒè¯•
                            self.logger.info(f"è‚¡ç¥¨ {stock_code} è¯„åˆ†: {score:.2f}")
                    else:
                        self.logger.debug(f"è‚¡ç¥¨ {stock_code} åœ¨ {score_date} æ— æ•°æ®")
                
                if (i + 1) % 50 == 0:
                    self.logger.info(f"è¯„åˆ†è¿›åº¦: {i+1}/{len(stock_codes)}")
                
            except Exception as e:
                self.logger.warning(f"è‚¡ç¥¨ {stock_code} è¯„åˆ†å¤±è´¥: {e}")
                import traceback
                self.logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
                continue
        
        # æŒ‰è¯„åˆ†æ’åºï¼Œé€‰æ‹©æœ€é«˜åˆ†çš„è‚¡ç¥¨
        stock_scores.sort(key=lambda x: x[1], reverse=True)
        selected_stocks = [stock_code for stock_code, score in stock_scores[:max_stocks]]
        
        self.logger.info(f"ç­–ç•¥è¯„åˆ†å®Œæˆï¼Œé€‰æ‹©äº† {len(selected_stocks)} åªæœ€ä¼˜è‚¡ç¥¨")
        if stock_scores:
            self.logger.info(f"æœ€é«˜è¯„åˆ†: {stock_scores[0][1]:.2f} ({stock_scores[0][0]})")
            if len(stock_scores) > 1:
                self.logger.info(f"æœ€ä½è¯„åˆ†: {stock_scores[-1][1]:.2f} ({stock_scores[-1][0]})")
        
        # å¦‚æœé€‰ä¸­çš„è‚¡ç¥¨å¤ªå°‘ï¼ˆå°‘äºç›®æ ‡çš„1/4ï¼‰ï¼Œå›é€€åˆ°åˆ†å±‚é‡‡æ ·
        if len(selected_stocks) < max_stocks // 4:
            self.logger.warning(f"ç­–ç•¥è¯„åˆ†ä»…é€‰ä¸­ {len(selected_stocks)} åªè‚¡ç¥¨ï¼Œå°‘äºç›®æ ‡çš„25%ï¼Œå›é€€åˆ°åˆ†å±‚é‡‡æ ·")
            return self._select_stocks_by_sampling(stock_codes, max_stocks)
        
        return selected_stocks
    
    def _select_stocks_by_sampling(self, stock_codes: List[str], max_stocks: int) -> List[str]:
        """
        åˆ†å±‚é‡‡æ ·é€‰æ‹©è‚¡ç¥¨ï¼Œç¡®ä¿ä¸åŒæ¿å—çš„ä»£è¡¨æ€§
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            max_stocks: æœ€å¤§è‚¡ç¥¨æ•°é‡
            
        Returns:
            é€‰ä¸­çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        if len(stock_codes) <= max_stocks:
            return stock_codes
        
        # æŒ‰å‰ç¼€åˆ†ç»„ï¼ˆ000=æ·±ä¸»æ¿, 001=æ·±ä¸»æ¿, 002=ä¸­å°æ¿, 003=åˆ›ä¸šæ¿, 600-603=æ²ªä¸»æ¿, 688=ç§‘åˆ›æ¿ç­‰ï¼‰
        stock_groups = {
            '000': [], '001': [], '002': [], '003': [], 
            '600': [], '601': [], '602': [], '603': [], '688': []
        }
        
        for stock_code in stock_codes:
            prefix = stock_code[:3]
            if prefix in stock_groups:
                stock_groups[prefix].append(stock_code)
            else:
                # å…¶ä»–å‰ç¼€å½’å…¥600ç»„
                stock_groups['600'].append(stock_code)
        
        # è®¡ç®—æ¯ç»„åº”é€‰æ‹©çš„æ•°é‡
        selected_stocks = []
        total_stocks = sum(len(stocks) for stocks in stock_groups.values() if stocks)
        
        for prefix, stocks in stock_groups.items():
            if not stocks:
                continue
                
            # æŒ‰æ¯”ä¾‹åˆ†é…ï¼Œç¡®ä¿æ¯ç»„è‡³å°‘æœ‰1åªè‚¡ç¥¨ï¼ˆå¦‚æœè¯¥ç»„æœ‰è‚¡ç¥¨çš„è¯ï¼‰
            group_quota = max(1, int(len(stocks) / total_stocks * max_stocks))
            group_quota = min(group_quota, len(stocks))
            
            # å‡åŒ€é‡‡æ ·
            step = len(stocks) // group_quota if group_quota > 0 else 1
            selected_from_group = [stocks[i * step] for i in range(group_quota)]
            selected_stocks.extend(selected_from_group)
            
            if len(selected_stocks) >= max_stocks:
                break
        
        # å¦‚æœè¿˜æ²¡è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œéšæœºè¡¥å……
        if len(selected_stocks) < max_stocks:
            remaining_stocks = [s for s in stock_codes if s not in selected_stocks]
            import random
            random.seed(42)  # å›ºå®šç§å­ä¿è¯å¯é‡å¤æ€§
            additional_stocks = random.sample(
                remaining_stocks, 
                min(max_stocks - len(selected_stocks), len(remaining_stocks))
            )
            selected_stocks.extend(additional_stocks)
        
        return selected_stocks[:max_stocks]
    
    def get_stock_data_on_date(self, 
                              stock_code: str, 
                              date: str, 
                              market_data: Dict[str, pd.DataFrame]) -> Optional[Dict]:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸ
            market_data: å¸‚åœºæ•°æ®
            
        Returns:
            è‚¡ç¥¨å½“æ—¥æ•°æ®å­—å…¸
        """
        if stock_code not in market_data:
            return None
        
        df = market_data[stock_code]
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        try:
            target_date = pd.to_datetime(date)
            
            # æŸ¥æ‰¾æœ€æ¥è¿‘çš„äº¤æ˜“æ—¥æ•°æ®
            if target_date in df.index:
                row = df.loc[target_date]
                data_dict = row.to_dict()
                
                # è°ƒè¯•è¾“å‡º
                if stock_code in ['002003.SZ', '600761.SH'] and date in ['2021-01-04', '2021-01-05']:
                    print(f"ğŸ” {stock_code} {date} æ•°æ®å­—å…¸æ£€æŸ¥:")
                    print(f"   ma20: {data_dict.get('ma20', 'N/A')} (ç±»å‹: {type(data_dict.get('ma20'))})")
                    print(f"   ma5: {data_dict.get('ma5', 'N/A')} (ç±»å‹: {type(data_dict.get('ma5'))})")
                    print(f"   volume_ma20: {data_dict.get('volume_ma20', 'N/A')} (ç±»å‹: {type(data_dict.get('volume_ma20'))})")
                    print(f"   DataFrameåˆ—: {list(df.columns)}")
                    print(f"   DataFrameä¸­ma20å€¼: {row.get('ma20', 'N/A')}")
                
                return data_dict
            else:
                # æ‰¾åˆ°æœ€è¿‘çš„äº¤æ˜“æ—¥
                valid_dates = df.index[df.index <= target_date]
                if len(valid_dates) > 0:
                    latest_date = valid_dates.max()
                    row = df.loc[latest_date]
                    return row.to_dict()
                else:
                    return None
                    
        except Exception as e:
            self.logger.error(f"è·å–è‚¡ç¥¨ {stock_code} åœ¨ {date} çš„æ•°æ®å¤±è´¥: {e}")
            return None
    
    def validate_data_quality(self, market_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """
        éªŒè¯æ•°æ®è´¨é‡
        
        Args:
            market_data: å¸‚åœºæ•°æ®
            
        Returns:
            æ•°æ®è´¨é‡æŠ¥å‘Š
        """
        report = {
            'total_stocks': len(market_data),
            'stock_details': {},
            'overall_quality': 'good'
        }
        
        issues = []
        
        for stock_code, df in market_data.items():
            stock_report = {
                'total_days': len(df),
                'missing_data_days': 0,
                'zero_volume_days': 0,
                'abnormal_price_days': 0,
                'quality_score': 100
            }
            
            # æ£€æŸ¥ç¼ºå¤±æ•°æ®
            missing_data = df[['open', 'high', 'low', 'close', 'volume']].isnull().any(axis=1).sum()
            stock_report['missing_data_days'] = missing_data
            
            # æ£€æŸ¥é›¶æˆäº¤é‡
            zero_volume = (df['volume'] == 0).sum()
            stock_report['zero_volume_days'] = zero_volume
            
            # æ£€æŸ¥å¼‚å¸¸ä»·æ ¼ï¼ˆå¦‚è´Ÿä»·æ ¼ï¼‰
            abnormal_price = ((df['open'] <= 0) | (df['high'] <= 0) | 
                            (df['low'] <= 0) | (df['close'] <= 0)).sum()
            stock_report['abnormal_price_days'] = abnormal_price
            
            # è®¡ç®—è´¨é‡å¾—åˆ†
            total_issues = missing_data + zero_volume + abnormal_price
            if len(df) > 0:
                quality_score = max(0, 100 - (total_issues / len(df)) * 100)
                stock_report['quality_score'] = quality_score
                
                if quality_score < 90:
                    issues.append(f"{stock_code}: è´¨é‡å¾—åˆ† {quality_score:.1f}")
            
            report['stock_details'][stock_code] = stock_report
        
        # æ•´ä½“è´¨é‡è¯„ä¼°
        avg_quality = np.mean([details['quality_score'] for details in report['stock_details'].values()])
        if avg_quality >= 95:
            report['overall_quality'] = 'excellent'
        elif avg_quality >= 90:
            report['overall_quality'] = 'good'
        elif avg_quality >= 80:
            report['overall_quality'] = 'fair'
        else:
            report['overall_quality'] = 'poor'
        
        report['avg_quality_score'] = avg_quality
        report['issues'] = issues
        
        return report
    
    def _merge_financial_data(self, result_df: pd.DataFrame, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """åˆå¹¶è´¢åŠ¡æ•°æ®åˆ°è‚¡ç¥¨æ•°æ®ä¸­ - ç”¨äºé€‰è‚¡è€Œéäº¤æ˜“ä¿¡å·"""
        try:
            # è·å–è´¢åŠ¡æ•°æ®é›†åˆ
            fina_collection = self.db_handler.get_collection(self.db_config.financial_indicator_collection)
            
            # æŸ¥è¯¢è´¢åŠ¡æ•°æ®ï¼ˆè·å–å†å²è´¢åŠ¡æ•°æ®ç”¨äºé€‰è‚¡ï¼‰
            from datetime import datetime, timedelta
            start_dt = datetime.strptime(start_date, '%Y-%m-%d')
            # å‘å‰æ‰©å±•1å¹´ä»¥è·å–è¶³å¤Ÿçš„è´¢åŠ¡æ•°æ®ç”¨äºé€‰è‚¡
            extended_start = start_dt - timedelta(days=365)
            
            extended_start_str = extended_start.strftime('%Y%m%d')
            
            # æŸ¥è¯¢é€»è¾‘ï¼šè·å–åœ¨å›æµ‹å¼€å§‹å‰å·²å…¬å‘Šçš„æ‰€æœ‰è´¢åŠ¡æ•°æ®
            query = {
                'ts_code': stock_code,
                'ann_date': {'$lt': start_date.replace('-', '')}  # åªè¦å›æµ‹å¼€å§‹å‰å·²å…¬å‘Šçš„æ•°æ®
            }
            
            # è°ƒè¯•è¾“å‡º
            if stock_code in ['000012.SZ', '002003.SZ']:
                print(f"ğŸ” {stock_code} è´¢åŠ¡æŸ¥è¯¢: {query}")
                # æŸ¥çœ‹æœ‰å¤šå°‘æ•°æ®
                count = fina_collection.count_documents(query)
                print(f"   åŒ¹é…è´¢åŠ¡è®°å½•æ•°: {count}")
                # æŸ¥çœ‹æ‰€æœ‰æ•°æ®çš„ann_dateèŒƒå›´
                all_query = {'ts_code': stock_code}
                sample = fina_collection.find(all_query, {'ann_date': 1, 'end_date': 1}).sort('ann_date', -1).limit(3)
                print(f"   æœ€æ–°3æ¡ann_date: {[doc for doc in sample]}")
            
            # è´¢åŠ¡æŒ‡æ ‡å­—æ®µ
            financial_fields = {
                'eps': 'eps',
                'bps': 'bps', 
                'roe': 'roe',
                'roa': 'roa_yearly',
                'debt_to_assets': 'debt_to_assets',
                'revenue_ps': 'revenue_ps',
                'netprofit_margin': 'netprofit_margin',
                'assets_turn': 'assets_turn',
                'current_ratio': 'current_ratio',
                'quick_ratio': 'quick_ratio'
            }
            
            # æ„å»ºæŸ¥è¯¢å­—æ®µ
            projection = {'ts_code': 1, 'end_date': 1, 'ann_date': 1}
            for alias, field in financial_fields.items():
                projection[field] = 1
            
            cursor = fina_collection.find(query, projection).sort('end_date', -1).limit(1)
            financial_data = list(cursor)
            
            if not financial_data:
                self.logger.debug(f"è‚¡ç¥¨ {stock_code} æ— è´¢åŠ¡æ•°æ®ç”¨äºé€‰è‚¡")
                # å¦‚æœæ²¡æœ‰è´¢åŠ¡æ•°æ®ï¼Œæ·»åŠ ç©ºåˆ—
                for alias in financial_fields.keys():
                    result_df[alias] = np.nan
                return result_df
            
            # è·å–æœ€æ–°çš„è´¢åŠ¡æ•°æ®ï¼ˆç”¨äºæ•´ä¸ªå›æµ‹æœŸé—´çš„é€‰è‚¡ï¼‰
            latest_financial = financial_data[0]
            
            # å°†è´¢åŠ¡æ•°æ®å¡«å……åˆ°æ‰€æœ‰äº¤æ˜“æ—¥ï¼ˆå› ä¸ºåªç”¨äºé€‰è‚¡ï¼Œä¸éœ€è¦æ—¶é—´å˜åŒ–ï¼‰
            for alias, field in financial_fields.items():
                if field in latest_financial:
                    value = latest_financial[field]
                    if value is not None:
                        result_df[alias] = pd.to_numeric(value, errors='coerce')
                    else:
                        result_df[alias] = np.nan
                else:
                    result_df[alias] = np.nan
            
            self.logger.debug(f"è‚¡ç¥¨ {stock_code} è´¢åŠ¡æ•°æ®å·²åŠ è½½ï¼Œç”¨äºé€‰è‚¡")
            return result_df
            
        except Exception as e:
            self.logger.warning(f"åˆå¹¶è´¢åŠ¡æ•°æ®å¤±è´¥ {stock_code}: {e}")
            # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œæ·»åŠ ç©ºçš„è´¢åŠ¡æ•°æ®åˆ—
            financial_fields = ['eps', 'bps', 'roe', 'roa', 'debt_to_assets', 'revenue_ps', 
                              'netprofit_margin', 'assets_turn', 'current_ratio', 'quick_ratio']
            for field in financial_fields:
                result_df[field] = np.nan
            return result_df
    
    def clear_cache(self):
        """æ¸…ç†æ•°æ®ç¼“å­˜"""
        self.data_cache.clear()
        self.logger.info("æ•°æ®ç¼“å­˜å·²æ¸…ç†")


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®ç®¡ç†å™¨
    print("ğŸš€ æµ‹è¯•æ•°æ®ç®¡ç†å™¨...")
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    data_manager = DataManager()
    
    # æµ‹è¯•åŠ è½½è‚¡ç¥¨æ± 
    stock_universe = data_manager.load_stock_universe()
    print(f"è‚¡ç¥¨æ± å¤§å°: {len(stock_universe)}")
    print(f"å‰10åªè‚¡ç¥¨: {stock_universe[:10]}")
    
    # æµ‹è¯•åŠ è½½å•åªè‚¡ç¥¨æ•°æ®
    if stock_universe:
        test_stock = stock_universe[0]
        df = data_manager.load_stock_data(
            stock_code=test_stock,
            start_date='2024-01-01',
            end_date='2024-12-31',
            include_indicators=True
        )
        
        if not df.empty:
            print(f"\n{test_stock} æ•°æ®æ¦‚è§ˆ:")
            print(f"æ•°æ®è¡Œæ•°: {len(df)}")
            print(f"æ•°æ®åˆ—æ•°: {len(df.columns)}")
            print(f"æ—¥æœŸèŒƒå›´: {df.index.min()} åˆ° {df.index.max()}")
            print(f"æ•°æ®åˆ—: {list(df.columns)}")
            print("\næœ€æ–°5å¤©æ•°æ®:")
            print(df.tail())
    
    print("âœ… æ•°æ®ç®¡ç†å™¨æµ‹è¯•å®Œæˆ")