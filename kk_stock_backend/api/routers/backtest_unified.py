#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€å›æµ‹APIæ¥å£
æä¾›ç­–ç•¥å›æµ‹ã€å®æ—¶æ•°æ®æ¨é€ã€å‚æ•°é…ç½®ã€ç»“æœåˆ†æç­‰åŠŸèƒ½
åˆå¹¶äº†åŸæœ‰çš„ backtest.py å’Œ backtest_realtime.py
"""

from fastapi import APIRouter, HTTPException, Query, Body, BackgroundTasks, Depends, WebSocket, WebSocketDisconnect
from fastapi.responses import StreamingResponse
from typing import List, Optional, Dict, Any, Union
from pydantic import BaseModel, Field, validator
from datetime import datetime, date
import logging
import uuid
import asyncio
import json
import os
import sys
import jwt
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥å›æµ‹æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
api_dir = os.path.dirname(current_dir)
project_root = os.path.dirname(api_dir)
sys.path.insert(0, project_root)

load_dotenv()

# JWTé…ç½®
SECRET_KEY = os.getenv("JWT_SECRET_KEY", "your_secret_key")
ALGORITHM = "HS256"

try:
    from api.cache_middleware import cache_endpoint
    HAS_CACHE = True
except ImportError:
    HAS_CACHE = False
    def cache_endpoint(data_type='', ttl=3600):
        def decorator(func):
            return func
        return decorator

try:
    HAS_DB_HANDLER = True
except ImportError:
    HAS_DB_HANDLER = False

try:
    from routers.user import get_current_user
    HAS_USER_AUTH = True
except ImportError:
    HAS_USER_AUTH = False
    async def get_current_user():
        return {"user_id": "anonymous", "role": "user"}

def get_user_dependency():
    """æ ¹æ®è®¤è¯å¯ç”¨æ€§è¿”å›ç”¨æˆ·ä¾èµ–"""
    if HAS_USER_AUTH:
        return Depends(get_current_user)
    else:
        # è¿”å›ä¸€ä¸ªç›´æ¥è¿”å›åŒ¿åç”¨æˆ·çš„ä¾èµ–
        def anonymous_user():
            return {"user_id": "anonymous", "role": "user"}
        return Depends(anonymous_user)

# å…¨å±€ä»»åŠ¡å­˜å‚¨ - ç”¨äºå®æ—¶ä»»åŠ¡çŠ¶æ€å’Œæ•°æ®ç®¡ç†
active_tasks: Dict[str, Dict[str, Any]] = {}

# WebSocketè¿æ¥ç®¡ç†å™¨
class WebSocketConnectionManager:
    """WebSocketè¿æ¥ç®¡ç†å™¨"""
    def __init__(self):
        self.active_connections: Dict[str, List[WebSocket]] = {}
        self.task_connections: Dict[str, List[WebSocket]] = {}
    
    async def connect(self, websocket: WebSocket, task_id: str = None):
        """å»ºç«‹WebSocketè¿æ¥"""
        await websocket.accept()
        connection_id = str(uuid.uuid4())
        
        if connection_id not in self.active_connections:
            self.active_connections[connection_id] = []
        self.active_connections[connection_id].append(websocket)
        
        if task_id:
            if task_id not in self.task_connections:
                self.task_connections[task_id] = []
            self.task_connections[task_id].append(websocket)
            logger.info(f"WebSocketè¿æ¥å·²å»ºç«‹: task_id={task_id}, connection_id={connection_id}")
        else:
            logger.info(f"WebSocketè¿æ¥å·²å»ºç«‹: connection_id={connection_id}")
        
        return connection_id
    
    def disconnect(self, websocket: WebSocket, task_id: str = None):
        """æ–­å¼€WebSocketè¿æ¥"""
        # ä»æ´»è·ƒè¿æ¥ä¸­ç§»é™¤
        for conn_id, connections in self.active_connections.items():
            if websocket in connections:
                connections.remove(websocket)
                if not connections:
                    del self.active_connections[conn_id]
                break
        
        # ä»ä»»åŠ¡è¿æ¥ä¸­ç§»é™¤
        if task_id and task_id in self.task_connections:
            if websocket in self.task_connections[task_id]:
                self.task_connections[task_id].remove(websocket)
                if not self.task_connections[task_id]:
                    del self.task_connections[task_id]
                logger.info(f"WebSocketè¿æ¥å·²æ–­å¼€: task_id={task_id}")
    
    async def send_personal_message(self, message: Dict[str, Any], websocket: WebSocket):
        """å‘é€ä¸ªäººæ¶ˆæ¯"""
        try:
            await websocket.send_text(json.dumps(message))
        except Exception as e:
            logger.error(f"å‘é€WebSocketæ¶ˆæ¯å¤±è´¥: {e}")
    
    async def broadcast_to_task(self, message: Dict[str, Any], task_id: str):
        """å‘æŒ‡å®šä»»åŠ¡çš„æ‰€æœ‰è¿æ¥å¹¿æ’­æ¶ˆæ¯"""
        if task_id in self.task_connections:
            disconnected = []
            for websocket in self.task_connections[task_id]:
                try:
                    await websocket.send_text(json.dumps(message))
                except Exception as e:
                    logger.error(f"WebSocketå¹¿æ’­å¤±è´¥: {e}")
                    disconnected.append(websocket)
            
            # æ¸…ç†æ–­å¼€çš„è¿æ¥
            for websocket in disconnected:
                self.disconnect(websocket, task_id)
    
    def get_task_connection_count(self, task_id: str) -> int:
        """è·å–ä»»åŠ¡çš„è¿æ¥æ•°é‡"""
        return len(self.task_connections.get(task_id, []))

# å…¨å±€WebSocketç®¡ç†å™¨å®ä¾‹
ws_manager = WebSocketConnectionManager()

# æ—¥å¿—é…ç½®
logger = logging.getLogger(__name__)

# =============================================================================
# æ•°æ®æ¨¡å‹å®šä¹‰
# =============================================================================

class TradingConfig(BaseModel):
    """äº¤æ˜“é…ç½®å‚æ•°"""
    commission_rate: float = Field(default=0.0001, description="æ‰‹ç»­è´¹ç‡")
    stamp_tax_rate: float = Field(default=0.001, description="å°èŠ±ç¨ç‡")
    min_commission: float = Field(default=5.0, description="æœ€å°æ‰‹ç»­è´¹")

class RiskConfig(BaseModel):
    """é£é™©æ§åˆ¶é…ç½®"""
    max_positions: int = Field(default=10, description="æœ€å¤§æŒä»“æ•°é‡")
    max_single_position: float = Field(default=0.1, description="å•ä¸ªè‚¡ç¥¨æœ€å¤§ä»“ä½")
    stop_loss_pct: float = Field(default=0.1, description="æ­¢æŸç™¾åˆ†æ¯”")
    take_profit_pct: float = Field(default=0.15, description="æ­¢ç›ˆç™¾åˆ†æ¯”")
    max_drawdown_limit: float = Field(default=0.2, description="æœ€å¤§å›æ’¤é™åˆ¶")

class MultiTrendParams(BaseModel):
    """å¤šè¶‹åŠ¿å…±æŒ¯ç­–ç•¥å‚æ•°"""
    sma_short: int = Field(default=5, description="çŸ­æœŸå‡çº¿å‘¨æœŸ")
    sma_medium: int = Field(default=20, description="ä¸­æœŸå‡çº¿å‘¨æœŸ")
    sma_long: int = Field(default=60, description="é•¿æœŸå‡çº¿å‘¨æœŸ")
    rsi_period: int = Field(default=14, description="RSIå‘¨æœŸ")
    rsi_oversold: float = Field(default=30, description="RSIè¶…å–é˜ˆå€¼")
    rsi_overbought: float = Field(default=70, description="RSIè¶…ä¹°é˜ˆå€¼")
    min_resonance_score: float = Field(default=6.0, description="æœ€å°å…±æŒ¯åˆ†æ•°")
    volume_ratio_threshold: float = Field(default=1.2, description="æˆäº¤é‡æ¯”ç‡é˜ˆå€¼")

class BollParams(BaseModel):
    """å¸ƒæ—å¸¦ç­–ç•¥å‚æ•°"""
    boll_period: int = Field(default=20, description="å¸ƒæ—å¸¦å‘¨æœŸ")
    boll_std: float = Field(default=2.0, description="å¸ƒæ—å¸¦æ ‡å‡†å·®å€æ•°")
    rsi_period: int = Field(default=14, description="RSIå‘¨æœŸ")
    volume_threshold: float = Field(default=1.5, description="æˆäº¤é‡é˜ˆå€¼")
    volatility_threshold: float = Field(default=0.02, description="æ³¢åŠ¨ç‡é˜ˆå€¼")

class TaiShang3FactorParams(BaseModel):
    """å¤ªä¸Šä¸‰å› å­ç­–ç•¥å‚æ•°"""
    lookback_period: int = Field(default=20, description="å›çœ‹å‘¨æœŸ")
    momentum_weight: float = Field(default=0.4, description="åŠ¨é‡å› å­æƒé‡")
    quality_weight: float = Field(default=0.3, description="è´¨é‡å› å­æƒé‡")
    value_weight: float = Field(default=0.3, description="ä»·å€¼å› å­æƒé‡")

class BacktestConfig(BaseModel):
    """å›æµ‹é…ç½®"""
    strategy_name: str = Field(..., description="ç­–ç•¥åç§°")
    strategy_type: str = Field(..., description="ç­–ç•¥ç±»å‹")
    initial_cash: float = Field(default=1000000.0, description="åˆå§‹èµ„é‡‘")
    start_date: date = Field(..., description="å¼€å§‹æ—¥æœŸ")
    end_date: date = Field(..., description="ç»“æŸæ—¥æœŸ")
    index_code: str = Field(default="000510.CSI", description="æŒ‡æ•°ä»£ç ")
    stock_pool: Optional[List[str]] = Field(default=None, description="è‡ªå®šä¹‰è‚¡ç¥¨æ± ")
    max_stocks: int = Field(default=50, description="æœ€å¤§è‚¡ç¥¨æ•°é‡")
    benchmark: str = Field(default="000300.SH", description="åŸºå‡†æŒ‡æ•°ä»£ç ")
    
    # äº¤æ˜“æˆæœ¬é…ç½® - æ”¯æŒæ‰å¹³åŒ–å‚æ•°ï¼ˆä¼˜å…ˆçº§é«˜äºtrading_configï¼‰
    commission_rate: Optional[float] = Field(default=0.0001, description="æ‰‹ç»­è´¹ç‡")
    stamp_tax_rate: Optional[float] = Field(default=0.001, description="å°èŠ±ç¨ç‡")
    slippage_rate: Optional[float] = Field(default=0.001, description="æ»‘ç‚¹ç‡")
    min_commission: Optional[float] = Field(default=5.0, description="æœ€å°æ‰‹ç»­è´¹")
    
    # åµŒå¥—é…ç½®å¯¹è±¡ï¼ˆå‘åå…¼å®¹ï¼‰
    trading_config: Optional[TradingConfig] = Field(default=None)
    risk_config: RiskConfig = Field(default_factory=RiskConfig)
    strategy_params: Union[MultiTrendParams, BollParams, TaiShang3FactorParams, None] = Field(default=None)

    @validator('end_date')
    def validate_dates(cls, v, values):
        if 'start_date' in values and v <= values['start_date']:
            raise ValueError('ç»“æŸæ—¥æœŸå¿…é¡»å¤§äºå¼€å§‹æ—¥æœŸ')
        return v

class BacktestTask(BaseModel):
    """å›æµ‹ä»»åŠ¡"""
    task_id: str
    user_id: str
    status: str
    progress: float
    message: str
    config: Optional[BacktestConfig] = None
    result: Optional[Dict] = None
    created_at: datetime
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

class BacktestResult(BaseModel):
    """å›æµ‹ç»“æœ"""
    backtest_config: Dict[str, Any]
    strategy_info: Dict[str, Any]
    performance_report: Dict[str, Any]
    portfolio_summary: Dict[str, Any]
    trading_summary: Dict[str, Any]
    chart_files: List[str] = []
    chart_data: Optional[Dict[str, Any]] = None
    benchmark_data: Optional[Dict[str, Any]] = None
    
    class Config:
        # å…è®¸é¢å¤–çš„å­—æ®µï¼Œæé«˜å…¼å®¹æ€§
        extra = "allow"

class StrategyInfo(BaseModel):
    """ç­–ç•¥ä¿¡æ¯"""
    strategy_type: str
    strategy_name: str
    description: str
    default_params: Dict[str, Any]
    param_ranges: Dict[str, Any]

# =============================================================================
# è®¤è¯ç›¸å…³å‡½æ•°
# =============================================================================

async def get_current_user_sse(token: Optional[str] = Query(None, description="è®¤è¯Token")):
    """SSEä¸“ç”¨ç”¨æˆ·éªŒè¯ï¼Œæ”¯æŒæŸ¥è¯¢å‚æ•°ä¼ é€’Token"""
    if not token:
        raise HTTPException(status_code=401, detail="ç¼ºå°‘è®¤è¯Token")
    
    try:
        # å¯¼å…¥MongoDBè¿æ¥é…ç½®
        from .user import users_col
        
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id = payload.get("user_id")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ")
        
        user = users_col.find_one({"user_id": user_id, "status": 1})
        if not user:
            raise HTTPException(status_code=401, detail="ç”¨æˆ·ä¸å­˜åœ¨æˆ–å·²ç¦ç”¨")
        return user
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Tokenå·²è¿‡æœŸ")
    except Exception:
        raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ")

# =============================================================================
# å›æµ‹å¼•æ“ç›¸å…³å‡½æ•°
# =============================================================================

# æ¨¡æ‹Ÿå›æµ‹å¼•æ“å¯¼å…¥
class FallbackBacktestEngine:
    """å›æµ‹å¼•æ“çš„å¤‡ç”¨å®ç°"""
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def run_strategy_backtest(self, *args, **kwargs):
        """æ¨¡æ‹Ÿå›æµ‹æ‰§è¡Œ"""
        raise HTTPException(
            status_code=503, 
            detail="å›æµ‹æ¨¡å—æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
        )

try:
    # å°è¯•å¯¼å…¥å®é™…çš„å›æµ‹æ¨¡å—
    sys.path.append('/Users/libing/kk_Projects/kk_Stock/kk_stock_backend')
    from backtrader_strategies.backtest.backtest_engine import run_strategy_backtest
    HAS_BACKTEST_ENGINE = True
    logger.info("å›æµ‹å¼•æ“æ¨¡å—åŠ è½½æˆåŠŸ")
except Exception as e:
    logger.warning(f"å›æµ‹å¼•æ“æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    HAS_BACKTEST_ENGINE = False
    run_strategy_backtest = FallbackBacktestEngine().run_strategy_backtest

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(tags=["ç»Ÿä¸€å›æµ‹æ¥å£"])

# =============================================================================
# ç­–ç•¥é…ç½®ç›¸å…³å‡½æ•°
# =============================================================================

def get_strategy_class(strategy_type: str):
    """æ ¹æ®ç­–ç•¥ç±»å‹è·å–å¯¹åº”çš„ç­–ç•¥ç±»"""
    try:
        # åŠ¨æ€å¯¼å…¥ç­–ç•¥ç±»
        if strategy_type == 'multi_trend':
            from backtrader_strategies.multi_trend_strategy_adapter import MultiTrendResonanceStrategyAdapter
            return MultiTrendResonanceStrategyAdapter
        elif strategy_type == 'boll':
            from backtrader_strategies.curious_ragdoll_boll_strategy_adapter import CuriousRagdollBollStrategyAdapter
            return CuriousRagdollBollStrategyAdapter
        elif strategy_type == 'taishang_3factor':
            from backtrader_strategies.taishang_3_factor_strategy_adapter import TaiShang3FactorStrategyAdapter
            return TaiShang3FactorStrategyAdapter
        else:
            return None
    except ImportError as e:
        logger.error(f"ç­–ç•¥ç±»å¯¼å…¥å¤±è´¥: {e}")
        return None

def create_strategy_config(config: BacktestConfig):
    """åˆ›å»ºç­–ç•¥é…ç½®å¯¹è±¡"""
    try:
        # å¯¼å…¥Configç±»
        from backtrader_strategies.config import Config
        
        # åˆ›å»ºConfigå®ä¾‹
        strategy_config = Config()
        
        # è®¾ç½®ç­–ç•¥åç§°å’Œç±»å‹
        strategy_config.strategy_name = config.strategy_name
        strategy_config.strategy_type = config.strategy_type
        
        # è®¾ç½®å›æµ‹é…ç½®
        strategy_config.backtest.initial_cash = config.initial_cash
        strategy_config.backtest.start_date = config.start_date.strftime('%Y-%m-%d')
        strategy_config.backtest.end_date = config.end_date.strftime('%Y-%m-%d')
        strategy_config.backtest.index_code = config.index_code
        strategy_config.backtest.max_stocks = config.max_stocks
        
        # è®¾ç½®äº¤æ˜“é…ç½® - ä¼˜å…ˆä½¿ç”¨æ‰å¹³åŒ–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨trading_config
        commission_rate = config.commission_rate if config.commission_rate is not None else (config.trading_config.commission_rate if config.trading_config else 0.0001)
        stamp_tax_rate = config.stamp_tax_rate if config.stamp_tax_rate is not None else (config.trading_config.stamp_tax_rate if config.trading_config else 0.001)
        min_commission = config.min_commission if config.min_commission is not None else (config.trading_config.min_commission if config.trading_config else 5.0)
        slippage_rate = config.slippage_rate if config.slippage_rate is not None else 0.001
        
        strategy_config.backtest.commission_rate = commission_rate
        strategy_config.backtest.stamp_tax_rate = stamp_tax_rate
        strategy_config.backtest.min_commission = min_commission
        strategy_config.backtest.slippage_rate = slippage_rate
        
        # è®¾ç½®é£é™©é…ç½®
        strategy_config.strategy.max_positions = config.risk_config.max_positions
        strategy_config.strategy.max_single_position = config.risk_config.max_single_position
        strategy_config.strategy.stop_loss_pct = config.risk_config.stop_loss_pct
        strategy_config.strategy.take_profit_pct = config.risk_config.take_profit_pct
        strategy_config.strategy.max_drawdown_limit = config.risk_config.max_drawdown_limit
        
        return strategy_config
        
    except ImportError as e:
        logger.error(f"Configç±»å¯¼å…¥å¤±è´¥: {e}")
        # å›é€€åˆ°å­—å…¸æ ¼å¼
        strategy_config = {
            'strategy_name': config.strategy_name,
            'backtest': {
                'initial_cash': config.initial_cash,
                'start_date': config.start_date.strftime('%Y-%m-%d'),
                'end_date': config.end_date.strftime('%Y-%m-%d'),
                'index_code': config.index_code,
                'max_stocks': config.max_stocks
            },
            'trading': {
                'commission_rate': config.commission_rate if config.commission_rate is not None else (config.trading_config.commission_rate if config.trading_config else 0.0001),
                'stamp_tax_rate': config.stamp_tax_rate if config.stamp_tax_rate is not None else (config.trading_config.stamp_tax_rate if config.trading_config else 0.001),
                'min_commission': config.min_commission if config.min_commission is not None else (config.trading_config.min_commission if config.trading_config else 5.0),
                'slippage_rate': config.slippage_rate if config.slippage_rate is not None else 0.001
            },
            'strategy': {
                'max_positions': config.risk_config.max_positions,
                'max_single_position': config.risk_config.max_single_position,
                'stop_loss_pct': config.risk_config.stop_loss_pct,
                'take_profit_pct': config.risk_config.take_profit_pct,
                'max_drawdown_limit': config.risk_config.max_drawdown_limit
            }
        }
    
        # æ·»åŠ ç­–ç•¥ç‰¹å®šå‚æ•°åˆ°å­—å…¸ç‰ˆæœ¬
        if config.strategy_params:
            if config.strategy_type == 'multi_trend' and isinstance(config.strategy_params, MultiTrendParams):
                strategy_config['multi_trend'] = {
                    'sma_short': config.strategy_params.sma_short,
                    'sma_medium': config.strategy_params.sma_medium,
                    'sma_long': config.strategy_params.sma_long,
                    'rsi_period': config.strategy_params.rsi_period,
                    'rsi_oversold': config.strategy_params.rsi_oversold,
                    'rsi_overbought': config.strategy_params.rsi_overbought,
                    'min_score': config.strategy_params.min_resonance_score / 11.0,
                    'volume_ratio_threshold': config.strategy_params.volume_ratio_threshold
                }
            elif config.strategy_type == 'boll' and isinstance(config.strategy_params, BollParams):
                strategy_config['boll'] = {
                    'boll_period': config.strategy_params.boll_period,
                    'boll_std': config.strategy_params.boll_std,
                    'rsi_period': config.strategy_params.rsi_period,
                    'volume_ratio_threshold': config.strategy_params.volume_threshold,
                    'volatility_threshold': config.strategy_params.volatility_threshold
                }
            elif config.strategy_type == 'taishang_3factor' and isinstance(config.strategy_params, TaiShang3FactorParams):
                strategy_config['taishang_3factor'] = {
                    'lookback_period': config.strategy_params.lookback_period,
                    'momentum_weight': config.strategy_params.momentum_weight,
                    'quality_weight': config.strategy_params.quality_weight,
                    'value_weight': config.strategy_params.value_weight
                }
        
        return strategy_config
    
    # å¯¹äºæˆåŠŸåˆ›å»ºçš„Configå¯¹è±¡ï¼Œæ·»åŠ ç­–ç•¥ç‰¹å®šå‚æ•°
    if config.strategy_params:
        if config.strategy_type == 'multi_trend' and isinstance(config.strategy_params, MultiTrendParams):
            strategy_config.multi_trend.sma_short = config.strategy_params.sma_short
            strategy_config.multi_trend.sma_medium = config.strategy_params.sma_medium
            strategy_config.multi_trend.sma_long = config.strategy_params.sma_long
            strategy_config.multi_trend.rsi_period = config.strategy_params.rsi_period
            strategy_config.multi_trend.rsi_oversold = config.strategy_params.rsi_oversold
            strategy_config.multi_trend.rsi_overbought = config.strategy_params.rsi_overbought
            strategy_config.multi_trend.min_score = config.strategy_params.min_resonance_score / 11.0
            strategy_config.multi_trend.volume_ratio_threshold = config.strategy_params.volume_ratio_threshold
        elif config.strategy_type == 'boll' and isinstance(config.strategy_params, BollParams):
            strategy_config.boll.boll_period = config.strategy_params.boll_period
            strategy_config.boll.boll_std = config.strategy_params.boll_std
            strategy_config.boll.rsi_period = config.strategy_params.rsi_period
            strategy_config.boll.volume_ratio_threshold = config.strategy_params.volume_threshold
            strategy_config.boll.volatility_threshold = config.strategy_params.volatility_threshold
        elif config.strategy_type == 'taishang_3factor' and isinstance(config.strategy_params, TaiShang3FactorParams):
            strategy_config.rim_strategy.lookback_period = config.strategy_params.lookback_period
            strategy_config.rim_strategy.momentum_weight = config.strategy_params.momentum_weight
            strategy_config.rim_strategy.quality_weight = config.strategy_params.quality_weight
            strategy_config.rim_strategy.value_weight = config.strategy_params.value_weight
    
    return strategy_config

def get_benchmark_data(benchmark_code: str, start_date: str, end_date: str) -> List[Dict[str, Any]]:
    """
    è·å–åŸºå‡†æŒ‡æ•°æ•°æ®
    
    Args:
        benchmark_code: æŒ‡æ•°ä»£ç ï¼Œå¦‚'000300.SH'
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
    
    Returns:
        åŸºå‡†æŒ‡æ•°æ•°æ®åˆ—è¡¨
    """
    if not HAS_DB_HANDLER:
        logger.warning("æ•°æ®åº“å¤„ç†å™¨ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåŸºå‡†æ•°æ®")
        return []
    
    try:
        collection = db_handler.get_collection('index_daily')
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶ - ä½¿ç”¨å­—ç¬¦ä¸²æ¯”è¾ƒ
        start_date_str = start_date.replace('-', '')
        end_date_str = end_date.replace('-', '')
        
        logger.info(f"æŸ¥è¯¢åŸºå‡†æ•°æ®: {benchmark_code}, æ—¥æœŸèŒƒå›´: {start_date_str} - {end_date_str}")
        
        query = {
            'ts_code': benchmark_code,
            'trade_date': {
                '$gte': start_date_str,
                '$lte': end_date_str
            }
        }
        
        # è·å–æ•°æ®å¹¶æŒ‰æ—¥æœŸæ’åº
        data = list(collection.find(query).sort('trade_date', 1))
        logger.info(f"ä»æ•°æ®åº“è·å–åˆ° {len(data)} æ¡åŸºå‡†æ•°æ®è®°å½•")
        
        # å¤„ç†æ•°æ®ï¼Œè¿”å›æ ‡å‡†æ ¼å¼
        benchmark_data = []
        for item in data:
            try:
                # è®¡ç®—æ”¶ç›Šç‡
                close_price = float(item.get('close', 0))
                prev_close = float(item.get('pre_close', close_price))
                daily_return = (close_price - prev_close) / prev_close if prev_close > 0 else 0
                
                formatted_data = {
                    'date': f"{item['trade_date'][:4]}-{item['trade_date'][4:6]}-{item['trade_date'][6:8]}",
                    'close': close_price,
                    'daily_return': daily_return,
                    'volume': float(item.get('vol', 0))
                }
                benchmark_data.append(formatted_data)
                
                # æ·»åŠ è°ƒè¯•æ—¥å¿—
                if len(benchmark_data) <= 3:
                    logger.info(f"åŸºå‡†æ•°æ®æ ·æœ¬: {formatted_data}")
                    
            except (ValueError, TypeError, KeyError) as e:
                logger.warning(f"å¤„ç†åŸºå‡†æ•°æ®æ—¶å‡ºé”™: {e}, æ•°æ®: {item}")
                continue
        
        logger.info(f"æˆåŠŸè·å–åŸºå‡†æŒ‡æ•°{benchmark_code}æ•°æ®: {len(benchmark_data)}æ¡è®°å½•")
        return benchmark_data
        
    except Exception as e:
        logger.error(f"è·å–åŸºå‡†æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        return []

def calculate_benchmark_returns(benchmark_data: List[Dict[str, Any]]) -> List[float]:
    """
    è®¡ç®—åŸºå‡†æŒ‡æ•°çš„ç´¯è®¡æ”¶ç›Šç‡åºåˆ—
    
    Args:
        benchmark_data: åŸºå‡†æŒ‡æ•°æ•°æ®
        
    Returns:
        ç´¯è®¡æ”¶ç›Šç‡åºåˆ—
    """
    if not benchmark_data:
        logger.warning("åŸºå‡†æ•°æ®ä¸ºç©ºï¼Œè¿”å›ç©ºæ”¶ç›Šç‡åºåˆ—")
        return []
    
    cumulative_returns = []
    cumulative_return = 0.0
    
    logger.info(f"å¼€å§‹è®¡ç®—åŸºå‡†æ”¶ç›Šç‡ï¼Œæ•°æ®ç‚¹æ•°: {len(benchmark_data)}")
    
    for i, data_point in enumerate(benchmark_data):
        daily_return = data_point.get('daily_return', 0)
        cumulative_return = (1 + cumulative_return) * (1 + daily_return) - 1
        cumulative_returns.append(cumulative_return)
        
        # è®°å½•å‰å‡ ä¸ªæ•°æ®ç‚¹çš„è®¡ç®—è¿‡ç¨‹
        if i < 3:
            logger.info(f"åŸºå‡†è®¡ç®—ç¬¬{i+1}å¤©: æ—¥æ”¶ç›Š={daily_return:.6f}, ç´¯è®¡æ”¶ç›Š={cumulative_return:.6f}")
    
    logger.info(f"åŸºå‡†æ”¶ç›Šç‡è®¡ç®—å®Œæˆï¼Œæœ€ç»ˆæ”¶ç›Šç‡: {cumulative_returns[-1]:.6f}")
    return cumulative_returns

# =============================================================================
# å›æµ‹ä»»åŠ¡ç®¡ç†
# =============================================================================

async def run_backtest_task(task_id: str, config: BacktestConfig, user_id: str):
    """è¿è¡Œå›æµ‹ä»»åŠ¡çš„åå°å‡½æ•°"""
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        if task_id in active_tasks:
            active_tasks[task_id].update({
                'status': 'running',
                'started_at': datetime.now(),
                'message': 'å›æµ‹å¼€å§‹æ‰§è¡Œ',
                'progress': 0.0
            })
        
        # åˆ›å»ºç­–ç•¥é…ç½®
        strategy_config = create_strategy_config(config)
        strategy_class = get_strategy_class(config.strategy_type)
        
        if not strategy_class:
            raise ValueError(f"ä¸æ”¯æŒçš„ç­–ç•¥ç±»å‹: {config.strategy_type}")
        
        # æ‰§è¡Œå›æµ‹
        logger.info(f"å¼€å§‹æ‰§è¡Œå›æµ‹ä»»åŠ¡ {task_id}")
        # åˆ›å»ºç­–ç•¥å®ä¾‹
        strategy_instance = strategy_class()
        result = run_strategy_backtest(
            strategy=strategy_instance,
            config=strategy_config,
            task_id=task_id,
            active_tasks=active_tasks  # ä¼ é€’ç»™å›æµ‹å¼•æ“ç”¨äºå®æ—¶æ›´æ–°
        )
        
        # è·å–åŸºå‡†æŒ‡æ•°æ•°æ®å¹¶æ·»åŠ åˆ°ç»“æœä¸­
        try:
            # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„åŸºå‡†æŒ‡æ•°
            benchmark_code = config.benchmark
            logger.info(f"ğŸ¯ å‡†å¤‡è·å–åŸºå‡†æŒ‡æ•°æ•°æ®: {benchmark_code}")
            benchmark_data = get_benchmark_data(
                benchmark_code=benchmark_code,
                start_date=str(config.start_date),
                end_date=str(config.end_date)
            )
            
            if benchmark_data:
                logger.info(f"âœ… æˆåŠŸè·å–åŸºå‡†æ•°æ®: {len(benchmark_data)}æ¡è®°å½•")
                benchmark_returns = calculate_benchmark_returns(benchmark_data)
                final_return = benchmark_returns[-1] if benchmark_returns else 0
                logger.info(f"ğŸ“Š åŸºå‡†æŒ‡æ•°æœ€ç»ˆæ”¶ç›Šç‡: {final_return:.4f} ({final_return*100:.2f}%)")
                
                # æ·»åŠ åŸºå‡†æ•°æ®åˆ°ç»“æœä¸­
                result['benchmark_data'] = {
                    'benchmark_code': benchmark_code,
                    'benchmark_name': benchmark_code,  # ä½¿ç”¨ä»£ç ä½œä¸ºåç§°
                    'data': benchmark_data,
                    'cumulative_returns': benchmark_returns,
                    'final_return': final_return
                }
                logger.info(f"âœ… å·²æ·»åŠ åŸºå‡†æŒ‡æ•°æ•°æ®åˆ°å›æµ‹ç»“æœ: {len(benchmark_returns)}ä¸ªæ”¶ç›Šç‡æ•°æ®ç‚¹")
            else:
                logger.warning("âŒ æœªèƒ½è·å–åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ŒåŸºå‡†æ”¶ç›Šå°†æ˜¾ç¤ºä¸º0")
                
        except Exception as e:
            logger.error(f"å¤„ç†åŸºå‡†æŒ‡æ•°æ•°æ®æ—¶å‡ºé”™: {e}")
        
        # æ›´æ–°ä»»åŠ¡å®ŒæˆçŠ¶æ€
        if task_id in active_tasks:
            active_tasks[task_id].update({
                'status': 'completed',
                'completed_at': datetime.now(),
                'progress': 1.0,
                'message': 'å›æµ‹å®Œæˆ',
                'result': result
            })
            
            # å°è¯•ä»ç»“æœä¸­æå–å’Œå­˜å‚¨ç»“æœç›®å½•è·¯å¾„ä¿¡æ¯
            try:
                if 'chart_data' in result and result['chart_data']:
                    # æ ¹æ®ç­–ç•¥åç§°æ˜ å°„åˆ°å®é™…ç›®å½•å
                    strategy_mapping = {
                        'multi_trend': 'MultiTrendResonanceStrategyAdapter',
                        'boll': 'CuriousRagdollBollStrategyAdapter', 
                        'taishang_3_factor': 'TaiShang3FactorStrategyAdapter'
                    }
                    strategy_name = strategy_mapping.get(config.strategy_type, config.strategy_type)
                    
                    # æŸ¥æ‰¾æœ€æ–°çš„ç»“æœç›®å½•ï¼ˆåŸºäºä¿®æ”¹æ—¶é—´ï¼‰
                    import os
                    import glob
                    results_dir = "/Users/libing/kk_Projects/kk_Stock/kk_stock_backend/results"
                    strategy_dir = os.path.join(results_dir, strategy_name)
                    
                    if os.path.exists(strategy_dir):
                        # è·å–è¯¥ç­–ç•¥ä¸‹æœ€æ–°çš„æ—¶é—´æˆ³ç›®å½•
                        subdirs = [d for d in os.listdir(strategy_dir) if os.path.isdir(os.path.join(strategy_dir, d))]
                        if subdirs:
                            latest_dir = max(subdirs)
                            result_dir_path = os.path.join(strategy_dir, latest_dir)
                            
                            # éªŒè¯è¯¥ç›®å½•æ˜¯å¦åŒ…å«äº¤æ˜“æ–‡ä»¶
                            trades_file = os.path.join(result_dir_path, f"{strategy_name}_trades.csv")
                            if os.path.exists(trades_file):
                                active_tasks[task_id]['result_dir'] = result_dir_path
                                logger.info(f"ğŸ“ å­˜å‚¨ç»“æœç›®å½•è·¯å¾„: {result_dir_path}")
                            
            except Exception as e:
                logger.warning(f"å­˜å‚¨ç»“æœç›®å½•è·¯å¾„å¤±è´¥: {e}")
        
        logger.info(f"å›æµ‹ä»»åŠ¡ {task_id} å®Œæˆ")
        
    except Exception as e:
        logger.error(f"å›æµ‹ä»»åŠ¡ {task_id} å¤±è´¥: {e}")
        if task_id in active_tasks:
            active_tasks[task_id].update({
                'status': 'failed',
                'completed_at': datetime.now(),
                'progress': 0.0,
                'message': f'å›æµ‹å¤±è´¥: {str(e)}'
            })

# =============================================================================
# å®æ—¶æ•°æ®æ¨é€ (SSE)
# =============================================================================

async def sse_generator(task_id: str, data_type: str = "realtime"):
    """SSEæ•°æ®æµç”Ÿæˆå™¨"""
    logger.info(f"å¼€å§‹SSEæµæ¨é€ for task {task_id}, data_type: {data_type}")
    
    # åˆå§‹åŒ–çŠ¶æ€è·Ÿè¸ª
    last_progress_data = None
    last_portfolio_data = None
    last_chart_data = None
    last_trades_count = 0
    
    try:
        while True:
            if task_id not in active_tasks:
                # ä»»åŠ¡ä¸å­˜åœ¨ï¼Œå‘é€é”™è¯¯å¹¶ç»“æŸ
                yield f"event: error\ndata: {json.dumps({'error': 'ä»»åŠ¡ä¸å­˜åœ¨', 'task_id': task_id})}\n\n"
                break
                
            task_info = active_tasks[task_id]
            current_time = datetime.now().isoformat()
            has_new_data = False
            
            if data_type == "progress" or data_type == "realtime":
                # è¿›åº¦æ•°æ® - åªåœ¨å‘ç”Ÿå˜åŒ–æ—¶æ¨é€
                current_progress = {
                    "progress": task_info.get('progress', 0.0),
                    "status": task_info.get('status', 'pending'),
                    "current_date": task_info.get('current_date'),
                    "message": task_info.get('message', ''),
                    "completed_days": task_info.get('completed_days', 0)
                }
                
                # æ£€æŸ¥è¿›åº¦æ˜¯å¦æœ‰å˜åŒ–
                if not last_progress_data or current_progress != last_progress_data:
                    progress_data = {
                        "type": "progress",
                        "task_id": task_id,
                        "status": current_progress['status'],
                        "progress": current_progress['progress'],
                        "message": current_progress['message'],
                        "current_date": current_progress['current_date'],
                        "timestamp": current_time,
                        "processing_speed": task_info.get('processing_speed', 0),
                        "estimated_remaining": task_info.get('estimated_remaining', 0)
                    }
                    yield f"event: progress\ndata: {json.dumps(progress_data)}\n\n"
                    last_progress_data = current_progress
                    has_new_data = True
            
            if data_type == "portfolio" or data_type == "realtime":
                # ç»„åˆæ•°æ® - æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æ—¥æœŸæ•°æ®
                current_portfolio = {
                    "current_date": task_info.get('current_date', ''),
                    "total_value": task_info.get('current_portfolio_value', task_info.get('config', {}).get('initial_cash', 1000000.0)),
                    "total_return": task_info.get('total_return', 0.0),
                    "daily_return": task_info.get('daily_return', 0.0),
                    "drawdown": task_info.get('current_drawdown', 0.0)
                }
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•°æ®ï¼šæ—¥æœŸå˜åŒ–æˆ–æ•°æ®æ›´æ–°æ ‡å¿—
                data_updated_flag = task_info.get('data_updated', False)
                date_changed = (current_portfolio['current_date'] and 
                               (not last_portfolio_data or 
                                current_portfolio['current_date'] != last_portfolio_data.get('current_date')))
                
                if date_changed or data_updated_flag:
                    logger.info(f"ğŸ” æ£€æµ‹åˆ°æ•°æ®å˜åŒ–: date_changed={date_changed}, data_updated_flag={data_updated_flag}, current_date={current_portfolio['current_date']}")
                    
                    portfolio_data = {
                        "type": "portfolio",
                        "task_id": task_id,
                        "timestamp": current_time,
                        "current_date": current_portfolio['current_date'],
                        "portfolio": {
                            "total_value": current_portfolio['total_value'],
                            "cash": task_info.get('current_cash', 0.0),
                            "positions_value": task_info.get('current_positions_value', 0.0),
                            "positions": task_info.get('current_positions', []),
                            "daily_return": current_portfolio['daily_return'],
                            "total_return": current_portfolio['total_return'],
                            "drawdown": current_portfolio['drawdown']
                        }
                    }
                    yield f"event: portfolio\ndata: {json.dumps(portfolio_data)}\n\n"
                    logger.info(f"ğŸ”„ SSEæ¨é€Portfolioæ•°æ®: {current_portfolio['current_date']}, ç»„åˆä»·å€¼: {current_portfolio['total_value']:,.2f}")
                    last_portfolio_data = current_portfolio
                    has_new_data = True
                    # é‡ç½®æ•°æ®æ›´æ–°æ ‡å¿—
                    if 'data_updated' in task_info:
                        task_info['data_updated'] = False
            
            if data_type == "trades" or data_type == "realtime":
                # äº¤æ˜“æ•°æ® - åªåœ¨æœ‰æ–°äº¤æ˜“æ—¶æ¨é€
                current_trades_count = task_info.get('total_trades', 0)
                recent_trades = task_info.get('recent_trades', [])
                
                if current_trades_count > last_trades_count and recent_trades:
                    trades_data = {
                        "type": "trades",
                        "task_id": task_id,
                        "timestamp": current_time,
                        "current_date": task_info.get('current_date', ''),
                        "recent_trades": recent_trades,
                        "trade_stats": {
                            "total_trades": current_trades_count,
                            "buy_trades": task_info.get('buy_trades', 0),
                            "sell_trades": task_info.get('sell_trades', 0),
                            "win_trades": task_info.get('win_trades', 0),
                            "lose_trades": task_info.get('lose_trades', 0),
                            "win_rate": task_info.get('win_rate', 0.0),
                            "total_pnl": task_info.get('total_pnl', 0.0),
                            "avg_win": task_info.get('avg_win', 0.0),
                            "avg_loss": task_info.get('avg_loss', 0.0),
                            "profit_factor": task_info.get('profit_factor', 0.0)
                        }
                    }
                    yield f"event: trades\ndata: {json.dumps(trades_data)}\n\n"
                    last_trades_count = current_trades_count
                    has_new_data = True
            
            if data_type == "chart" or data_type == "realtime":
                # å›¾è¡¨æ•°æ® - æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æ—¥æœŸæ•°æ®ç‚¹
                current_chart_data = {
                    "current_date": task_info.get('current_date', ''),
                    "dates_count": len(task_info.get('date_series', [])),
                    "latest_portfolio_value": task_info.get('portfolio_series', [])[-1] if task_info.get('portfolio_series') else 0
                }
                
                if not last_chart_data or current_chart_data['dates_count'] > last_chart_data.get('dates_count', 0):
                    chart_data = {
                        "type": "chart",
                        "task_id": task_id,
                        "timestamp": current_time,
                        "current_date": current_chart_data['current_date'],
                        "data": {
                            "dates": task_info.get('date_series', []),
                            "portfolio_values": task_info.get('portfolio_series', []),
                            "daily_returns": task_info.get('daily_return_series', []),
                            "cumulative_returns": task_info.get('cumulative_return_series', []),
                            "drawdowns": task_info.get('drawdown_series', [])
                        }
                    }
                    yield f"event: chart\ndata: {json.dumps(chart_data)}\n\n"
                    last_chart_data = current_chart_data
                    has_new_data = True
            
            # æ£€æŸ¥ä»»åŠ¡å®ŒæˆçŠ¶æ€
            status = task_info.get('status', 'pending')
            if status in ['completed', 'failed']:
                # å‘é€æœ€ç»ˆå®Œæˆäº‹ä»¶
                final_data = {
                    "type": "final",
                    "task_id": task_id,
                    "status": status,
                    "timestamp": current_time,
                    "message": task_info.get('message', ''),
                    "result_available": True
                }
                yield f"event: final\ndata: {json.dumps(final_data)}\n\n"
                
                # ç­‰å¾…å®¢æˆ·ç«¯å¤„ç†ï¼Œç„¶åä¼˜é›…å…³é—­
                await asyncio.sleep(3)
                logger.info(f"SSE stream gracefully ended for {status} task {task_id}")
                break
            
            # åŠ¨æ€è°ƒæ•´æ¨é€é¢‘ç‡ï¼šæœ‰æ–°æ•°æ®æ—¶é¢‘ç¹æ¨é€ï¼Œæ— æ–°æ•°æ®æ—¶é™ä½é¢‘ç‡
            if has_new_data:
                await asyncio.sleep(0.05)  # æœ‰æ–°æ•°æ®æ—¶æ¯0.05ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œç¡®ä¿å®æ—¶æ€§
            else:
                await asyncio.sleep(0.5)   # æ— æ–°æ•°æ®æ—¶æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
            
    except asyncio.CancelledError:
        logger.info(f"SSE stream cancelled for task {task_id}")
    except Exception as e:
        logger.error(f"SSE stream error for task {task_id}: {e}")
        yield f"event: error\ndata: {json.dumps({'error': str(e), 'task_id': task_id})}\n\n"

def update_task_realtime_data(task_id: str, update_data: Dict[str, Any]):
    """æ›´æ–°ä»»åŠ¡çš„å®æ—¶æ•°æ®"""
    if task_id in active_tasks:
        active_tasks[task_id].update(update_data)

# =============================================================================
# API ç«¯ç‚¹å®šä¹‰ - åŸºç¡€ç®¡ç†æ¥å£
# =============================================================================

@router.get("/strategies", response_model=List[StrategyInfo])
async def get_available_strategies():
    """è·å–å¯ç”¨ç­–ç•¥åˆ—è¡¨"""
    strategies = [
        {
            "strategy_type": "multi_trend",
            "strategy_name": "å¤šè¶‹åŠ¿å…±æŒ¯ç­–ç•¥",
            "description": "åŸºäºå¤šæ—¶é—´å‘¨æœŸæŠ€æœ¯æŒ‡æ ‡çš„å…±æŒ¯åˆ†æï¼Œé€šè¿‡çŸ­ä¸­é•¿æœŸå‡çº¿ã€RSIã€æˆäº¤é‡ç­‰æŒ‡æ ‡çš„ç»¼åˆåˆ¤æ–­æ¥è¯†åˆ«è¶‹åŠ¿",
            "default_params": {
                "sma_short": 5,
                "sma_medium": 20,
                "sma_long": 60,
                "rsi_period": 14,
                "rsi_oversold": 30,
                "rsi_overbought": 70,
                "min_resonance_score": 6.0,
                "volume_ratio_threshold": 1.2
            },
            "param_ranges": {
                "sma_short": {"min": 3, "max": 10, "step": 1},
                "sma_medium": {"min": 10, "max": 30, "step": 1},
                "sma_long": {"min": 30, "max": 120, "step": 1},
                "rsi_period": {"min": 10, "max": 20, "step": 1},
                "rsi_oversold": {"min": 20, "max": 40, "step": 1},
                "rsi_overbought": {"min": 60, "max": 80, "step": 1},
                "min_resonance_score": {"min": 4.0, "max": 8.0, "step": 0.5},
                "volume_ratio_threshold": {"min": 1.0, "max": 2.0, "step": 0.1}
            }
        },
        {
            "strategy_type": "boll",
            "strategy_name": "å¸ƒæ—å¸¦ç­–ç•¥",
            "description": "åŸºäºå¸ƒæ—å¸¦æŒ‡æ ‡çš„å‡å€¼å›å½’ç­–ç•¥ï¼Œç»“åˆRSIå’Œæˆäº¤é‡æŒ‡æ ‡è¿›è¡Œä¹°å–æ—¶æœºåˆ¤æ–­",
            "default_params": {
                "boll_period": 20,
                "boll_std": 2.0,
                "rsi_period": 14,
                "volume_threshold": 1.5,
                "volatility_threshold": 0.02
            },
            "param_ranges": {
                "boll_period": {"min": 10, "max": 30, "step": 1},
                "boll_std": {"min": 1.5, "max": 3.0, "step": 0.1},
                "rsi_period": {"min": 10, "max": 20, "step": 1},
                "volume_threshold": {"min": 1.0, "max": 3.0, "step": 0.1},
                "volatility_threshold": {"min": 0.01, "max": 0.05, "step": 0.001}
            }
        },
        {
            "strategy_type": "taishang_3factor",
            "strategy_name": "å¤ªä¸Šä¸‰å› å­ç­–ç•¥",
            "description": "åŸºäºåŠ¨é‡ã€è´¨é‡ã€ä»·å€¼ä¸‰ä¸ªå› å­çš„å¤šå› å­é€‰è‚¡ç­–ç•¥ï¼Œé€šè¿‡å› å­åŠ æƒè¯„åˆ†é€‰æ‹©ä¼˜è´¨è‚¡ç¥¨",
            "default_params": {
                "lookback_period": 20,
                "momentum_weight": 0.4,
                "quality_weight": 0.3,
                "value_weight": 0.3
            },
            "param_ranges": {
                "lookback_period": {"min": 10, "max": 60, "step": 1},
                "momentum_weight": {"min": 0.2, "max": 0.6, "step": 0.05},
                "quality_weight": {"min": 0.1, "max": 0.5, "step": 0.05},
                "value_weight": {"min": 0.1, "max": 0.5, "step": 0.05}
            }
        }
    ]
    return strategies

@router.get("/config-templates")
async def get_config_templates():
    """è·å–é…ç½®æ¨¡æ¿"""
    templates = {
        "conservative": {
            "name": "ä¿å®ˆå‹",
            "risk_config": {
                "max_positions": 8,
                "max_single_position": 0.08,
                "stop_loss_pct": 0.08,
                "take_profit_pct": 0.12,
                "max_drawdown_limit": 0.15
            }
        },
        "balanced": {
            "name": "å¹³è¡¡å‹",
            "risk_config": {
                "max_positions": 10,
                "max_single_position": 0.1,
                "stop_loss_pct": 0.1,
                "take_profit_pct": 0.15,
                "max_drawdown_limit": 0.2
            }
        },
        "aggressive": {
            "name": "æ¿€è¿›å‹",
            "risk_config": {
                "max_positions": 12,
                "max_single_position": 0.15,
                "stop_loss_pct": 0.12,
                "take_profit_pct": 0.2,
                "max_drawdown_limit": 0.25
            }
        }
    }
    return templates

@router.post("/run", response_model=BacktestTask)
async def run_backtest(
    config: BacktestConfig = Body(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    current_user: dict = get_user_dependency()
):
    """å¯åŠ¨å›æµ‹ä»»åŠ¡"""
    if not HAS_BACKTEST_ENGINE:
        raise HTTPException(status_code=503, detail="å›æµ‹å¼•æ“æš‚æ—¶ä¸å¯ç”¨")
    
    # ç”Ÿæˆä»»åŠ¡ID
    task_id = str(uuid.uuid4())
    user_id = current_user.get('user_id', 'anonymous')
    
    # è°ƒè¯•ï¼šæ‰“å°æ¥æ”¶åˆ°çš„é…ç½®
    logger.info(f"ğŸ” åç«¯æ¥æ”¶çš„é…ç½®: strategy_name={config.strategy_name}, strategy_type={config.strategy_type}")
    
    # åˆ›å»ºä»»åŠ¡è®°å½•
    task = BacktestTask(
        task_id=task_id,
        user_id=user_id,
        status='pending',
        progress=0.0,
        message='ä»»åŠ¡å·²åˆ›å»ºï¼Œç­‰å¾…æ‰§è¡Œ',
        config=config,
        created_at=datetime.now()
    )
    
    # å­˜å‚¨åˆ°æ´»åŠ¨ä»»åŠ¡ä¸­
    active_tasks[task_id] = {
        'task_id': task_id,
        'user_id': user_id,
        'status': 'pending',
        'progress': 0.0,
        'message': 'ä»»åŠ¡å·²åˆ›å»ºï¼Œç­‰å¾…æ‰§è¡Œ',
        'config': config.dict(),
        'created_at': datetime.now(),
        'started_at': None,
        'completed_at': None,
        'result': None
    }
    
    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(run_backtest_task, task_id, config, user_id)
    
    logger.info(f"åˆ›å»ºå›æµ‹ä»»åŠ¡: {task_id}")
    return task

@router.get("/task/{task_id}", response_model=BacktestTask)
async def get_task_status(task_id: str, current_user: dict = get_user_dependency()):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    if task_id not in active_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    task = active_tasks[task_id]
    user_id = current_user.get('user_id', 'anonymous')
    
    # æ£€æŸ¥æƒé™
    if task['user_id'] != user_id and current_user.get('role') != 'admin':
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    return BacktestTask(**task)

@router.get("/tasks", response_model=Dict[str, Any])
async def get_user_tasks(
    status: Optional[str] = Query(None, description="ä»»åŠ¡çŠ¶æ€è¿‡æ»¤"),
    limit: int = Query(10, ge=1, le=1000, description="è¿”å›æ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡"),
    current_user: dict = get_user_dependency()
):
    """è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨"""
    user_id = current_user.get('user_id', 'anonymous')
    is_admin = current_user.get('role') == 'admin'
    
    # è¿‡æ»¤ç”¨æˆ·çš„ä»»åŠ¡
    user_tasks = []
    for task in active_tasks.values():
        if is_admin or task['user_id'] == user_id:
            if not status or task['status'] == status:
                user_tasks.append(task)
    
    # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åº
    user_tasks.sort(key=lambda x: x['created_at'], reverse=True)
    
    # ç»Ÿè®¡
    stats = {
        'total': len(user_tasks),
        'pending': len([t for t in user_tasks if t['status'] == 'pending']),
        'running': len([t for t in user_tasks if t['status'] == 'running']),
        'completed': len([t for t in user_tasks if t['status'] == 'completed']),
        'failed': len([t for t in user_tasks if t['status'] == 'failed'])
    }
    
    # åˆ†é¡µ
    paginated_tasks = user_tasks[offset:offset + limit]
    
    return {
        'tasks': [BacktestTask(**task) for task in paginated_tasks],
        'total': len(paginated_tasks),
        'total_count': len(user_tasks),
        'stats': stats
    }

@router.delete("/task/{task_id}")
async def delete_task(task_id: str, current_user: dict = get_user_dependency()):
    """åˆ é™¤ä»»åŠ¡"""
    if task_id not in active_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    task = active_tasks[task_id]
    user_id = current_user.get('user_id', 'anonymous')
    
    # æ£€æŸ¥æƒé™
    if task['user_id'] != user_id and current_user.get('role') != 'admin':
        raise HTTPException(status_code=403, detail="æ— æƒåˆ é™¤æ­¤ä»»åŠ¡")
    
    # ä¸èƒ½åˆ é™¤æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
    if task['status'] == 'running':
        raise HTTPException(status_code=400, detail="ä¸èƒ½åˆ é™¤æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡")
    
    # åˆ é™¤ä»»åŠ¡
    del active_tasks[task_id]
    
    return {"message": "ä»»åŠ¡å·²åˆ é™¤", "task_id": task_id}

# =============================================================================
# ç»“æœæŸ¥è¯¢æ¥å£
# =============================================================================

@router.get("/result/{task_id}", response_model=BacktestResult)
async def get_backtest_result(task_id: str, current_user: dict = get_user_dependency()):
    """è·å–å›æµ‹ç»“æœ"""
    if task_id not in active_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    task = active_tasks[task_id]
    user_id = current_user.get('user_id', 'anonymous')
    
    # æ£€æŸ¥æƒé™
    if task['user_id'] != user_id and current_user.get('role') != 'admin':
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    if task['status'] != 'completed':
        raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªå®Œæˆ")
    
    if not task.get('result'):
        raise HTTPException(status_code=404, detail="å›æµ‹ç»“æœä¸å­˜åœ¨")
    
    result = task['result']
    return BacktestResult(**result)

@router.get("/result/{task_id}/markdown")
async def get_markdown_report(
    task_id: str, 
    current_user: dict = get_user_dependency()
):
    """è·å–Markdownåˆ†ææŠ¥å‘Š"""
    if task_id not in active_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    task = active_tasks[task_id]
    user_id = current_user.get('user_id', 'anonymous')
    
    # æ£€æŸ¥æƒé™
    if task['user_id'] != user_id and current_user.get('role') != 'admin':
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    if task['status'] != 'completed':
        raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªå®Œæˆ")
    
    result = task.get('result', {})
    
    # å°è¯•è¯»å–MarkdownæŠ¥å‘Š
    markdown_content = ""
    try:
        markdown_content = find_and_read_markdown_report(result, task_id)
    except Exception as e:
        logger.warning(f"è¯»å–MarkdownæŠ¥å‘Šå¤±è´¥: {e}")
        # ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Š
        markdown_content = generate_fallback_markdown_report(result, task, task_id)
    
    return {"content": markdown_content, "task_id": task_id}

def find_and_read_markdown_report(result: dict, task_id: str) -> str:
    """æŸ¥æ‰¾å¹¶è¯»å–MarkdownæŠ¥å‘Šæ–‡ä»¶"""
    import os
    import glob
    
    try:
        # å°è¯•ä»ç»“æœä¸­è·å–æŠ¥å‘Šè·¯å¾„
        report_path = result.get('markdown_report_path')
        if report_path and os.path.exists(report_path):
            with open(report_path, 'r', encoding='utf-8') as f:
                return f.read()
        
        # å°è¯•æŸ¥æ‰¾resultsç›®å½•ä¸­çš„Markdownæ–‡ä»¶
        results_dir = result.get('results_dir')
        if results_dir:
            # æŸ¥æ‰¾å¯èƒ½çš„MarkdownæŠ¥å‘Šæ–‡ä»¶
            patterns = [
                os.path.join(results_dir, 'analysis_report.md'),
                os.path.join(results_dir, 'backtest_report.md'),
                os.path.join(results_dir, f'{task_id}_report.md'),
                os.path.join(results_dir, '*.md')
            ]
            
            for pattern in patterns[:-1]:  # å…ˆæ£€æŸ¥å…·ä½“æ–‡ä»¶å
                if os.path.exists(pattern):
                    with open(pattern, 'r', encoding='utf-8') as f:
                        return f.read()
            
            # æœ€åä½¿ç”¨é€šé…ç¬¦æŸ¥æ‰¾ä»»ä½•.mdæ–‡ä»¶
            md_files = glob.glob(patterns[-1])
            if md_files:
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
                md_files.sort(key=os.path.getmtime, reverse=True)
                with open(md_files[0], 'r', encoding='utf-8') as f:
                    return f.read()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œå°è¯•ç”ŸæˆæŠ¥å‘Š
        logger.info(f"æœªæ‰¾åˆ°ç°å­˜çš„MarkdownæŠ¥å‘Šï¼Œå°è¯•ç”Ÿæˆæ–°æŠ¥å‘Š")
        return generate_markdown_report_from_result(result, task_id)
        
    except Exception as e:
        logger.warning(f"è¯»å–MarkdownæŠ¥å‘Šå¤±è´¥: {e}")
        raise

def generate_markdown_report_from_result(result: dict, task_id: str) -> str:
    """ä»å›æµ‹ç»“æœç”ŸæˆMarkdownæŠ¥å‘Š"""
    try:
        # å¯¼å…¥æ€§èƒ½åˆ†æå™¨
        sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'backtrader_strategies'))
        from backtest.performance_analyzer import PerformanceAnalyzer
        
        # åˆ›å»ºæ€§èƒ½åˆ†æå™¨å®ä¾‹
        analyzer = PerformanceAnalyzer()
        
        # ç”ŸæˆMarkdownæŠ¥å‘Šå†…å®¹
        markdown_content = analyzer._generate_markdown_report(result)
        
        logger.info(f"æˆåŠŸä»ç»“æœç”ŸæˆMarkdownæŠ¥å‘Šï¼Œé•¿åº¦: {len(markdown_content)}")
        return markdown_content
        
    except Exception as e:
        logger.error(f"ä»ç»“æœç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥: {e}")
        # ç”Ÿæˆç®€åŒ–çš„å¤‡ç”¨æŠ¥å‘Š
        return generate_fallback_markdown_report(result, {"status": "completed"}, task_id)

def get_friendly_strategy_name(raw_name: str, strategy_type: str) -> str:
    """
    å°†åç«¯æŠ€æœ¯åç§°è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„æ˜¾ç¤ºåç§°
    """
    # ç­–ç•¥ç±»å‹åˆ°å‹å¥½åç§°çš„æ˜ å°„
    strategy_mapping = {
        'multi_trend': 'å¤ªä¸Šè€å›1å·ç­–ç•¥',
        'boll': 'å¤ªä¸Šè€å›2å·ç­–ç•¥',
        'taishang_3factor': 'å¤ªä¸Šè€å›3å·ç­–ç•¥'
    }
    
    # ä¼˜å…ˆä½¿ç”¨strategy_typeè¿›è¡Œæ˜ å°„
    if strategy_type in strategy_mapping:
        return strategy_mapping[strategy_type]
    
    # å¦‚æœstrategy_typeæ²¡æœ‰åŒ¹é…ï¼Œå°è¯•ä»raw_nameä¸­è¯†åˆ«
    raw_lower = raw_name.lower()
    for key, friendly_name in strategy_mapping.items():
        if key in raw_lower or key.replace('_', '') in raw_lower:
            return friendly_name
    
    # å¦‚æœåŸåç§°å·²ç»æ˜¯å‹å¥½åç§°ï¼Œç›´æ¥è¿”å›
    if 'å¤ªä¸Šè€å›' in raw_name:
        return raw_name
        
    # é»˜è®¤è¿”å›é€šç”¨åç§°ï¼Œä¸æš´éœ²æŠ€æœ¯ç»†èŠ‚
    return 'é‡åŒ–ç­–ç•¥'

def generate_fallback_markdown_report(result: dict, task: dict, task_id: str) -> str:
    """ç”Ÿæˆå¤‡ç”¨MarkdownæŠ¥å‘Š"""
    from datetime import datetime
    
    # æå–åŸºç¡€ä¿¡æ¯å¹¶è½¬æ¢ä¸ºå‹å¥½åç§°
    raw_strategy_name = result.get('strategy_info', {}).get('strategy_name', 'æœªçŸ¥ç­–ç•¥')
    
    # å¤šè·¯å¾„è·å–strategy_type
    strategy_type = (
        result.get('backtest_config', {}).get('strategy_type') or
        result.get('config', {}).get('strategy_type') or
        result.get('strategy_type') or
        ''
    )
    
    logger.info(f"APIç­–ç•¥ç±»å‹è·å–: raw_name={raw_strategy_name}, strategy_type={strategy_type}")
    strategy_name = get_friendly_strategy_name(raw_strategy_name, strategy_type)
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    performance = result.get('performance_report', {}).get('basic_metrics', {})
    
    # ç”Ÿæˆç®€åŒ–æŠ¥å‘Š
    markdown = f"""# {strategy_name} å›æµ‹åˆ†ææŠ¥å‘Š

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|------|------|
| ä»»åŠ¡ID | {task_id} |
| ç­–ç•¥åç§° | {strategy_name} |
| æŠ¥å‘Šç”Ÿæˆæ—¶é—´ | {current_time} |
| ä»»åŠ¡çŠ¶æ€ | {task.get('status', 'æœªçŸ¥')} |

## ğŸ“Š æ ¸å¿ƒç»©æ•ˆæŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»æ”¶ç›Šç‡ | {performance.get('total_return', 0):.2%} |
| å¹´åŒ–æ”¶ç›Šç‡ | {performance.get('annual_return', 0):.2%} |
| æœ€å¤§å›æ’¤ | {performance.get('max_drawdown', 0):.2%} |
| å¤æ™®æ¯”ç‡ | {performance.get('sharpe_ratio', 0):.3f} |

---

*å¤‡æ³¨ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬çš„æŠ¥å‘Šã€‚å®Œæ•´æŠ¥å‘Šç”Ÿæˆä¸­é‡åˆ°é—®é¢˜ï¼Œä»…æ˜¾ç¤ºåŸºç¡€ä¿¡æ¯ã€‚*
"""
    
    return markdown

@router.get("/result/{task_id}/trades")
async def get_trades_data(
    task_id: str,
    limit: int = Query(10000, ge=1, le=10000, description="è¿”å›æ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡"),
    current_user: dict = get_user_dependency()
):
    """è·å–äº¤æ˜“æ•°æ®"""
    try:
        logger.info(f"ğŸ” å¼€å§‹è·å–ä»»åŠ¡ {task_id} çš„äº¤æ˜“æ•°æ®")
        logger.info(f"ğŸ“‹ å½“å‰æ´»è·ƒä»»åŠ¡æ•°é‡: {len(active_tasks)}")
        logger.info(f"ğŸ“‹ æ´»è·ƒä»»åŠ¡IDåˆ—è¡¨: {list(active_tasks.keys())}")
        
        # ä»ä»»åŠ¡å­˜å‚¨è·å–ä»»åŠ¡
        task = active_tasks.get(task_id)
        trades = []
        
        if not task:
            logger.warning(f"ä»»åŠ¡ {task_id} ä¸åœ¨æ´»è·ƒä»»åŠ¡ä¸­ï¼Œå°è¯•ç›´æ¥è¯»å–CSVæ–‡ä»¶")
        else:
            logger.info(f"ğŸ“‹ æ‰¾åˆ°ä»»åŠ¡ï¼ŒçŠ¶æ€: {task.get('status')}")
            # å¦‚æœä»»åŠ¡æœªå®Œæˆï¼Œè¿”å›ç©ºæ•°æ®
            if task.get('status') != 'completed':
                logger.info(f"ä»»åŠ¡ {task_id} æœªå®Œæˆï¼Œè¿”å›ç©ºæ•°æ®")
                return {"trades": [], "total": 0}
            
            # è·å–ä»»åŠ¡ç»“æœ
            result = task.get('result')
            if not result:
                logger.warning(f"ä»»åŠ¡ {task_id} æ²¡æœ‰ç»“æœæ•°æ®")
            else:
                # æ–¹æ³•1: ä»trading_summaryä¸­è·å–
                trading_summary = result.get('trading_summary', {})
                logger.info(f"ğŸ“‹ trading_summaryç»“æ„: {type(trading_summary)}, keys: {list(trading_summary.keys()) if isinstance(trading_summary, dict) else 'not dict'}")
                
                if 'trades' in trading_summary:
                    trades_from_summary = trading_summary['trades']
                    logger.info(f"ğŸ“Š trading_summary['trades']ç±»å‹: {type(trades_from_summary)}, å€¼: {trades_from_summary}")
                    
                    if isinstance(trades_from_summary, list):
                        trades = trades_from_summary
                        logger.info(f"âœ… ä»trading_summaryè·å–åˆ° {len(trades)} æ¡äº¤æ˜“è®°å½•")
                    else:
                        logger.warning(f"âš ï¸ trading_summary['trades']ä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(trades_from_summary)}")
                        trades = []
        
        # æ–¹æ³•2: å¦‚æœæ²¡æœ‰tradesï¼Œå°è¯•è¯»å–CSVæ–‡ä»¶
        if not trades:
            logger.info(f"ğŸ“ å°è¯•ä»CSVæ–‡ä»¶è¯»å–äº¤æ˜“æ•°æ®")
            try:
                # è·å–ç»“æœç›®å½•è·¯å¾„ï¼ˆåŸºäºä»»åŠ¡é…ç½®ï¼‰
                import os
                results_dir = "/home/libing/kk_Projects/kk_stock/kk_stock_backend/results"
                
                # ä¼˜å…ˆå°è¯•ï¼šå¦‚æœä»»åŠ¡åœ¨active_tasksä¸­ï¼Œä¸”æœ‰ç»“æœç›®å½•ä¿¡æ¯
                matching_files = []
                if task and 'result_dir' in task:
                    potential_trades_file = os.path.join(task['result_dir'], f"*_trades.csv")
                    import glob
                    matching_files = glob.glob(potential_trades_file)
                    if matching_files:
                        logger.info(f"ğŸ“„ ä»ä»»åŠ¡ä¿¡æ¯æ‰¾åˆ°äº¤æ˜“æ–‡ä»¶: {matching_files[0]}")
                
                # å¤‡é€‰æ–¹æ¡ˆï¼šå…¨å±€æœç´¢CSVæ–‡ä»¶
                if not matching_files:
                    import glob
                    pattern = f"{results_dir}/**/*_trades.csv"
                    trade_files = glob.glob(pattern, recursive=True)
                    logger.info(f"ğŸ” å…¨å±€æœç´¢æ‰¾åˆ° {len(trade_files)} ä¸ªäº¤æ˜“CSVæ–‡ä»¶")
                    
                    # æŸ¥æ‰¾åŒ…å«task_idçš„æ–‡ä»¶æˆ–æœ€æ–°çš„æ–‡ä»¶
                    matching_files = [f for f in trade_files if task_id in f]
                    if not matching_files and trade_files:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ï¼Œä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
                        matching_files = [max(trade_files, key=os.path.getmtime)]
                        logger.info(f"ğŸ“„ æœªæ‰¾åˆ°åŒ¹é…task_idçš„æ–‡ä»¶ï¼Œä½¿ç”¨æœ€æ–°æ–‡ä»¶: {matching_files[0]}")
                    elif matching_files:
                        logger.info(f"ğŸ“„ æ‰¾åˆ°åŒ¹é…æ–‡ä»¶: {matching_files[0]}")
                
                if matching_files:
                    import pandas as pd
                    df = pd.read_csv(matching_files[0])
                    logger.info(f"ğŸ“Š CSVæ–‡ä»¶åŒ…å« {len(df)} è¡Œæ•°æ®")
                    
                    # è½¬æ¢æ•°æ®æ ¼å¼
                    for _, row in df.iterrows():
                        trade = {
                            "trade_id": str(row.get('trade_id', '')),
                            "date": str(row.get('trade_date', '')),
                            "symbol": str(row.get('stock_code', '')),
                            "name": str(row.get('stock_code', '')),
                            "action": str(row.get('order_type', '')),
                            "shares": float(row.get('quantity', 0)),
                            "price": float(row.get('price', 0)),
                            "amount": float(row.get('net_amount', 0)),
                            "commission": float(row.get('commission', 0)),
                            "stamp_tax": float(row.get('stamp_tax', 0)),
                            "total_cost": abs(float(row.get('net_amount', 0)))
                        }
                        trades.append(trade)
                    
                    # æŒ‰äº¤æ˜“æ—¥æœŸå€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
                    trades.sort(key=lambda x: x.get('date', ''), reverse=True)
                    logger.info(f"âœ… ä»CSVæ–‡ä»¶è·å–ä»»åŠ¡ {task_id} çš„äº¤æ˜“è®°å½•: {len(trades)} æ¡ï¼Œå·²æŒ‰æ—¥æœŸå€’åºæ’åº")
                else:
                    logger.warning(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„äº¤æ˜“CSVæ–‡ä»¶")
                    
            except Exception as e:
                logger.error(f"è¯»å–äº¤æ˜“è®°å½•CSVæ–‡ä»¶å¤±è´¥: {e}")
                import traceback
                logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        
        # ç¡®ä¿tradesæ˜¯åˆ—è¡¨å¹¶è¿›è¡Œç±»å‹æ£€æŸ¥
        logger.info(f"ğŸ” tradesç±»å‹æ£€æŸ¥: type={type(trades)}, isinstance(list)={isinstance(trades, list)}")
        if not isinstance(trades, list):
            logger.warning(f"âš ï¸ tradesä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(trades)}, å€¼: {trades}, é‡ç½®ä¸ºç©ºåˆ—è¡¨")
            trades = []
        
        # æœ€ç»ˆæ’åºç¡®ä¿æŒ‰æ—¶é—´å€’åº
        if trades:
            trades.sort(key=lambda x: x.get('date', ''), reverse=True)
            logger.info(f"ğŸ“… äº¤æ˜“è®°å½•æœ€ç»ˆæ’åºå®Œæˆï¼Œæœ€æ–°äº¤æ˜“: {trades[0].get('date', 'N/A')} {trades[0].get('symbol', 'N/A')}")
        
        # åˆ†é¡µå¤„ç†
        total = len(trades)
        logger.info(f"ğŸ“„ åˆ†é¡µå¤„ç†: total={total}, offset={offset}, limit={limit}")
        
        # å¦‚æœlimitè¾¾åˆ°æœ€å¤§å€¼(10000)ä¸”totalè¶…è¿‡limitï¼Œåˆ™è¿”å›æ‰€æœ‰æ•°æ®
        if limit == 10000 and total > limit:
            logger.info(f"ğŸ“„ æ£€æµ‹åˆ°æ€»è®°å½•æ•°({total})è¶…è¿‡é»˜è®¤é™åˆ¶ï¼Œè¿”å›æ‰€æœ‰äº¤æ˜“è®°å½•")
            trades = trades[offset:]  # åªåº”ç”¨offsetï¼Œä¸é™åˆ¶æ•°é‡
        else:
            trades = trades[offset:offset+limit]
        
        logger.info(f"âœ… æˆåŠŸè·å–ä»»åŠ¡ {task_id} çš„äº¤æ˜“è®°å½•: {len(trades)}/{total}")
        return {"trades": trades, "total": total}
        
    except Exception as e:
        logger.error(f"è·å–äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–äº¤æ˜“æ•°æ®å¤±è´¥: {str(e)}")

@router.get("/result/{task_id}/portfolio")
async def get_portfolio_data(
    task_id: str,
    limit: int = Query(1000, ge=1, le=10000, description="è¿”å›æ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡"),
    current_user: dict = get_user_dependency()
):
    """è·å–ç»„åˆå†å²æ•°æ®"""
    # å®ç°ç»„åˆæ•°æ®æŸ¥è¯¢é€»è¾‘
    _ = task_id, limit, offset, current_user  # æš‚æ—¶æœªä½¿ç”¨
    return {"portfolio_history": [], "total": 0}

@router.get("/benchmark/{benchmark_code}")
async def get_benchmark_index_data(
    benchmark_code: str,
    start_date: str = Query(..., description="å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD"),
    end_date: str = Query(..., description="ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD"),
    current_user: dict = get_user_dependency()
):
    """
    è·å–åŸºå‡†æŒ‡æ•°æ•°æ®
    æ”¯æŒçš„æŒ‡æ•°ä»£ç ï¼š000300.SH, 000905.SH, 000852.SH, 000001.SHç­‰
    """
    try:
        # åŸºå‡†æŒ‡æ•°åç§°æ˜ å°„
        benchmark_names = {
            '000300.SH': 'æ²ªæ·±300',
            '000905.SH': 'ä¸­è¯500', 
            '000852.SH': 'ä¸­è¯1000',
            '000001.SH': 'ä¸Šè¯æŒ‡æ•°'
        }
        
        benchmark_name = benchmark_names.get(benchmark_code, benchmark_code)
        
        # è·å–åŸºå‡†æŒ‡æ•°æ•°æ®
        benchmark_data = get_benchmark_data(benchmark_code, start_date, end_date)
        
        if not benchmark_data:
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°åŸºå‡†æŒ‡æ•°{benchmark_code}çš„æ•°æ®")
        
        # è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡
        benchmark_returns = calculate_benchmark_returns(benchmark_data)
        
        return {
            "benchmark_code": benchmark_code,
            "benchmark_name": benchmark_name,
            "start_date": start_date,
            "end_date": end_date,
            "data_count": len(benchmark_data),
            "data": benchmark_data,
            "cumulative_returns": benchmark_returns,
            "final_return": benchmark_returns[-1] if benchmark_returns else 0,
            "annualized_return": (benchmark_returns[-1] if benchmark_returns else 0) * 252 / len(benchmark_data) if benchmark_data else 0
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–åŸºå‡†æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–åŸºå‡†æŒ‡æ•°æ•°æ®å¤±è´¥: {str(e)}")

# =============================================================================
# å®æ—¶æ•°æ®æ¨é€ç«¯ç‚¹ (SSE)
# =============================================================================

@router.get("/sse/test")
async def test_connection():
    """æµ‹è¯•SSEè¿æ¥"""
    return {"message": "SSEæµ‹è¯•è¿æ¥æˆåŠŸ", "timestamp": datetime.now().isoformat()}

@router.get("/sse/test-stream")
async def test_stream():
    """æµ‹è¯•SSEæµæ˜¯å¦æ­£å¸¸"""
    async def test_generator():
        for i in range(5):
            yield f"data: {{\"message\": \"æµ‹è¯•æ¶ˆæ¯ {i+1}\", \"timestamp\": \"{datetime.now().isoformat()}\"}}\n\n"
            await asyncio.sleep(1)
        yield f"data: {{\"message\": \"æµ‹è¯•å®Œæˆ\", \"final\": true}}\n\n"
    
    return StreamingResponse(
        test_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

@router.get("/sse/progress/{task_id}")
async def stream_progress(task_id: str, user: dict = Depends(get_current_user_sse)):
    """æ¨é€è¿›åº¦æ•°æ®"""
    _ = user  # ç”¨æˆ·éªŒè¯å·²é€šè¿‡ï¼Œæ­¤å¤„æš‚ä¸ä½¿ç”¨
    return StreamingResponse(
        sse_generator(task_id, "progress"),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

@router.get("/sse/portfolio/{task_id}")
async def stream_portfolio(task_id: str, user: dict = Depends(get_current_user_sse)):
    """æ¨é€ç»„åˆæ•°æ®"""
    _ = user  # ç”¨æˆ·éªŒè¯å·²é€šè¿‡ï¼Œæ­¤å¤„æš‚ä¸ä½¿ç”¨
    return StreamingResponse(
        sse_generator(task_id, "portfolio"),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

@router.get("/sse/trades/{task_id}")
async def stream_trades(task_id: str, user: dict = Depends(get_current_user_sse)):
    """æ¨é€äº¤æ˜“æ•°æ®"""
    _ = user  # ç”¨æˆ·éªŒè¯å·²é€šè¿‡ï¼Œæ­¤å¤„æš‚ä¸ä½¿ç”¨
    return StreamingResponse(
        sse_generator(task_id, "trades"),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

@router.get("/sse/chart/{task_id}")
async def stream_chart(task_id: str, user: dict = Depends(get_current_user_sse)):
    """æ¨é€å›¾è¡¨æ•°æ®"""
    _ = user  # ç”¨æˆ·éªŒè¯å·²é€šè¿‡ï¼Œæ­¤å¤„æš‚ä¸ä½¿ç”¨
    return StreamingResponse(
        sse_generator(task_id, "chart"),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

@router.get("/sse/realtime/{task_id}")
async def stream_realtime(task_id: str, user: dict = Depends(get_current_user_sse)):
    """æ¨é€å®æ—¶ç»¼åˆæ•°æ®ï¼ˆæ¨èä½¿ç”¨ï¼‰"""
    _ = user  # ç”¨æˆ·éªŒè¯å·²é€šè¿‡ï¼Œæ­¤å¤„æš‚ä¸ä½¿ç”¨
    return StreamingResponse(
        sse_generator(task_id, "realtime"),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

# =============================================================================
# è¾…åŠ©æŸ¥è¯¢æ¥å£
# =============================================================================

@router.get("/indices")
@cache_endpoint(data_type='indices', ttl=3600)
async def get_available_indices():
    """è·å–å¯ç”¨æŒ‡æ•°åˆ—è¡¨"""
    indices = [
        {"code": "000510.CSI", "name": "ä¸­è¯500", "description": "ä¸­è¯500æŒ‡æ•°æˆåˆ†è‚¡"},
        {"code": "399006.SZ", "name": "åˆ›ä¸šæ¿æŒ‡", "description": "åˆ›ä¸šæ¿æŒ‡æ•°æˆåˆ†è‚¡"},
        {"code": "000001.SH", "name": "ä¸Šè¯æŒ‡æ•°", "description": "ä¸Šè¯ç»¼åˆæŒ‡æ•°æˆåˆ†è‚¡"},
        {"code": "399001.SZ", "name": "æ·±è¯æˆæŒ‡", "description": "æ·±è¯æˆä»½æŒ‡æ•°æˆåˆ†è‚¡"}
    ]
    return indices

@router.get("/stock-pool/{index_code}")
@cache_endpoint(data_type='stock_pool', ttl=3600)
async def get_stock_pool(
    index_code: str,
    limit: int = Query(100, ge=10, le=1000, description="è¿”å›æ•°é‡é™åˆ¶")
):
    """è·å–æŒ‡æ•°æˆåˆ†è‚¡æ± """
    # è¿™é‡Œåº”è¯¥å®ç°çœŸå®çš„è‚¡ç¥¨æ± æŸ¥è¯¢é€»è¾‘
    # ç®€åŒ–ç‰ˆæœ¬è¿”å›æ¨¡æ‹Ÿæ•°æ®
    stocks = [
        {"code": f"00000{i}.SZ", "name": f"è‚¡ç¥¨{i}", "weight": 0.01}
        for i in range(1, min(limit + 1, 101))
    ]
    
    return {
        "index_code": index_code,
        "stocks": stocks,
        "total": len(stocks),
        "update_time": datetime.now().isoformat()
    }

@router.get("/health")
async def backtest_health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "backtest_unified",
        "has_backtest_engine": HAS_BACKTEST_ENGINE,
        "has_cache": HAS_CACHE,
        "has_db_handler": HAS_DB_HANDLER,
        "has_user_auth": HAS_USER_AUTH,
        "active_tasks_count": len(active_tasks),
        "timestamp": datetime.now().isoformat()
    }

# =============================================================================
# WebSocketå®æ—¶æ•°æ®æ¨é€
# =============================================================================

async def websocket_data_broadcaster(task_id: str):
    """WebSocketæ•°æ®å¹¿æ’­å™¨ - æŒç»­ç›‘æ§ä»»åŠ¡çŠ¶æ€å¹¶æ¨é€æ•°æ®"""
    logger.info(f"å¼€å§‹WebSocketæ•°æ®å¹¿æ’­: task_id={task_id}")
    
    last_progress_data = None
    last_portfolio_data = None
    last_trades_count = 0
    
    try:
        while task_id in active_tasks:
            task_info = active_tasks[task_id]
            has_new_data = False
            
            # æ£€æŸ¥è¿›åº¦å˜åŒ–
            current_progress = {
                "progress": task_info.get('progress', 0.0),
                "status": task_info.get('status', 'pending'),
                "current_date": task_info.get('current_date'),
                "message": task_info.get('message', '')
            }
            
            if not last_progress_data or current_progress != last_progress_data:
                progress_message = {
                    "type": "progress",
                    "task_id": task_id,
                    "data": current_progress,
                    "timestamp": datetime.now().isoformat()
                }
                await ws_manager.broadcast_to_task(progress_message, task_id)
                last_progress_data = current_progress
                has_new_data = True
            
            # æ£€æŸ¥ç»„åˆæ•°æ®å˜åŒ–
            current_portfolio = {
                "current_date": task_info.get('current_date', ''),
                "total_value": task_info.get('current_portfolio_value', 0.0),
                "total_return": task_info.get('total_return', 0.0),
                "daily_return": task_info.get('daily_return', 0.0),
                "drawdown": task_info.get('current_drawdown', 0.0)
            }
            
            data_updated_flag = task_info.get('data_updated', False)
            date_changed = (current_portfolio['current_date'] and 
                           (not last_portfolio_data or 
                            current_portfolio['current_date'] != last_portfolio_data.get('current_date')))
            
            if date_changed or data_updated_flag:
                portfolio_message = {
                    "type": "portfolio",
                    "task_id": task_id,
                    "data": {
                        "current_date": current_portfolio['current_date'],
                        "portfolio": {
                            "total_value": current_portfolio['total_value'],
                            "cash": task_info.get('current_cash', 0.0),
                            "positions_value": task_info.get('current_positions_value', 0.0),
                            "positions": task_info.get('current_positions', []),
                            "daily_return": current_portfolio['daily_return'],
                            "total_return": current_portfolio['total_return'],
                            "drawdown": current_portfolio['drawdown']
                        }
                    },
                    "timestamp": datetime.now().isoformat()
                }
                await ws_manager.broadcast_to_task(portfolio_message, task_id)
                logger.info(f"ğŸ”„ WebSocketæ¨é€Portfolioæ•°æ®: {current_portfolio['current_date']}, ç»„åˆä»·å€¼: {current_portfolio['total_value']:,.2f}")
                last_portfolio_data = current_portfolio
                has_new_data = True
                
                # é‡ç½®æ•°æ®æ›´æ–°æ ‡å¿—
                if 'data_updated' in task_info:
                    task_info['data_updated'] = False
            
            # æ£€æŸ¥äº¤æ˜“æ•°æ®å˜åŒ–
            current_trades_count = task_info.get('total_trades', 0)
            if current_trades_count > last_trades_count:
                trades_message = {
                    "type": "trades",
                    "task_id": task_id,
                    "data": {
                        "current_date": task_info.get('current_date', ''),
                        "recent_trades": task_info.get('recent_trades', []),
                        "trade_stats": {
                            "total_trades": current_trades_count,
                            "buy_trades": task_info.get('buy_trades', 0),
                            "sell_trades": task_info.get('sell_trades', 0),
                            "win_trades": task_info.get('win_trades', 0),
                            "lose_trades": task_info.get('lose_trades', 0),
                            "win_rate": task_info.get('win_rate', 0.0),
                            "total_pnl": task_info.get('total_pnl', 0.0)
                        }
                    },
                    "timestamp": datetime.now().isoformat()
                }
                await ws_manager.broadcast_to_task(trades_message, task_id)
                last_trades_count = current_trades_count
                has_new_data = True
            
            # æ£€æŸ¥å›¾è¡¨æ•°æ®å˜åŒ–
            if task_info.get('date_series'):
                chart_message = {
                    "type": "chart",
                    "task_id": task_id,
                    "data": {
                        "current_date": task_info.get('current_date', ''),
                        "chart_data": {
                            "dates": task_info.get('date_series', []),
                            "portfolio_values": task_info.get('portfolio_series', []),
                            "daily_returns": task_info.get('daily_return_series', []),
                            "cumulative_returns": task_info.get('cumulative_return_series', []),
                            "drawdowns": task_info.get('drawdown_series', [])
                        }
                    },
                    "timestamp": datetime.now().isoformat()
                }
                await ws_manager.broadcast_to_task(chart_message, task_id)
                has_new_data = True
            
            # æ£€æŸ¥ä»»åŠ¡å®ŒæˆçŠ¶æ€
            status = task_info.get('status', 'pending')
            if status in ['completed', 'failed']:
                final_message = {
                    "type": "final",
                    "task_id": task_id,
                    "data": {
                        "status": status,
                        "message": task_info.get('message', ''),
                        "result_available": status == 'completed'
                    },
                    "timestamp": datetime.now().isoformat()
                }
                await ws_manager.broadcast_to_task(final_message, task_id)
                logger.info(f"WebSocketå¹¿æ’­ä»»åŠ¡å®Œæˆ: task_id={task_id}, status={status}")
                break
            
            # åŠ¨æ€è°ƒæ•´æ¨é€é¢‘ç‡
            if has_new_data:
                await asyncio.sleep(0.05)  # æœ‰æ–°æ•°æ®æ—¶å¿«é€Ÿæ¨é€
            else:
                await asyncio.sleep(0.5)   # æ— æ–°æ•°æ®æ—¶é™ä½é¢‘ç‡
                
    except Exception as e:
        logger.error(f"WebSocketå¹¿æ’­å™¨å¼‚å¸¸: task_id={task_id}, error={e}")
    finally:
        logger.info(f"WebSocketå¹¿æ’­å™¨ç»“æŸ: task_id={task_id}")

async def websocket_authenticate(websocket: WebSocket, token: str) -> dict:
    """WebSocketè®¤è¯"""
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id = payload.get("user_id")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ")
        
        # ç®€åŒ–çš„ç”¨æˆ·éªŒè¯ï¼Œå®é™…åº”è¯¥æŸ¥è¯¢æ•°æ®åº“
        return {"user_id": user_id, "role": "user"}
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Tokenå·²è¿‡æœŸ")
    except Exception:
        raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ")

def update_task_realtime_data(task_id: str, update_data: Dict[str, Any]):
    """æ›´æ–°ä»»åŠ¡çš„å®æ—¶æ•°æ® - ä¿ç•™å…¼å®¹æ€§å‡½æ•°"""
    if task_id in active_tasks:
        active_tasks[task_id].update(update_data)

# =============================================================================
# WebSocketç«¯ç‚¹
# =============================================================================

@router.websocket("/ws/test")
async def websocket_test_endpoint(websocket: WebSocket):
    """WebSocketæµ‹è¯•ç«¯ç‚¹"""
    await websocket.accept()
    try:
        # å‘é€æ¬¢è¿æ¶ˆæ¯
        await websocket.send_text(json.dumps({
            "type": "welcome",
            "message": "WebSocketè¿æ¥æµ‹è¯•æˆåŠŸ",
            "timestamp": datetime.now().isoformat()
        }))
        
        # å‘é€å‡ æ¡æµ‹è¯•æ¶ˆæ¯
        for i in range(5):
            await asyncio.sleep(1)
            await websocket.send_text(json.dumps({
                "type": "test",
                "message": f"æµ‹è¯•æ¶ˆæ¯ {i+1}",
                "timestamp": datetime.now().isoformat()
            }))
        
        # å‘é€å®Œæˆæ¶ˆæ¯
        await websocket.send_text(json.dumps({
            "type": "complete",
            "message": "æµ‹è¯•å®Œæˆ",
            "timestamp": datetime.now().isoformat()
        }))
        
    except WebSocketDisconnect:
        logger.info("WebSocketæµ‹è¯•è¿æ¥æ–­å¼€")
    except Exception as e:
        logger.error(f"WebSocketæµ‹è¯•å¼‚å¸¸: {e}")

@router.websocket("/ws/realtime/{task_id}")
async def websocket_realtime_endpoint(websocket: WebSocket, task_id: str, token: str = Query(...)):
    """WebSocketå®æ—¶æ•°æ®æ¨é€ç«¯ç‚¹"""
    try:
        # è®¤è¯
        user = await websocket_authenticate(websocket, token)
        logger.info(f"WebSocketç”¨æˆ·è®¤è¯æˆåŠŸ: user_id={user['user_id']}, task_id={task_id}")
        
        # æ£€æŸ¥ä»»åŠ¡æƒé™
        if task_id not in active_tasks:
            await websocket.close(code=1008, reason="ä»»åŠ¡ä¸å­˜åœ¨")
            return
        
        task = active_tasks[task_id]
        if task['user_id'] != user['user_id'] and user.get('role') != 'admin':
            await websocket.close(code=1008, reason="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
            return
        
        # å»ºç«‹è¿æ¥
        connection_id = await ws_manager.connect(websocket, task_id)
        
        # å‘é€è¿æ¥ç¡®è®¤
        await websocket.send_text(json.dumps({
            "type": "connected",
            "task_id": task_id,
            "connection_id": connection_id,
            "message": "WebSocketè¿æ¥å·²å»ºç«‹",
            "timestamp": datetime.now().isoformat()
        }))
        
        # å¯åŠ¨æ•°æ®å¹¿æ’­å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰çš„è¯ï¼‰
        if ws_manager.get_task_connection_count(task_id) == 1:
            # ç¬¬ä¸€ä¸ªè¿æ¥ï¼Œå¯åŠ¨å¹¿æ’­å™¨
            asyncio.create_task(websocket_data_broadcaster(task_id))
        
        # å¯åŠ¨æœåŠ¡ç«¯å¿ƒè·³ä»»åŠ¡
        async def server_heartbeat():
            """æœåŠ¡ç«¯å¿ƒè·³ä»»åŠ¡"""
            while True:
                try:
                    await asyncio.sleep(30)  # æ¯30ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
                    if websocket.client_state.DISCONNECTED:
                        break
                    await websocket.send_text(json.dumps({
                        "type": "heartbeat",
                        "timestamp": datetime.now().isoformat(),
                        "task_id": task_id
                    }))
                except Exception as e:
                    logger.error(f"æœåŠ¡ç«¯å¿ƒè·³å‘é€å¤±è´¥: {e}")
                    break
        
        heartbeat_task = asyncio.create_task(server_heartbeat())
        
        # ä¿æŒè¿æ¥æ´»è·ƒ
        while True:
            try:
                # ä½¿ç”¨timeoutç­‰å¾…å®¢æˆ·ç«¯æ¶ˆæ¯ï¼Œé¿å…æ— é™æœŸé˜»å¡
                try:
                    message = await asyncio.wait_for(websocket.receive_text(), timeout=60.0)
                    data = json.loads(message)
                    
                    # å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
                    if data.get("type") == "ping":
                        await websocket.send_text(json.dumps({
                            "type": "pong",
                            "timestamp": datetime.now().isoformat()
                        }))
                    elif data.get("type") == "heartbeat_response":
                        # å®¢æˆ·ç«¯å“åº”å¿ƒè·³
                        logger.debug(f"æ”¶åˆ°å®¢æˆ·ç«¯å¿ƒè·³å“åº”: task_id={task_id}")
                    elif data.get("type") == "get_current_status":
                        # å‘é€å½“å‰ä»»åŠ¡çŠ¶æ€
                        current_task = active_tasks.get(task_id, {})
                        await websocket.send_text(json.dumps({
                            "type": "current_status",
                            "task_id": task_id,
                            "data": {
                                "status": current_task.get('status', 'unknown'),
                                "progress": current_task.get('progress', 0.0),
                                "message": current_task.get('message', ''),
                                "current_date": current_task.get('current_date', '')
                            },
                            "timestamp": datetime.now().isoformat()
                        }))
                        
                except asyncio.TimeoutError:
                    # è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­å¾ªç¯ç­‰å¾…æ¶ˆæ¯
                    continue
                except WebSocketDisconnect:
                    logger.info(f"WebSocketå®¢æˆ·ç«¯ä¸»åŠ¨æ–­å¼€è¿æ¥: task_id={task_id}")
                    break
                except Exception as e:
                    logger.error(f"WebSocketæ¶ˆæ¯æ¥æ”¶å¼‚å¸¸: {e}")
                    break
                    
            except WebSocketDisconnect:
                logger.info(f"WebSocketè¿æ¥æ–­å¼€: task_id={task_id}")
                break
            except Exception as e:
                logger.error(f"WebSocketæ¶ˆæ¯å¤„ç†å¼‚å¸¸: {e}")
                break
                
    except Exception as e:
        logger.error(f"WebSocketè¿æ¥å¼‚å¸¸: {e}")
        try:
            await websocket.close(code=1011, reason=str(e))
        except:
            pass
    finally:
        # å–æ¶ˆå¿ƒè·³ä»»åŠ¡
        if 'heartbeat_task' in locals():
            heartbeat_task.cancel()
            try:
                await heartbeat_task
            except asyncio.CancelledError:
                pass
        
        # æ¸…ç†è¿æ¥
        ws_manager.disconnect(websocket, task_id)
        logger.info(f"WebSocketè¿æ¥å·²æ¸…ç†: task_id={task_id}")