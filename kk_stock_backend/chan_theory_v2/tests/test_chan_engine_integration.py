#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼ è®ºåˆ†æå¼•æ“é›†æˆæµ‹è¯•
æµ‹è¯•å®Œæ•´çš„ç¼ è®ºåˆ†ææµç¨‹ï¼šå½¢æ€å­¦ + åŠ¨åŠ›å­¦ + å¤šçº§åˆ«åˆ†æ

å±•ç¤ºç¼ è®ºv2æ¨¡å—çš„å®Œæ•´åŠŸèƒ½å’Œæœ€ä½³å®è·µåº”ç”¨
"""

import unittest
import sys
import os
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(project_root)

chan_theory_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(chan_theory_root)

try:
    from database.db_handler import get_db_handler
    from models.enums import TimeLevel
    from core.chan_engine import ChanEngine, ChanAnalysisResult, AnalysisLevel, quick_analyze, multi_level_analyze
    from models.dynamics import DynamicsConfig
    from config.chan_config import ChanConfig
    
    MODULES_AVAILABLE = True
except Exception as e:
    print(f"å¯¼å…¥å¤±è´¥: {e}")
    MODULES_AVAILABLE = False


class TestChanEngineIntegration(unittest.TestCase):
    """æµ‹è¯•ç¼ è®ºåˆ†æå¼•æ“é›†æˆåŠŸèƒ½"""
    
    @classmethod
    def setUpClass(cls):
        if not MODULES_AVAILABLE:
            raise unittest.SkipTest("æ¨¡å—å¯¼å…¥å¤±è´¥")
        
        try:
            cls.db_handler = get_db_handler()
            cls.db = cls.db_handler.db
            cls.chan_engine = ChanEngine()
            
            cls.db.command('ping')
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            
        except Exception as e:
            raise unittest.SkipTest(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
    
    @classmethod
    def tearDownClass(cls):
        """æµ‹è¯•ç»“æŸåæ¸…ç†èµ„æº"""
        try:
            if hasattr(cls, 'db_handler') and cls.db_handler:
                cls.db_handler.__del__()
                print("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
                
            from database.db_handler import reset_db_handler
            reset_db_handler()
            print("âœ… æ•°æ®åº“å¤„ç†å™¨å•ä¾‹å·²é‡ç½®")
            
        except Exception as e:
            print(f"âš ï¸ èµ„æºæ¸…ç†æ—¶å‡ºç°å¼‚å¸¸: {e}")
        finally:
            print("ğŸ”’ æ•°æ®åº“èµ„æºæ¸…ç†å®Œæˆ")
    
    def test_basic_analysis(self):
        """æµ‹è¯•åŸºç¡€åˆ†æåŠŸèƒ½"""
        print("\\nğŸ” åŸºç¡€åˆ†ææµ‹è¯•")
        
        # è·å–æµ‹è¯•æ•°æ®
        data = self._get_daily_data("000001.SZ", 200)
        if not data:
            self.skipTest("æ— æ³•è·å–æµ‹è¯•æ•°æ®")
        
        # æ‰§è¡ŒåŸºç¡€åˆ†æ
        result = self.chan_engine.analyze(
            data=data,
            symbol="000001.SZ",
            time_level=TimeLevel.DAILY,
            analysis_level=AnalysisLevel.BASIC
        )
        
        # éªŒè¯ç»“æœ
        self.assertIsInstance(result, ChanAnalysisResult)
        self.assertEqual(result.symbol, "000001.SZ")
        self.assertEqual(result.time_level, TimeLevel.DAILY)
        self.assertEqual(result.analysis_level, AnalysisLevel.BASIC)
        
        print(f"ğŸ“Š åŸºç¡€åˆ†æç»“æœ:")
        stats = result.get_statistics()
        print(f"  - åŸå§‹Kçº¿: {stats['klines_count']}æ ¹")
        print(f"  - å¤„ç†åKçº¿: {stats['processed_klines_count']}æ ¹")
        print(f"  - åˆ†å‹: {stats['fenxings_count']}ä¸ª")
        print(f"  - ç¬”: {stats['bis_count']}ä¸ª")
        print(f"  - çº¿æ®µ: {stats['segs_count']}ä¸ª")
        print(f"  - ä¸­æ¢: {stats['zhongshus_count']}ä¸ª")
        
        # åŸºç¡€æ–­è¨€
        self.assertGreater(stats['processed_klines_count'], 0)
        if stats['fenxings_count'] > 0:
            self.assertGreater(stats['fenxings_count'], 0)
    
    def test_standard_analysis(self):
        """æµ‹è¯•æ ‡å‡†åˆ†æåŠŸèƒ½ï¼ˆå½¢æ€å­¦+åŠ¨åŠ›å­¦ï¼‰"""
        print("\\nğŸ” æ ‡å‡†åˆ†ææµ‹è¯•ï¼ˆå½¢æ€å­¦+åŠ¨åŠ›å­¦ï¼‰")
        
        # è·å–æµ‹è¯•æ•°æ®
        data = self._get_daily_data("000002.SZ", 250)
        if not data:
            self.skipTest("æ— æ³•è·å–æµ‹è¯•æ•°æ®")
        
        # æ‰§è¡Œæ ‡å‡†åˆ†æ
        result = self.chan_engine.analyze(
            data=data,
            symbol="000002.SZ",
            time_level=TimeLevel.DAILY,
            analysis_level=AnalysisLevel.STANDARD
        )
        
        print(f"ğŸ“Š æ ‡å‡†åˆ†æç»“æœ:")
        stats = result.get_statistics()
        print(f"  - å½¢æ€å­¦ç»“æ„: {stats['segs_count']}çº¿æ®µ, {stats['zhongshus_count']}ä¸­æ¢")
        print(f"  - åŠ¨åŠ›å­¦åˆ†æ: {stats['backchi_count']}èƒŒé©°, {stats['buy_sell_points_count']}ä¹°å–ç‚¹")
        print(f"  - ä¹°ç‚¹/å–ç‚¹: {stats['buy_points_count']}/{stats['sell_points_count']}")
        
        # æ˜¾ç¤ºä¹°å–ç‚¹è¯¦æƒ…
        if result.buy_sell_points:
            print(f"\\nğŸ“‹ ä¹°å–ç‚¹è¯¦æƒ…:")
            for i, point in enumerate(result.buy_sell_points[:3]):
                print(f"  {i+1}. {point.point_type} @{point.price:.2f} "
                      f"({point.timestamp.strftime('%Y-%m-%d')}) "
                      f"å¯é åº¦:{point.reliability:.3f}")
        
        # è·å–äº¤æ˜“ä¿¡å·
        signals = self.chan_engine.get_trading_signals(result)
        print(f"\\nğŸ¯ äº¤æ˜“ä¿¡å·æ‘˜è¦:")
        print(f"  - æ€»ä¿¡å·æ•°: {signals['summary']['total_signals']}")
        print(f"  - ä¹°å…¥ä¿¡å·: {signals['summary']['buy_signals']}")
        print(f"  - å–å‡ºä¿¡å·: {signals['summary']['sell_signals']}")
        print(f"  - é«˜å¯ä¿¡åº¦ä¿¡å·: {signals['summary']['high_confidence_signals']}")
        
        # éªŒè¯ç»“æœ
        self.assertEqual(result.analysis_level, AnalysisLevel.STANDARD)
        self.assertTrue(stats['backchi_count'] >= 0)
        self.assertTrue(stats['buy_sell_points_count'] >= 0)
    
    def test_complete_analysis(self):
        """æµ‹è¯•å®Œæ•´åˆ†æåŠŸèƒ½"""
        print("\\nğŸ” å®Œæ•´åˆ†ææµ‹è¯•")
        
        # è·å–æµ‹è¯•æ•°æ®
        data = self._get_daily_data("000001.SZ", 300)
        if not data:
            self.skipTest("æ— æ³•è·å–æµ‹è¯•æ•°æ®")
        
        # æ‰§è¡Œå®Œæ•´åˆ†æ
        result = self.chan_engine.analyze(
            data=data,
            symbol="000001.SZ",
            time_level=TimeLevel.DAILY,
            analysis_level=AnalysisLevel.COMPLETE
        )
        
        print(f"ğŸ“Š å®Œæ•´åˆ†æç»“æœ:")
        stats = result.get_statistics()
        
        # æ˜¾ç¤ºç»¼åˆè¯„ä¼°
        print(f"\\nğŸ¯ ç»¼åˆè¯„ä¼°:")
        print(f"  - è¶‹åŠ¿æ–¹å‘: {stats['trend_direction']}")
        print(f"  - è¶‹åŠ¿å¼ºåº¦: {stats['trend_strength']:.1%}")
        print(f"  - é£é™©ç­‰çº§: {stats['risk_level']:.1%}")
        print(f"  - å¯ä¿¡åº¦: {stats['confidence_score']:.1%}")
        print(f"  - äº¤æ˜“å»ºè®®: {stats['recommended_action']}")
        
        if result.entry_price:
            print(f"  - å»ºè®®å…¥åœºä»·: {result.entry_price:.2f}")
        if result.stop_loss:
            print(f"  - æ­¢æŸä»·: {result.stop_loss:.2f}")
        if result.take_profit:
            print(f"  - æ­¢ç›ˆä»·: {result.take_profit:.2f}")
        
        # æ˜¾ç¤ºåˆ†ææ‘˜è¦
        summary = self.chan_engine.get_analysis_summary(result)
        print(f"\\nğŸ“‹ å®Œæ•´åˆ†ææ‘˜è¦:")
        print(summary)
        
        # éªŒè¯ç»“æœ
        self.assertEqual(result.analysis_level, AnalysisLevel.COMPLETE)
        self.assertIsNotNone(result.trend_direction)
        self.assertGreaterEqual(result.trend_strength, 0.0)
        self.assertLessEqual(result.trend_strength, 1.0)
        self.assertGreaterEqual(result.confidence_score, 0.0)
        self.assertLessEqual(result.confidence_score, 1.0)
    
    def test_multi_level_analysis(self):
        """æµ‹è¯•å¤šçº§åˆ«åˆ†æåŠŸèƒ½"""
        print("\\nğŸ” å¤šçº§åˆ«åˆ†ææµ‹è¯•")
        
        # å‡†å¤‡å¤šçº§åˆ«æ•°æ®
        level_data = {}
        
        # è·å–æ—¥çº¿æ•°æ®
        daily_data = self._get_daily_data("000001.SZ", 200)
        if daily_data:
            level_data[TimeLevel.DAILY] = daily_data
            print(f"âœ… æ—¥çº¿æ•°æ®: {len(daily_data)} æ¡")
        
        # è·å–30åˆ†é’Ÿæ•°æ®
        min30_data = self._get_minute_data("000001.SZ", "stock_kline_30min", 1000)
        if min30_data:
            level_data[TimeLevel.MIN_30] = min30_data
            print(f"âœ… 30åˆ†é’Ÿæ•°æ®: {len(min30_data)} æ¡")
        
        # è·å–5åˆ†é’Ÿæ•°æ®
        min5_data = self._get_minute_data("000001.SZ", "stock_kline_5min", 1500)
        if min5_data:
            level_data[TimeLevel.MIN_5] = min5_data
            print(f"âœ… 5åˆ†é’Ÿæ•°æ®: {len(min5_data)} æ¡")
        
        if len(level_data) < 2:
            self.skipTest("å¤šçº§åˆ«æ•°æ®ä¸è¶³")
        
        # æ‰§è¡Œå¤šçº§åˆ«åˆ†æ
        results = self.chan_engine.analyze_multi_level(level_data, "000001.SZ")
        
        print(f"\\nğŸ“Š å¤šçº§åˆ«åˆ†æç»“æœ:")
        
        for level, result in results.items():
            stats = result.get_statistics()
            print(f"\\nğŸ“ˆ {level.value} çº§åˆ«:")
            print(f"  - ç»“æ„: {stats['segs_count']}çº¿æ®µ, {stats['zhongshus_count']}ä¸­æ¢")
            print(f"  - ä¿¡å·: {stats['buy_sell_points_count']}ä¹°å–ç‚¹")
            print(f"  - è¶‹åŠ¿: {stats['trend_direction']} (å¼ºåº¦:{stats['trend_strength']:.1%})")
            print(f"  - ä¸€è‡´æ€§å¾—åˆ†: {result.level_consistency_score:.3f}")
            
            # æ˜¾ç¤ºæœ€æ–°ä¿¡å·
            latest_signals = result.get_latest_signals(2)
            if latest_signals:
                print(f"  - æœ€æ–°ä¿¡å·: {latest_signals[0].point_type} @{latest_signals[0].price:.2f}")
        
        # éªŒè¯ç»“æœ
        self.assertGreaterEqual(len(results), 1)
        for level, result in results.items():
            self.assertIsInstance(result, ChanAnalysisResult)
            self.assertEqual(result.symbol, "000001.SZ")
            self.assertEqual(result.time_level, level)
    
    def test_quick_analyze_function(self):
        """æµ‹è¯•å¿«é€Ÿåˆ†æä¾¿æ·å‡½æ•°"""
        print("\\nğŸ” å¿«é€Ÿåˆ†æå‡½æ•°æµ‹è¯•")
        
        data = self._get_daily_data("000002.SZ", 150)
        if not data:
            self.skipTest("æ— æ³•è·å–æµ‹è¯•æ•°æ®")
        
        # ä½¿ç”¨ä¾¿æ·å‡½æ•°è¿›è¡Œå¿«é€Ÿåˆ†æ
        result = quick_analyze(data, "000002.SZ", TimeLevel.DAILY)
        
        self.assertIsInstance(result, ChanAnalysisResult)
        self.assertEqual(result.symbol, "000002.SZ")
        self.assertEqual(result.analysis_level, AnalysisLevel.STANDARD)
        
        stats = result.get_statistics()
        print(f"ğŸ“Š å¿«é€Ÿåˆ†æç»“æœ: {stats['segs_count']}çº¿æ®µ, {stats['buy_sell_points_count']}ä¹°å–ç‚¹")
    
    def test_engine_configuration(self):
        """æµ‹è¯•å¼•æ“é…ç½®åŠŸèƒ½"""
        print("\\nğŸ” å¼•æ“é…ç½®æµ‹è¯•")
        
        # è‡ªå®šä¹‰é…ç½®
        chan_config = ChanConfig()
        dynamics_config = DynamicsConfig(
            macd_params=(8, 21, 5),  # è‡ªå®šä¹‰MACDå‚æ•°
            backchi_threshold=0.7,   # æ›´ä¸¥æ ¼çš„èƒŒé©°é˜ˆå€¼
        )
        
        # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»ºå¼•æ“
        custom_engine = ChanEngine(chan_config, dynamics_config)
        
        self.assertEqual(custom_engine.dynamics_config.macd_params, (8, 21, 5))
        self.assertEqual(custom_engine.dynamics_config.backchi_threshold, 0.7)
        
        print(f"âœ… è‡ªå®šä¹‰MACDå‚æ•°: {custom_engine.dynamics_config.macd_params}")
        print(f"âœ… è‡ªå®šä¹‰èƒŒé©°é˜ˆå€¼: {custom_engine.dynamics_config.backchi_threshold}")
    
    def test_analysis_cache(self):
        """æµ‹è¯•åˆ†æç¼“å­˜åŠŸèƒ½"""
        print("\\nğŸ” åˆ†æç¼“å­˜æµ‹è¯•")
        
        data = self._get_daily_data("000001.SZ", 100)
        if not data:
            self.skipTest("æ— æ³•è·å–æµ‹è¯•æ•°æ®")
        
        # ç¬¬ä¸€æ¬¡åˆ†æ
        result1 = self.chan_engine.analyze(data, "000001.SZ", TimeLevel.DAILY)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"000001.SZ_{TimeLevel.DAILY.value}_{AnalysisLevel.STANDARD.value}"
        self.assertIn(cache_key, self.chan_engine._analysis_cache)
        
        # æ¸…ç©ºç¼“å­˜
        self.chan_engine.clear_cache()
        self.assertEqual(len(self.chan_engine._analysis_cache), 0)
        
        print(f"âœ… ç¼“å­˜åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    def _get_daily_data(self, stock_code: str, limit: int) -> List[Dict]:
        """è·å–æ—¥çº¿æ•°æ®"""
        try:
            collection = self.db['stock_kline_daily']
            query = {'ts_code': stock_code}
            cursor = collection.find(query).sort('trade_date', 1).limit(limit)
            raw_data = list(cursor)
            
            converted_data = []
            for item in raw_data:
                try:
                    trade_date_str = str(item['trade_date'])
                    timestamp = datetime.strptime(trade_date_str, '%Y%m%d')
                    
                    converted_item = {
                        'timestamp': timestamp,
                        'open': float(item['open']),
                        'high': float(item['high']),
                        'low': float(item['low']),
                        'close': float(item['close']),
                        'volume': int(float(item['vol'])),
                        'amount': float(item.get('amount', 0)),
                        'symbol': item['ts_code']
                    }
                    
                    if all(converted_item[k] > 0 for k in ['open', 'high', 'low', 'close']):
                        converted_data.append(converted_item)
                        
                except Exception:
                    continue
            
            return converted_data
            
        except Exception as e:
            print(f"è·å–æ—¥çº¿æ•°æ®å¤±è´¥: {e}")
            return []
    
    def _get_minute_data(self, stock_code: str, collection_name: str, limit: int) -> List[Dict]:
        """è·å–åˆ†é’Ÿæ•°æ®"""
        try:
            collection = self.db[collection_name]
            query = {'ts_code': stock_code}
            cursor = collection.find(query).sort('trade_time', -1).limit(limit)
            raw_data = list(cursor)
            raw_data.reverse()  # è½¬ä¸ºå‡åº
            
            converted_data = []
            for item in raw_data:
                try:
                    if 'trade_time' in item:
                        timestamp_str = str(item['trade_time'])
                        timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
                    else:
                        continue
                    
                    converted_item = {
                        'timestamp': timestamp,
                        'open': float(item['open']),
                        'high': float(item['high']),
                        'low': float(item['low']),
                        'close': float(item['close']),
                        'volume': int(float(item.get('vol', item.get('volume', 1)))),
                        'amount': float(item.get('amount', 0)),
                        'symbol': item['ts_code']
                    }
                    
                    if all(converted_item[k] > 0 for k in ['open', 'high', 'low', 'close']):
                        converted_data.append(converted_item)
                        
                except Exception:
                    continue
            
            return converted_data
            
        except Exception as e:
            print(f"è·å–åˆ†é’Ÿæ•°æ®å¤±è´¥: {e}")
            return []


if __name__ == '__main__':
    print("ğŸ”¥ ç¼ è®ºåˆ†æå¼•æ“é›†æˆæµ‹è¯•")
    print("=" * 60)
    print("ğŸ“‹ æµ‹è¯•å†…å®¹ï¼š")
    print("  - åŸºç¡€åˆ†æåŠŸèƒ½æµ‹è¯•")
    print("  - æ ‡å‡†åˆ†æåŠŸèƒ½æµ‹è¯•ï¼ˆå½¢æ€å­¦+åŠ¨åŠ›å­¦ï¼‰")
    print("  - å®Œæ•´åˆ†æåŠŸèƒ½æµ‹è¯•ï¼ˆå«ç»¼åˆè¯„ä¼°ï¼‰")
    print("  - å¤šçº§åˆ«åˆ†æåŠŸèƒ½æµ‹è¯•")
    print("  - ä¾¿æ·å‡½æ•°æµ‹è¯•")
    print("  - å¼•æ“é…ç½®æµ‹è¯•")
    print("  - å±•ç¤ºå®Œæ•´çš„ç¼ è®ºv2æ¨¡å—åŠŸèƒ½")
    print("=" * 60)
    
    unittest.main(verbosity=2)