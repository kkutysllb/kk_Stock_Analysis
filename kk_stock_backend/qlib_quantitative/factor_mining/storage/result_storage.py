#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»“æœå­˜å‚¨ç®¡ç†å™¨ - å› å­æŒ–æ˜ç»“æœçš„æ•°æ®åº“å­˜å‚¨
è´Ÿè´£å°†å› å­åˆ†æã€é€‰æ‹©ã€æ¨¡å‹è®­ç»ƒå’Œç­–ç•¥è¿è¡Œç»“æœå­˜å‚¨åˆ°MongoDB
"""

import os
import sys
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Union
from datetime import datetime
import yaml
import logging
import json
from dataclasses import asdict

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))))
from api.global_db import db_handler
from qlib_quantitative.factor_mining.core.factor_analyzer import FactorAnalysisResult
from qlib_quantitative.factor_mining.core.factor_selector import FactorSelectionResult
from qlib_quantitative.factor_mining.core.model_trainer import ModelResult


class ResultStorage:
    """
    ç»“æœå­˜å‚¨ç®¡ç†å™¨
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. å› å­åˆ†æç»“æœå­˜å‚¨
    2. å› å­é€‰æ‹©ç»“æœå­˜å‚¨
    3. æ¨¡å‹è®­ç»ƒç»“æœå­˜å‚¨
    4. ç­–ç•¥è¿è¡Œç»“æœå­˜å‚¨
    5. å†å²ç»“æœæŸ¥è¯¢å’Œç®¡ç†
    """
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–ç»“æœå­˜å‚¨ç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.logger = self._setup_logger()
        
        # åŠ è½½é…ç½®
        if config_path is None:
            config_path = os.path.join(os.path.dirname(__file__), "../config/factor_mining_config.yaml")
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
            self.logger.info(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            raise
        
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        self.db_handler = db_handler
        
        # é›†åˆåç§°é…ç½®
        storage_config = self.config['storage_config']['collections']
        self.collections = {
            'factors': storage_config['factors'],
            'models': storage_config['models'],
            'results': storage_config['results'],
            'evaluations': storage_config['evaluations']
        }
        
        # ç¡®ä¿é›†åˆå­˜åœ¨
        self._ensure_collections()
        
        self.logger.info("ğŸš€ ç»“æœå­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _ensure_collections(self):
        """ç¡®ä¿é›†åˆå­˜åœ¨"""
        try:
            for collection_name in self.collections.values():
                collection = self.db_handler.get_collection(collection_name)
                # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»º
                collection.count_documents({})
            
            self.logger.info("âœ… æ•°æ®åº“é›†åˆæ£€æŸ¥å®Œæˆ")
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“é›†åˆæ£€æŸ¥å¤±è´¥: {e}")
    
    def save_factor_analysis_results(self, 
                                   analysis_results: Dict[str, Dict[str, FactorAnalysisResult]],
                                   metadata: Dict[str, Any] = None) -> str:
        """
        ä¿å­˜å› å­åˆ†æç»“æœ
        
        Args:
            analysis_results: å› å­åˆ†æç»“æœ
            metadata: å…ƒæ•°æ®
            
        Returns:
            ä¿å­˜çš„æ–‡æ¡£ID
        """
        try:
            self.logger.info("ğŸ’¾ ä¿å­˜å› å­åˆ†æç»“æœ")
            
            # è½¬æ¢ç»“æœæ ¼å¼
            formatted_results = {}
            for period, results in analysis_results.items():
                formatted_results[period] = {}
                for factor_name, result in results.items():
                    formatted_results[period][factor_name] = result.to_dict()
            
            # åˆ›å»ºæ–‡æ¡£
            document = {
                'type': 'factor_analysis',
                'results': formatted_results,
                'metadata': metadata or {},
                'created_at': datetime.now(),
                'version': '1.0'
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            collection = self.db_handler.get_collection(self.collections['results'])
            result = collection.insert_one(document)
            
            self.logger.info(f"âœ… å› å­åˆ†æç»“æœå·²ä¿å­˜: {result.inserted_id}")
            return str(result.inserted_id)
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜å› å­åˆ†æç»“æœå¤±è´¥: {e}")
            return ""
    
    def save_factor_selection_results(self,
                                    selection_results: Dict[str, FactorSelectionResult],
                                    metadata: Dict[str, Any] = None) -> str:
        """
        ä¿å­˜å› å­é€‰æ‹©ç»“æœ
        
        Args:
            selection_results: å› å­é€‰æ‹©ç»“æœ
            metadata: å…ƒæ•°æ®
            
        Returns:
            ä¿å­˜çš„æ–‡æ¡£ID
        """
        try:
            self.logger.info("ğŸ’¾ ä¿å­˜å› å­é€‰æ‹©ç»“æœ")
            
            # è½¬æ¢ç»“æœæ ¼å¼
            formatted_results = {}
            for method, result in selection_results.items():
                formatted_results[method] = result.to_dict()
            
            # åˆ›å»ºæ–‡æ¡£
            document = {
                'type': 'factor_selection',
                'results': formatted_results,
                'metadata': metadata or {},
                'created_at': datetime.now(),
                'version': '1.0'
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            collection = self.db_handler.get_collection(self.collections['results'])
            result = collection.insert_one(document)
            
            self.logger.info(f"âœ… å› å­é€‰æ‹©ç»“æœå·²ä¿å­˜: {result.inserted_id}")
            return str(result.inserted_id)
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜å› å­é€‰æ‹©ç»“æœå¤±è´¥: {e}")
            return ""
    
    def save_model_training_results(self,
                                  training_results: Dict[str, ModelResult],
                                  metadata: Dict[str, Any] = None) -> str:
        """
        ä¿å­˜æ¨¡å‹è®­ç»ƒç»“æœ
        
        Args:
            training_results: æ¨¡å‹è®­ç»ƒç»“æœ
            metadata: å…ƒæ•°æ®
            
        Returns:
            ä¿å­˜çš„æ–‡æ¡£ID
        """
        try:
            self.logger.info("ğŸ’¾ ä¿å­˜æ¨¡å‹è®­ç»ƒç»“æœ")
            
            # è½¬æ¢ç»“æœæ ¼å¼
            formatted_results = {}
            for model_name, result in training_results.items():
                formatted_results[model_name] = result.to_dict()
            
            # åˆ›å»ºæ–‡æ¡£
            document = {
                'type': 'model_training',
                'results': formatted_results,
                'metadata': metadata or {},
                'created_at': datetime.now(),
                'version': '1.0'
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            collection = self.db_handler.get_collection(self.collections['models'])
            result = collection.insert_one(document)
            
            self.logger.info(f"âœ… æ¨¡å‹è®­ç»ƒç»“æœå·²ä¿å­˜: {result.inserted_id}")
            return str(result.inserted_id)
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æ¨¡å‹è®­ç»ƒç»“æœå¤±è´¥: {e}")
            return ""
    
    def save_strategy_results(self,
                            strategy_result: Dict[str, Any],
                            metadata: Dict[str, Any] = None) -> str:
        """
        ä¿å­˜ç­–ç•¥è¿è¡Œç»“æœ
        
        Args:
            strategy_result: ç­–ç•¥è¿è¡Œç»“æœ
            metadata: å…ƒæ•°æ®
            
        Returns:
            ä¿å­˜çš„æ–‡æ¡£ID
        """
        try:
            self.logger.info("ğŸ’¾ ä¿å­˜ç­–ç•¥è¿è¡Œç»“æœ")
            
            # åˆ›å»ºæ–‡æ¡£
            document = {
                'type': 'strategy_execution',
                'result': strategy_result,
                'metadata': metadata or {},
                'created_at': datetime.now(),
                'version': '1.0'
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            collection = self.db_handler.get_collection(self.collections['results'])
            result = collection.insert_one(document)
            
            self.logger.info(f"âœ… ç­–ç•¥è¿è¡Œç»“æœå·²ä¿å­˜: {result.inserted_id}")
            return str(result.inserted_id)
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ç­–ç•¥è¿è¡Œç»“æœå¤±è´¥: {e}")
            return ""
    
    def save_factor_importance(self,
                             factor_importance: Dict[str, float],
                             model_name: str,
                             period: str,
                             metadata: Dict[str, Any] = None) -> str:
        """
        ä¿å­˜å› å­é‡è¦æ€§
        
        Args:
            factor_importance: å› å­é‡è¦æ€§å­—å…¸
            model_name: æ¨¡å‹åç§°
            period: é¢„æµ‹å‘¨æœŸ
            metadata: å…ƒæ•°æ®
            
        Returns:
            ä¿å­˜çš„æ–‡æ¡£ID
        """
        try:
            self.logger.info("ğŸ’¾ ä¿å­˜å› å­é‡è¦æ€§")
            
            # åˆ›å»ºæ–‡æ¡£
            document = {
                'type': 'factor_importance',
                'model_name': model_name,
                'period': period,
                'factor_importance': factor_importance,
                'metadata': metadata or {},
                'created_at': datetime.now(),
                'version': '1.0'
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            collection = self.db_handler.get_collection(self.collections['factors'])
            result = collection.insert_one(document)
            
            self.logger.info(f"âœ… å› å­é‡è¦æ€§å·²ä¿å­˜: {result.inserted_id}")
            return str(result.inserted_id)
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜å› å­é‡è¦æ€§å¤±è´¥: {e}")
            return ""
    
    def get_latest_factor_analysis(self, 
                                 period: str = '20d',
                                 limit: int = 1) -> List[Dict[str, Any]]:
        """
        è·å–æœ€æ–°çš„å› å­åˆ†æç»“æœ
        
        Args:
            period: é¢„æµ‹å‘¨æœŸ
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            å› å­åˆ†æç»“æœåˆ—è¡¨
        """
        try:
            collection = self.db_handler.get_collection(self.collections['results'])
            
            query = {'type': 'factor_analysis'}
            cursor = collection.find(query).sort('created_at', -1).limit(limit)
            
            results = []
            for doc in cursor:
                # æå–æŒ‡å®šå‘¨æœŸçš„ç»“æœ
                if period in doc.get('results', {}):
                    results.append({
                        'id': str(doc['_id']),
                        'period': period,
                        'results': doc['results'][period],
                        'metadata': doc.get('metadata', {}),
                        'created_at': doc['created_at']
                    })
            
            self.logger.info(f"ğŸ“Š è·å–äº†{len(results)}ä¸ªå› å­åˆ†æç»“æœ")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–å› å­åˆ†æç»“æœå¤±è´¥: {e}")
            return []
    
    def get_latest_model_results(self, 
                               model_type: str = None,
                               limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æœ€æ–°çš„æ¨¡å‹è®­ç»ƒç»“æœ
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ç­›é€‰
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            æ¨¡å‹ç»“æœåˆ—è¡¨
        """
        try:
            collection = self.db_handler.get_collection(self.collections['models'])
            
            query = {'type': 'model_training'}
            cursor = collection.find(query).sort('created_at', -1).limit(limit)
            
            results = []
            for doc in cursor:
                doc_results = doc.get('results', {})
                
                # å¦‚æœæŒ‡å®šäº†æ¨¡å‹ç±»å‹ï¼Œè¿›è¡Œç­›é€‰
                if model_type:
                    filtered_results = {
                        name: result for name, result in doc_results.items()
                        if result.get('model_type') == model_type
                    }
                    if not filtered_results:
                        continue
                    doc_results = filtered_results
                
                results.append({
                    'id': str(doc['_id']),
                    'results': doc_results,
                    'metadata': doc.get('metadata', {}),
                    'created_at': doc['created_at']
                })
            
            self.logger.info(f"ğŸ“Š è·å–äº†{len(results)}ä¸ªæ¨¡å‹è®­ç»ƒç»“æœ")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–æ¨¡å‹è®­ç»ƒç»“æœå¤±è´¥: {e}")
            return []
    
    def get_factor_performance_history(self, 
                                     factor_name: str,
                                     days: int = 30) -> List[Dict[str, Any]]:
        """
        è·å–å› å­å†å²è¡¨ç°
        
        Args:
            factor_name: å› å­åç§°
            days: å†å²å¤©æ•°
            
        Returns:
            å› å­å†å²è¡¨ç°åˆ—è¡¨
        """
        try:
            collection = self.db_handler.get_collection(self.collections['results'])
            
            # è®¡ç®—æŸ¥è¯¢èµ·å§‹æ—¥æœŸ
            start_date = datetime.now() - pd.Timedelta(days=days)
            
            query = {
                'type': 'factor_analysis',
                'created_at': {'$gte': start_date}
            }
            
            cursor = collection.find(query).sort('created_at', -1)
            
            history = []
            for doc in cursor:
                results = doc.get('results', {})
                
                # æŸ¥æ‰¾åŒ…å«æŒ‡å®šå› å­çš„ç»“æœ
                for period, factors in results.items():
                    if factor_name in factors:
                        factor_data = factors[factor_name]
                        history.append({
                            'date': doc['created_at'],
                            'period': period,
                            'factor_name': factor_name,
                            'ic_mean': factor_data.get('ic_mean', 0),
                            'ic_ir': factor_data.get('ic_ir', 0),
                            'significance': factor_data.get('significance', False),
                            'sharpe_ratio': factor_data.get('sharpe_ratio', 0)
                        })
            
            self.logger.info(f"ğŸ“Š è·å–äº†{factor_name}çš„{len(history)}æ¡å†å²è®°å½•")
            return history
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–å› å­å†å²è¡¨ç°å¤±è´¥: {e}")
            return []
    
    def get_best_models_summary(self, 
                              top_k: int = 10,
                              metric: str = 'r2') -> List[Dict[str, Any]]:
        """
        è·å–æœ€ä½³æ¨¡å‹æ±‡æ€»
        
        Args:
            top_k: è¿”å›å‰Kä¸ªæ¨¡å‹
            metric: è¯„ä¼°æŒ‡æ ‡
            
        Returns:
            æœ€ä½³æ¨¡å‹æ±‡æ€»åˆ—è¡¨
        """
        try:
            collection = self.db_handler.get_collection(self.collections['models'])
            
            query = {'type': 'model_training'}
            cursor = collection.find(query).sort('created_at', -1)
            
            all_models = []
            for doc in cursor:
                results = doc.get('results', {})
                created_at = doc['created_at']
                
                for model_name, model_data in results.items():
                    val_metrics = model_data.get('val_metrics', {})
                    if metric in val_metrics:
                        all_models.append({
                            'model_name': model_name,
                            'model_type': model_data.get('model_type', ''),
                            'metric_value': val_metrics[metric],
                            'train_r2': model_data.get('train_metrics', {}).get('r2', 0),
                            'val_r2': val_metrics.get('r2', 0),
                            'test_r2': model_data.get('test_metrics', {}).get('r2', 0),
                            'cv_score': model_data.get('cross_val_score', 0),
                            'training_time': model_data.get('training_time', 0),
                            'created_at': created_at,
                            'document_id': str(doc['_id'])
                        })
            
            # æ’åºå¹¶å–å‰Kä¸ª
            reverse = metric == 'r2'  # RÂ²é™åºï¼Œå…¶ä»–å‡åº
            all_models.sort(key=lambda x: x['metric_value'], reverse=reverse)
            
            best_models = all_models[:top_k]
            
            self.logger.info(f"ğŸ“Š è·å–äº†å‰{len(best_models)}ä¸ªæœ€ä½³æ¨¡å‹")
            return best_models
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–æœ€ä½³æ¨¡å‹æ±‡æ€»å¤±è´¥: {e}")
            return []
    
    def cleanup_old_results(self, days: int = 30) -> int:
        """
        æ¸…ç†æ—§çš„ç»“æœè®°å½•
        
        Args:
            days: ä¿ç•™å¤©æ•°
            
        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        try:
            self.logger.info(f"ğŸ—‘ï¸ æ¸…ç†{days}å¤©å‰çš„æ—§ç»“æœ")
            
            cutoff_date = datetime.now() - pd.Timedelta(days=days)
            query = {'created_at': {'$lt': cutoff_date}}
            
            total_deleted = 0
            
            # æ¸…ç†å„ä¸ªé›†åˆ
            for collection_name in self.collections.values():
                collection = self.db_handler.get_collection(collection_name)
                result = collection.delete_many(query)
                total_deleted += result.deleted_count
                
                self.logger.info(f"  {collection_name}: åˆ é™¤äº†{result.deleted_count}æ¡è®°å½•")
            
            self.logger.info(f"âœ… æ€»å…±åˆ é™¤äº†{total_deleted}æ¡æ—§è®°å½•")
            return total_deleted
            
        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç†æ—§ç»“æœå¤±è´¥: {e}")
            return 0
    
    def export_results_to_json(self, 
                             result_type: str,
                             output_path: str,
                             days: int = 7) -> bool:
        """
        å¯¼å‡ºç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            result_type: ç»“æœç±»å‹
            output_path: è¾“å‡ºè·¯å¾„
            days: å¯¼å‡ºå¤©æ•°
            
        Returns:
            å¯¼å‡ºæ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info(f"ğŸ“¤ å¯¼å‡º{result_type}ç»“æœåˆ°{output_path}")
            
            # ç¡®å®šé›†åˆ
            if result_type in ['factor_analysis', 'factor_selection', 'strategy_execution']:
                collection = self.db_handler.get_collection(self.collections['results'])
            elif result_type == 'model_training':
                collection = self.db_handler.get_collection(self.collections['models'])
            elif result_type == 'factor_importance':
                collection = self.db_handler.get_collection(self.collections['factors'])
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ç»“æœç±»å‹: {result_type}")
            
            # æŸ¥è¯¢æ•°æ®
            start_date = datetime.now() - pd.Timedelta(days=days)
            query = {
                'type': result_type,
                'created_at': {'$gte': start_date}
            }
            
            cursor = collection.find(query).sort('created_at', -1)
            
            # è½¬æ¢æ•°æ®
            results = []
            for doc in cursor:
                # ç§»é™¤_idå­—æ®µå¹¶è½¬æ¢æ—¥æœŸ
                doc_dict = dict(doc)
                doc_dict.pop('_id', None)
                
                # è½¬æ¢datetimeå¯¹è±¡ä¸ºå­—ç¬¦ä¸²
                if 'created_at' in doc_dict:
                    doc_dict['created_at'] = doc_dict['created_at'].isoformat()
                
                results.append(doc_dict)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"âœ… å¯¼å‡ºå®Œæˆ: {len(results)}æ¡è®°å½•")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ å¯¼å‡ºç»“æœå¤±è´¥: {e}")
            return False
    
    def get_storage_statistics(self) -> Dict[str, Any]:
        """
        è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            stats = {
                'collections': {},
                'total_documents': 0,
                'storage_size_mb': 0,
                'latest_update': None
            }
            
            for name, collection_name in self.collections.items():
                collection = self.db_handler.get_collection(collection_name)
                
                # æ–‡æ¡£æ•°é‡
                count = collection.count_documents({})
                stats['collections'][name] = {
                    'collection_name': collection_name,
                    'document_count': count
                }
                stats['total_documents'] += count
                
                # æœ€æ–°æ›´æ–°æ—¶é—´
                if count > 0:
                    latest_doc = collection.find().sort('created_at', -1).limit(1)
                    latest_doc = list(latest_doc)
                    if latest_doc:
                        latest_time = latest_doc[0].get('created_at')
                        if latest_time and (stats['latest_update'] is None or latest_time > stats['latest_update']):
                            stats['latest_update'] = latest_time
            
            # æ ¼å¼åŒ–æœ€æ–°æ›´æ–°æ—¶é—´
            if stats['latest_update']:
                stats['latest_update'] = stats['latest_update'].isoformat()
            
            self.logger.info(f"ğŸ“Š å­˜å‚¨ç»Ÿè®¡: {stats['total_documents']}ä¸ªæ–‡æ¡£")
            return stats
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {e}")
            return {}


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸš€ æµ‹è¯•ç»“æœå­˜å‚¨ç®¡ç†å™¨...")
    
    try:
        storage = ResultStorage()
        
        # è·å–å­˜å‚¨ç»Ÿè®¡
        stats = storage.get_storage_statistics()
        print("ğŸ“Š å­˜å‚¨ç»Ÿè®¡:")
        for name, info in stats['collections'].items():
            print(f"  {name}: {info['document_count']}ä¸ªæ–‡æ¡£")
        
        print(f"æ€»æ–‡æ¡£æ•°: {stats['total_documents']}")
        print(f"æœ€æ–°æ›´æ–°: {stats['latest_update']}")
        
        # è·å–æœ€æ–°æ¨¡å‹ç»“æœ
        model_results = storage.get_latest_model_results(limit=3)
        print(f"\nğŸ“Š æœ€æ–°æ¨¡å‹ç»“æœ: {len(model_results)}æ¡")
        
        # è·å–æœ€ä½³æ¨¡å‹æ±‡æ€»
        best_models = storage.get_best_models_summary(top_k=5)
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹:")
        for i, model in enumerate(best_models[:3], 1):
            print(f"  {i}. {model['model_name']} (RÂ²: {model['val_r2']:.4f})")
        
        print("âœ… ç»“æœå­˜å‚¨ç®¡ç†å™¨æµ‹è¯•æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()