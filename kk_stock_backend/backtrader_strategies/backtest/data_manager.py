#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®ç®¡ç†å™¨
è´Ÿè´£ä»æ•°æ®åº“åŠ è½½å†å²æ•°æ®ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®æ¥å£
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from api.global_db import db_handler
from backtrader_strategies.config import DatabaseConfig


class DataManager:
    """
    æ•°æ®ç®¡ç†å™¨
    è´Ÿè´£åŠ è½½å’Œç®¡ç†å†å²å¸‚åœºæ•°æ®
    """
    
    def __init__(self, db_config: Optional[DatabaseConfig] = None):
        """
        åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        
        Args:
            db_config: æ•°æ®åº“é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.db_config = db_config or DatabaseConfig()
        self.db_handler = db_handler
        self.data_cache = {}  # æ•°æ®ç¼“å­˜
        self.stock_universe = []  # è‚¡ç¥¨æ± 
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
    def load_stock_universe(self, index_code: str = "000510.CSI") -> List[str]:
        """
        åŠ è½½è‚¡ç¥¨æ± ï¼ˆé»˜è®¤ä¸­è¯A500ï¼‰
        
        Args:
            index_code: æŒ‡æ•°ä»£ç 
            
        Returns:
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        try:
            self.logger.info(f"åŠ è½½è‚¡ç¥¨æ± : {index_code}")
            
            # è·å–æŒ‡æ•°æƒé‡é›†åˆ
            index_collection = self.db_handler.get_collection('index_weight')
            
            # æŸ¥è¯¢æœ€æ–°çš„æˆåˆ†è‚¡
            query = {'index_code': index_code}
            cursor = index_collection.find(query).sort('trade_date', -1).limit(1000)
            
            stock_codes = []
            latest_date = None
            
            for doc in cursor:
                current_date = doc.get('trade_date')
                if latest_date is None:
                    latest_date = current_date
                elif current_date != latest_date:
                    break  # åªå–æœ€æ–°æ—¥æœŸçš„æ•°æ®
                    
                if 'con_code' in doc and doc['con_code']:
                    stock_codes.append(doc['con_code'])
            
            # å»é‡å¹¶æ’åº
            self.stock_universe = sorted(list(set(stock_codes)))
            
            self.logger.info(f"åŠ è½½å®Œæˆï¼Œè‚¡ç¥¨æ•°é‡: {len(self.stock_universe)}")
            return self.stock_universe
            
        except Exception as e:
            self.logger.error(f"åŠ è½½è‚¡ç¥¨æ± å¤±è´¥: {e}")
            # è¿”å›ä¸€äº›é»˜è®¤è‚¡ç¥¨ç”¨äºæµ‹è¯•
            self.stock_universe = []
            return self.stock_universe
    
    def load_all_market_universe(self) -> List[str]:
        """
        åŠ è½½å…¨å¸‚åœºè‚¡ç¥¨æ± 
        æ³¨æ„ï¼šæ­¤æ–¹æ³•åªæä¾›åŸºç¡€æ•°æ®æºï¼Œå…·ä½“çš„ç­›é€‰ã€è¯„åˆ†ã€é€‰è‚¡ç”±ç­–ç•¥é€‚é…å™¨è´Ÿè´£
        
        Returns:
            å…¨å¸‚åœºè‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆåŸºç¡€æ•°æ®æºï¼Œä¸åšä»»ä½•ç­›é€‰ï¼‰
        """
        try:
            self.logger.info(f"åŠ è½½å…¨å¸‚åœºåŸºç¡€è‚¡ç¥¨æ± ")
            
            # è·å–å…¨å¸‚åœºè‚¡ç¥¨ï¼ˆä»è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è¡¨è·å–æ‰€æœ‰æœ‰æ•ˆè‚¡ç¥¨ï¼‰
            stock_basic_collection = self.db_handler.get_collection('infrastructure_stock_basic')
            
            # æŸ¥è¯¢æ‰€æœ‰Aè‚¡å¸‚åœºè‚¡ç¥¨
            query = {
                'market': {'$in': ['ä¸»æ¿', 'ä¸­å°æ¿', 'åˆ›ä¸šæ¿', 'ç§‘åˆ›æ¿']},  # Aè‚¡å¸‚åœº
            }
            projection = {'ts_code': 1, '_id': 0}
            
            cursor = stock_basic_collection.find(query, projection)
            stock_codes = [doc['ts_code'] for doc in cursor if doc.get('ts_code')]
            
            # åŸºæœ¬è¿‡æ»¤ï¼šåªä¿ç•™æ­£å¸¸çš„Aè‚¡ä»£ç æ ¼å¼
            filtered_stock_codes = []
            for code in stock_codes:
                if code and (code.endswith('.SZ') or code.endswith('.SH')):
                    filtered_stock_codes.append(code)
            
            stock_codes = sorted(filtered_stock_codes)
            
            self.logger.info(f"å…¨å¸‚åœºåŸºç¡€è‚¡ç¥¨æ± åŠ è½½å®Œæˆï¼Œæ€»æ•°é‡: {len(stock_codes)}åªè‚¡ç¥¨")
            self.logger.info("ğŸ“ æ³¨æ„ï¼šæ•°æ®ç®¡ç†å™¨ä»…æä¾›åŸºç¡€æ•°æ®æºï¼Œå…·ä½“é€‰è‚¡ã€è¯„åˆ†ã€è°ƒä»“ç”±ç­–ç•¥é€‚é…å™¨è´Ÿè´£")
            
            # æ›´æ–°è‚¡ç¥¨æ± 
            self.stock_universe = stock_codes
            
            return self.stock_universe
            
        except Exception as e:
            self.logger.error(f"åŠ è½½å…¨å¸‚åœºåŸºç¡€è‚¡ç¥¨æ± å¤±è´¥: {e}")
            # å¦‚æœæ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œè¿™æ˜¯ç³»ç»Ÿé—®é¢˜ï¼Œä¸åº”è¯¥é™çº§
            raise e
    
    def load_stock_data(self, 
                       stock_code: str, 
                       start_date: str, 
                       end_date: str,
                       include_indicators: bool = True) -> pd.DataFrame:
        """
        åŠ è½½å•åªè‚¡ç¥¨çš„å†å²æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            include_indicators: æ˜¯å¦åŒ…å«æŠ€æœ¯æŒ‡æ ‡
            
        Returns:
            è‚¡ç¥¨å†å²æ•°æ®DataFrame
        """
        cache_key = f"{stock_code}_{start_date}_{end_date}_{include_indicators}"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.data_cache:
            return self.data_cache[cache_key].copy()
        
        try:
            collection = self.db_handler.get_collection(self.db_config.factor_collection)
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            start_date_str = start_date.replace('-', '')
            end_date_str = end_date.replace('-', '')
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {
                'ts_code': stock_code,
                'trade_date': {
                    '$gte': start_date_str,
                    '$lte': end_date_str
                }
            }
            
            # æŸ¥è¯¢æ•°æ®
            cursor = collection.find(query).sort('trade_date', 1)
            data_list = list(cursor)
            
            if not data_list:
                self.logger.warning(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} åœ¨ {start_date} åˆ° {end_date} æœŸé—´çš„æ•°æ®")
                return pd.DataFrame()
            
            # è°ƒè¯•è¾“å‡ºï¼šæ£€æŸ¥WRæŒ‡æ ‡æ˜¯å¦å­˜åœ¨
            if stock_code in ['002003.SZ', '600761.SH'] and data_list:
                sample_data = data_list[0]
                field_mapping = self.db_config.field_mapping
                wr1_source = field_mapping.get('wr1', 'wr1_bfq')
                wr2_source = field_mapping.get('wr2', 'wr_bfq')
                
                print(f"ğŸ” {stock_code} WRæŒ‡æ ‡æ£€æŸ¥:")
                print(f"   wr1å­—æ®µ: {wr1_source} ({'å­˜åœ¨' if wr1_source in sample_data else 'ä¸å­˜åœ¨'})")
                print(f"   wr2å­—æ®µ: {wr2_source} ({'å­˜åœ¨' if wr2_source in sample_data else 'ä¸å­˜åœ¨'})")
                if wr1_source in sample_data:
                    print(f"   wr1æ ·æœ¬å€¼: {sample_data.get(wr1_source)}")
                if wr2_source in sample_data:
                    print(f"   wr2æ ·æœ¬å€¼: {sample_data.get(wr2_source)}")
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data_list)
            
            # å¤„ç†æ—¥æœŸåˆ—
            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
            df.set_index('trade_date', inplace=True)
            
            # å­—æ®µæ˜ å°„å’Œé‡å‘½å
            field_mapping = self.db_config.field_mapping
            
            # åŸºç¡€OHLCVæ•°æ®å’Œå…³é”®å­—æ®µ
            required_fields = {
                'open': field_mapping.get('open', 'open'),
                'high': field_mapping.get('high', 'high'),
                'low': field_mapping.get('low', 'low'),
                'close': field_mapping.get('close', 'close'),
                'volume': field_mapping.get('volume', 'vol'),
                'amount': field_mapping.get('amount', 'amount'),
                'pre_close': field_mapping.get('pre_close', 'pre_close'),  # å‰æ”¶ç›˜ä»·
                'circ_mv': field_mapping.get('circ_mv', 'circ_mv')          # æµé€šå¸‚å€¼
            }
            
            # æ£€æŸ¥å¹¶é‡å‘½ååŸºç¡€å­—æ®µ
            result_df = pd.DataFrame(index=df.index)
            for target_field, source_field in required_fields.items():
                if source_field in df.columns:
                    result_df[target_field] = df[source_field]
                else:
                    self.logger.warning(f"ç¼ºå°‘å­—æ®µ: {source_field}")
                    result_df[target_field] = np.nan
            
            # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
            if include_indicators:
                # éœ€è¦åŠ è½½çš„æŠ€æœ¯æŒ‡æ ‡å­—æ®µï¼ˆåŸºäºå…¨é‡æ•°æ®åº“å­—æ®µæ˜ å°„ï¼‰ 
                indicator_field_names = [
                    # ==================== åŸºç¡€å¸‚åœºæ•°æ® ====================
                    'change', 'pct_chg', 'adj_factor',
                    
                    # ==================== å¤æƒä»·æ ¼æ•°æ® ====================
                    'open_hfq', 'high_hfq', 'low_hfq', 'close_hfq',
                    'open_qfq', 'high_qfq', 'low_qfq', 'close_qfq',
                    
                    # ==================== å¸‚å€¼å’Œä¼°å€¼æŒ‡æ ‡ ====================
                    'total_mv', 'circ_mv', 'pe', 'pe_ttm', 'pb', 'ps', 'ps_ttm',
                    'dv_ratio', 'dv_ttm', 'total_share', 'float_share', 'free_share',
                    
                    # ==================== æˆäº¤é‡å’ŒæµåŠ¨æ€§æŒ‡æ ‡ ====================
                    'turnover_rate', 'turnover_rate_f', 'volume_ratio',
                    
                    # ==================== ç§»åŠ¨å¹³å‡çº¿ç³»åˆ— ====================
                    # ç®€å•ç§»åŠ¨å¹³å‡(SMA) - ä¸å¤æƒ
                    'ma5', 'ma10', 'ma20', 'ma30', 'ma60', 'ma90', 'ma250',  # ç§»é™¤ma120(ä¸å­˜åœ¨)
                    # ç®€å•ç§»åŠ¨å¹³å‡(SMA) - åå¤æƒ  
                    'ma5_hfq', 'ma10_hfq', 'ma20_hfq', 'ma30_hfq', 'ma60_hfq', 'ma90_hfq', 'ma250_hfq',
                    # ç®€å•ç§»åŠ¨å¹³å‡(SMA) - å‰å¤æƒ
                    'ma5_qfq', 'ma10_qfq', 'ma20_qfq', 'ma30_qfq', 'ma60_qfq', 'ma90_qfq', 'ma250_qfq',
                    # æŒ‡æ•°ç§»åŠ¨å¹³å‡(EMA) - ä¸å¤æƒ
                    'ema5', 'ema10', 'ema20', 'ema30', 'ema60', 'ema90', 'ema250',
                    # æŒ‡æ•°ç§»åŠ¨å¹³å‡(EMA) - åå¤æƒ
                    'ema5_hfq', 'ema10_hfq', 'ema20_hfq', 'ema30_hfq', 'ema60_hfq', 'ema90_hfq', 'ema250_hfq',
                    # æŒ‡æ•°ç§»åŠ¨å¹³å‡(EMA) - å‰å¤æƒ  
                    'ema5_qfq', 'ema10_qfq', 'ema20_qfq', 'ema30_qfq', 'ema60_qfq', 'ema90_qfq', 'ema250_qfq',
                    # EXPMAæŒ‡æ•°ç§»åŠ¨å¹³å‡
                    'expma12', 'expma50', 'expma12_hfq', 'expma50_hfq', 'expma12_qfq', 'expma50_qfq',
                    
                    # ==================== RSIç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ç³»åˆ— ====================
                    'rsi6', 'rsi12', 'rsi24',
                    'rsi6_hfq', 'rsi12_hfq', 'rsi24_hfq',
                    'rsi6_qfq', 'rsi12_qfq', 'rsi24_qfq',
                    
                    # ==================== MACDæŒ‡æ ‡ç³»åˆ— ====================
                    'macd_dif', 'macd_dea', 'macd_macd',
                    'macd_dif_hfq', 'macd_dea_hfq', 'macd_macd_hfq',
                    'macd_dif_qfq', 'macd_dea_qfq', 'macd_macd_qfq',
                    
                    # ==================== å¸ƒæ—å¸¦æŒ‡æ ‡ç³»åˆ— ====================
                    'boll_upper', 'boll_mid', 'boll_lower',
                    'boll_upper_hfq', 'boll_mid_hfq', 'boll_lower_hfq',
                    'boll_upper_qfq', 'boll_mid_qfq', 'boll_lower_qfq',
                    
                    # ==================== KDJéšæœºæŒ‡æ ‡ç³»åˆ— ====================
                    'kdj_k', 'kdj_d', 'kdj_j',
                    'kdj_k_hfq', 'kdj_d_hfq', 'kdj_j_hfq',
                    'kdj_k_qfq', 'kdj_d_qfq', 'kdj_j_qfq',
                    
                    # ==================== å¨å»‰æŒ‡æ ‡ç³»åˆ— ====================
                    'wr', 'wr1',
                    'wr_hfq', 'wr1_hfq',
                    'wr_qfq', 'wr1_qfq',
                    
                    # ==================== BIASä¹–ç¦»ç‡æŒ‡æ ‡ç³»åˆ— ====================
                    'bias1', 'bias2', 'bias3',
                    'bias1_hfq', 'bias2_hfq', 'bias3_hfq',
                    'bias1_qfq', 'bias2_qfq', 'bias3_qfq',
                    
                    # ==================== DMIè¶‹å‘æŒ‡æ ‡ç³»åˆ— ====================
                    'dmi_pdi', 'dmi_mdi', 'dmi_adx', 'dmi_adxr',
                    'dmi_pdi_hfq', 'dmi_mdi_hfq', 'dmi_adx_hfq', 'dmi_adxr_hfq',
                    'dmi_pdi_qfq', 'dmi_mdi_qfq', 'dmi_adx_qfq', 'dmi_adxr_qfq',
                    
                    # ==================== BRARäººæ°”æ„æ„¿æŒ‡æ ‡ç³»åˆ— ====================
                    'brar_ar', 'brar_br',
                    'brar_ar_hfq', 'brar_br_hfq',
                    'brar_ar_qfq', 'brar_br_qfq',
                    
                    # ==================== å…¶ä»–é‡è¦æŠ€æœ¯æŒ‡æ ‡ ====================
                    'cci', 'cci_hfq', 'cci_qfq',                      # CCIå•†å“é€šé“æŒ‡æ•°
                    'atr', 'atr_hfq', 'atr_qfq',                      # ATRçœŸå®æ³¢å¹…
                    'roc', 'roc_hfq', 'roc_qfq',                      # ROCå˜åŠ¨ç‡
                    'mtm', 'mtm_hfq', 'mtm_qfq',                      # MTMåŠ¨é‡æŒ‡æ ‡
                    'psy', 'psy_hfq', 'psy_qfq',                      # PSYå¿ƒç†çº¿
                    'psyma', 'psyma_hfq', 'psyma_qfq',                # PSYMAå¿ƒç†çº¿ç§»åŠ¨å¹³å‡
                    'obv', 'obv_hfq', 'obv_qfq',                      # OBVç´¯ç§¯èƒ½é‡
                    'emv', 'emv_hfq', 'emv_qfq',                      # EMVç®€æ˜“æ³¢åŠ¨
                    'mfi', 'mfi_hfq', 'mfi_qfq',                      # MFIèµ„é‡‘æµé‡
                    'vr', 'vr_hfq', 'vr_qfq',                         # VRæˆäº¤é‡å˜å¼‚ç‡
                    'mass', 'mass_hfq', 'mass_qfq',                   # MASSæ¢…æ–¯çº¿
                    'ma_mass', 'ma_mass_hfq', 'ma_mass_qfq',          # MA_MASSæ¢…æ–¯çº¿ç§»åŠ¨å¹³å‡
                    'cr', 'cr_hfq', 'cr_qfq',                         # CRæŒ‡æ ‡
                    'asi', 'asit', 'asi_hfq', 'asit_hfq', 'asi_qfq', 'asit_qfq', # ASIæŒ¯åŠ¨å‡é™æŒ‡æ ‡
                    'trix', 'trix_hfq', 'trix_qfq',                   # TRIXä¸‰é‡æŒ‡æ•°å¹³æ»‘
                    'dpo', 'dpo_hfq', 'dpo_qfq',                      # DPOå»è¶‹åŠ¿ä»·æ ¼éœ‡è¡
                    'bbi', 'bbi_hfq', 'bbi_qfq',                      # BBIå¤šç©ºæŒ‡æ ‡
                    
                    # ==================== é«˜çº§æŠ€æœ¯æŒ‡æ ‡ ====================
                    'dfma_dif', 'dfma_difma',                         # DFMAåŠ¨æ€å¹³å‡
                    'dfma_dif_hfq', 'dfma_difma_hfq',
                    'dfma_dif_qfq', 'dfma_difma_qfq',
                    'ktn_upper', 'ktn_mid', 'ktn_down',               # KTNè‚¯ç‰¹çº³é€šé“
                    'ktn_upper_hfq', 'ktn_mid_hfq', 'ktn_down_hfq',
                    'ktn_upper_qfq', 'ktn_mid_qfq', 'ktn_down_qfq',
                    'taq_up', 'taq_mid', 'taq_down',                  # TAQæŠ›ç‰©çº¿æŒ‡æ ‡
                    'taq_up_hfq', 'taq_mid_hfq', 'taq_down_hfq',
                    'taq_up_qfq', 'taq_mid_qfq', 'taq_down_qfq',
                    'xsii_td1', 'xsii_td2', 'xsii_td3', 'xsii_td4',  # XSIIå°æ—¶å››åº¦ç©ºé—´æŒ‡æ ‡
                    'xsii_td1_hfq', 'xsii_td2_hfq', 'xsii_td3_hfq', 'xsii_td4_hfq',
                    'xsii_td1_qfq', 'xsii_td2_qfq', 'xsii_td3_qfq', 'xsii_td4_qfq',
                    
                    # ==================== æ¶¨è·Œç»Ÿè®¡æŒ‡æ ‡ ====================
                    'updays', 'downdays', 'topdays', 'lowdays',
                ]
                
                # ä½¿ç”¨field_mappingåŠ è½½æŒ‡æ ‡æ•°æ®
                for target_field in indicator_field_names:
                    if target_field == 'volume_ma20':
                        continue  # volume_ma20å°†åœ¨åé¢è®¡ç®—
                    
                    # ä»field_mappingè·å–å®é™…æ•°æ®åº“å­—æ®µå
                    source_field = field_mapping.get(target_field, target_field)
                    
                    if source_field in df.columns:
                        result_df[target_field] = df[source_field]
                    else:
                        # å¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œè®¾ä¸ºNaNå¹¶è®°å½•è­¦å‘Š
                        result_df[target_field] = np.nan
                        if target_field not in ['wr1', 'wr2']:  # å…¼å®¹æ€§å­—æ®µä¸è­¦å‘Š
                            self.logger.debug(f"æŠ€æœ¯æŒ‡æ ‡å­—æ®µ {target_field} ({source_field}) ä¸å­˜åœ¨")
            
            # æ•°æ®æ¸…ç† - åªå¯¹å¿…éœ€çš„ä»·æ ¼æ•°æ®åšä¸¥æ ¼æ£€æŸ¥
            result_df = result_df.dropna(subset=['open', 'high', 'low', 'close', 'volume'])
            
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'amount', 'pre_close', 'circ_mv']
            if include_indicators:
                # æ·»åŠ æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡å­—æ®µ
                numeric_columns.extend(indicator_field_names)
                numeric_columns.append('volume_ma20')  # æ·»åŠ è®¡ç®—å­—æ®µ
            
            for col in numeric_columns:
                if col in result_df.columns:
                    result_df[col] = pd.to_numeric(result_df[col], errors='coerce')
            
            # æœ€ç»ˆæ•°æ®éªŒè¯
            result_df = result_df.dropna(subset=['open', 'high', 'low', 'close'])
            
           
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            if include_indicators:
                # è®¡ç®—20æ—¥æˆäº¤é‡ç§»åŠ¨å¹³å‡
                result_df['volume_ma20'] = result_df['volume'].rolling(window=20, min_periods=1).mean()
                
                # è°ƒè¯•è¾“å‡ºï¼šæˆäº¤é‡è®¡ç®—å®Œæˆ
                if stock_code in ['002003.SZ', '600761.SH']:
                    print(f"   æˆäº¤é‡å‡çº¿è®¡ç®—å®Œæˆ: ç¬¬1å¤©{result_df['volume_ma20'].iloc[0]:.0f}")
            
            # æ·»åŠ å‰ä¸€æ—¥æ”¶ç›˜ä»·
            result_df['prev_close'] = result_df['close'].shift(1)
            
            # è®¡ç®—æ¶¨è·Œå¹…
            result_df['pct_change'] = result_df['close'].pct_change()
            
            # åˆå¹¶è´¢åŠ¡æ•°æ®
            result_df = self._merge_financial_data(result_df, stock_code, start_date, end_date)
            
            # æ·»åŠ åˆ°ç¼“å­˜
            self.data_cache[cache_key] = result_df.copy()
            
            self.logger.info(f"æˆåŠŸåŠ è½½è‚¡ç¥¨ {stock_code} æ•°æ®: {len(result_df)} æ¡è®°å½•")
            return result_df
            
        except Exception as e:
            self.logger.error(f"åŠ è½½è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
    
    def load_market_data(self, 
                        stock_codes: List[str], 
                        start_date: str, 
                        end_date: str,
                        max_stocks: int = 100,
                        strategy_scorer=None) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡åŠ è½½å¤šåªè‚¡ç¥¨çš„å†å²æ•°æ®
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_stocks: æœ€å¤§è‚¡ç¥¨æ•°é‡
            strategy_scorer: ç­–ç•¥è¯„åˆ†å‡½æ•°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è‚¡ç¥¨ä»£ç åˆ°æ•°æ®çš„æ˜ å°„å­—å…¸
        """
        market_data = {}
        
        # å¦‚æœæä¾›äº†ç­–ç•¥è¯„åˆ†å‡½æ•°ï¼Œä½¿ç”¨è¯„åˆ†é€‰æ‹©è‚¡ç¥¨
        if strategy_scorer and len(stock_codes) > max_stocks:
            self.logger.info(f"ä½¿ç”¨ç­–ç•¥è¯„åˆ†é€‰æ‹©æœ€ä¼˜ {max_stocks} åªè‚¡ç¥¨...")
            selected_stocks = self._select_stocks_by_strategy_score(
                stock_codes, start_date, end_date, max_stocks, strategy_scorer
            )
        else:
            # å¦åˆ™ä½¿ç”¨åˆ†å±‚é‡‡æ ·ç¡®ä¿ä¸åŒæ¿å—çš„è‚¡ç¥¨
            selected_stocks = self._select_stocks_by_sampling(stock_codes, max_stocks)
        
        self.logger.info(f"å¼€å§‹åŠ è½½ {len(selected_stocks)} åªè‚¡ç¥¨çš„å†å²æ•°æ®...")
        
        success_count = 0
        for i, stock_code in enumerate(selected_stocks):
            try:
                df = self.load_stock_data(
                    stock_code=stock_code,
                    start_date=start_date,
                    end_date=end_date,
                    include_indicators=True
                )
                
                if not df.empty and len(df) > 20:  # è‡³å°‘éœ€è¦20ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                    market_data[stock_code] = df
                    success_count += 1
                    
                    if (i + 1) % 10 == 0:  # æ¯10åªè‚¡ç¥¨è¾“å‡ºä¸€æ¬¡è¿›åº¦
                        self.logger.info(f"è¿›åº¦: {i+1}/{len(selected_stocks)}, æˆåŠŸ: {success_count}")
                else:
                    self.logger.warning(f"è‚¡ç¥¨ {stock_code} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                    
            except Exception as e:
                self.logger.error(f"åŠ è½½è‚¡ç¥¨ {stock_code} å¤±è´¥: {e}")
                continue
        
        self.logger.info(f"æ•°æ®åŠ è½½å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(selected_stocks)}")
        return market_data
    
    def get_trading_dates(self, start_date: str, end_date: str) -> List[str]:
        """
        è·å–æŒ‡å®šæœŸé—´çš„äº¤æ˜“æ—¥åˆ—è¡¨
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            äº¤æ˜“æ—¥åˆ—è¡¨
        """
        try:
            # ä»æ•°æ®åº“è·å–äº¤æ˜“æ—¥å†
            collection = self.db_handler.get_collection(self.db_config.factor_collection)
            
            start_date_str = start_date.replace('-', '')
            end_date_str = end_date.replace('-', '')
            
            # æŸ¥è¯¢æŒ‡å®šæœŸé—´çš„æ‰€æœ‰äº¤æ˜“æ—¥
            pipeline = [
                {
                    '$match': {
                        'trade_date': {
                            '$gte': start_date_str,
                            '$lte': end_date_str
                        }
                    }
                },
                {
                    '$group': {
                        '_id': '$trade_date'
                    }
                },
                {
                    '$sort': {'_id': 1}
                }
            ]
            
            cursor = collection.aggregate(pipeline)
            trading_dates = []
            
            for doc in cursor:
                date_str = doc['_id']
                formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
                trading_dates.append(formatted_date)
            
            self.logger.info(f"è·å–äº¤æ˜“æ—¥: {len(trading_dates)} å¤©")
            return trading_dates
            
        except Exception as e:
            self.logger.error(f"è·å–äº¤æ˜“æ—¥å¤±è´¥: {e}")
            # è¿”å›ç®€å•çš„å·¥ä½œæ—¥åˆ—è¡¨ä½œä¸ºå¤‡é€‰
            date_range = pd.date_range(start_date, end_date, freq='B')  # Bè¡¨ç¤ºå·¥ä½œæ—¥
            return [date.strftime('%Y%m%d') for date in date_range]
    
    def _select_stocks_by_strategy_score(self, stock_codes: List[str], start_date: str, 
                                       end_date: str, max_stocks: int, strategy_scorer) -> List[str]:
        """
        åŸºäºç­–ç•¥è¯„åˆ†é€‰æ‹©è‚¡ç¥¨
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_stocks: æœ€å¤§è‚¡ç¥¨æ•°é‡
            strategy_scorer: ç­–ç•¥è¯„åˆ†å‡½æ•°
            
        Returns:
            é€‰ä¸­çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        self.logger.info("æ­£åœ¨è®¡ç®—è‚¡ç¥¨ç­–ç•¥è¯„åˆ†...")
        stock_scores = []
        
        # è·å–è¯„åˆ†è®¡ç®—çš„å‚è€ƒæ—¥æœŸï¼ˆå¼€å§‹æ—¥æœŸå60å¤©ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ï¼‰
        from datetime import datetime, timedelta
        # ç»Ÿä¸€ä½¿ç”¨%Y%m%dæ ¼å¼
        start_date_fmt = start_date.replace('-', '') if '-' in start_date else start_date
        score_date = (datetime.strptime(start_date_fmt, '%Y%m%d') + timedelta(days=60)).strftime('%Y%m%d')
        
        # æ‰©å¤§æ•°æ®åŠ è½½èŒƒå›´ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿçš„æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        score_start_date = (datetime.strptime(start_date_fmt, '%Y%m%d') - timedelta(days=60)).strftime('%Y%m%d')
        
        # ä¸ºæ¯åªè‚¡ç¥¨è®¡ç®—è¯„åˆ†
        for i, stock_code in enumerate(stock_codes):
            try:
                # åŠ è½½è‚¡ç¥¨æ•°æ®ç”¨äºè¯„åˆ†ï¼ˆæ‰©å¤§èŒƒå›´ä»¥ç¡®ä¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æ­£ç¡®ï¼‰
                stock_data_df = self.load_stock_data(stock_code, score_start_date, score_date, include_indicators=True)
                
                if not stock_data_df.empty and len(stock_data_df) > 20:
                    # è·å–è¯„åˆ†æ—¥æœŸçš„æ•°æ®
                    score_date_data = self.get_stock_data_on_date(stock_code, score_date, {stock_code: stock_data_df})
                    
                    if score_date_data:
                        # è®¡ç®—ç­–ç•¥è¯„åˆ†
                        score = strategy_scorer(stock_code, score_date_data)
                        # è®°å½•æ‰€æœ‰è¯„åˆ†ï¼Œä¸ç®¡æ˜¯å¦æ»¡è¶³ä¹°å…¥æ¡ä»¶
                        stock_scores.append((stock_code, score))
                        if len(stock_scores) <= 10:  # è®°å½•å‰10ä¸ªè¯„åˆ†ç”¨äºè°ƒè¯•
                            self.logger.info(f"è‚¡ç¥¨ {stock_code} è¯„åˆ†: {score:.2f}")
                    else:
                        self.logger.debug(f"è‚¡ç¥¨ {stock_code} åœ¨ {score_date} æ— æ•°æ®")
                
                if (i + 1) % 50 == 0:
                    self.logger.info(f"è¯„åˆ†è¿›åº¦: {i+1}/{len(stock_codes)}")
                
            except Exception as e:
                self.logger.warning(f"è‚¡ç¥¨ {stock_code} è¯„åˆ†å¤±è´¥: {e}")
                import traceback
                self.logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
                continue
        
        # æŒ‰è¯„åˆ†æ’åºï¼Œé€‰æ‹©æœ€é«˜åˆ†çš„è‚¡ç¥¨
        stock_scores.sort(key=lambda x: x[1], reverse=True)
        selected_stocks = [stock_code for stock_code, score in stock_scores[:max_stocks]]
        
        self.logger.info(f"ç­–ç•¥è¯„åˆ†å®Œæˆï¼Œé€‰æ‹©äº† {len(selected_stocks)} åªæœ€ä¼˜è‚¡ç¥¨")
        if stock_scores:
            self.logger.info(f"æœ€é«˜è¯„åˆ†: {stock_scores[0][1]:.2f} ({stock_scores[0][0]})")
            if len(stock_scores) > 1:
                self.logger.info(f"æœ€ä½è¯„åˆ†: {stock_scores[-1][1]:.2f} ({stock_scores[-1][0]})")
        
        # å¦‚æœé€‰ä¸­çš„è‚¡ç¥¨å¤ªå°‘ï¼ˆå°‘äºç›®æ ‡çš„1/4ï¼‰ï¼Œå›é€€åˆ°åˆ†å±‚é‡‡æ ·
        if len(selected_stocks) < max_stocks // 4:
            self.logger.warning(f"ç­–ç•¥è¯„åˆ†ä»…é€‰ä¸­ {len(selected_stocks)} åªè‚¡ç¥¨ï¼Œå°‘äºç›®æ ‡çš„25%ï¼Œå›é€€åˆ°åˆ†å±‚é‡‡æ ·")
            return self._select_stocks_by_sampling(stock_codes, max_stocks)
        
        return selected_stocks
    
    def _select_stocks_by_sampling(self, stock_codes: List[str], max_stocks: int) -> List[str]:
        """
        åˆ†å±‚é‡‡æ ·é€‰æ‹©è‚¡ç¥¨ï¼Œç¡®ä¿ä¸åŒæ¿å—çš„ä»£è¡¨æ€§
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            max_stocks: æœ€å¤§è‚¡ç¥¨æ•°é‡
            
        Returns:
            é€‰ä¸­çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        if len(stock_codes) <= max_stocks:
            return stock_codes
        
        # æŒ‰å‰ç¼€åˆ†ç»„ï¼ˆ000=æ·±ä¸»æ¿, 001=æ·±ä¸»æ¿, 002=ä¸­å°æ¿, 003=åˆ›ä¸šæ¿, 600-603=æ²ªä¸»æ¿, 688=ç§‘åˆ›æ¿ç­‰ï¼‰
        stock_groups = {
            '000': [], '001': [], '002': [], '003': [], 
            '600': [], '601': [], '602': [], '603': [], '688': []
        }
        
        for stock_code in stock_codes:
            prefix = stock_code[:3]
            if prefix in stock_groups:
                stock_groups[prefix].append(stock_code)
            else:
                # å…¶ä»–å‰ç¼€å½’å…¥600ç»„
                stock_groups['600'].append(stock_code)
        
        # è®¡ç®—æ¯ç»„åº”é€‰æ‹©çš„æ•°é‡
        selected_stocks = []
        total_stocks = sum(len(stocks) for stocks in stock_groups.values() if stocks)
        
        for prefix, stocks in stock_groups.items():
            if not stocks:
                continue
                
            # æŒ‰æ¯”ä¾‹åˆ†é…ï¼Œç¡®ä¿æ¯ç»„è‡³å°‘æœ‰1åªè‚¡ç¥¨ï¼ˆå¦‚æœè¯¥ç»„æœ‰è‚¡ç¥¨çš„è¯ï¼‰
            group_quota = max(1, int(len(stocks) / total_stocks * max_stocks))
            group_quota = min(group_quota, len(stocks))
            
            # å‡åŒ€é‡‡æ ·
            step = len(stocks) // group_quota if group_quota > 0 else 1
            selected_from_group = [stocks[i * step] for i in range(group_quota)]
            selected_stocks.extend(selected_from_group)
            
            if len(selected_stocks) >= max_stocks:
                break
        
        # å¦‚æœè¿˜æ²¡è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œéšæœºè¡¥å……
        if len(selected_stocks) < max_stocks:
            remaining_stocks = [s for s in stock_codes if s not in selected_stocks]
            import random
            random.seed(42)  # å›ºå®šç§å­ä¿è¯å¯é‡å¤æ€§
            additional_stocks = random.sample(
                remaining_stocks, 
                min(max_stocks - len(selected_stocks), len(remaining_stocks))
            )
            selected_stocks.extend(additional_stocks)
        
        return selected_stocks[:max_stocks]
    
    def get_stock_data_on_date(self, 
                              stock_code: str, 
                              date: str, 
                              market_data: Dict[str, pd.DataFrame]) -> Optional[Dict]:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸ
            market_data: å¸‚åœºæ•°æ®
            
        Returns:
            è‚¡ç¥¨å½“æ—¥æ•°æ®å­—å…¸
        """
        if stock_code not in market_data:
            return None
        
        df = market_data[stock_code]
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        try:
            target_date = pd.to_datetime(date)
            
            # æŸ¥æ‰¾æœ€æ¥è¿‘çš„äº¤æ˜“æ—¥æ•°æ®
            if target_date in df.index:
                row = df.loc[target_date]
                data_dict = row.to_dict()
                            
                return data_dict
            else:
                # æ‰¾åˆ°æœ€è¿‘çš„äº¤æ˜“æ—¥
                valid_dates = df.index[df.index <= target_date]
                if len(valid_dates) > 0:
                    latest_date = valid_dates.max()
                    row = df.loc[latest_date]
                    return row.to_dict()
                else:
                    return None
                    
        except Exception as e:
            self.logger.error(f"è·å–è‚¡ç¥¨ {stock_code} åœ¨ {date} çš„æ•°æ®å¤±è´¥: {e}")
            return None
    
    def validate_data_quality(self, market_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """
        éªŒè¯æ•°æ®è´¨é‡
        
        Args:
            market_data: å¸‚åœºæ•°æ®
            
        Returns:
            æ•°æ®è´¨é‡æŠ¥å‘Š
        """
        report = {
            'total_stocks': len(market_data),
            'stock_details': {},
            'overall_quality': 'good'
        }
        
        issues = []
        
        for stock_code, df in market_data.items():
            stock_report = {
                'total_days': len(df),
                'missing_data_days': 0,
                'zero_volume_days': 0,
                'abnormal_price_days': 0,
                'quality_score': 100
            }
            
            # æ£€æŸ¥ç¼ºå¤±æ•°æ®
            missing_data = df[['open', 'high', 'low', 'close', 'volume']].isnull().any(axis=1).sum()
            stock_report['missing_data_days'] = missing_data
            
            # æ£€æŸ¥é›¶æˆäº¤é‡
            zero_volume = (df['volume'] == 0).sum()
            stock_report['zero_volume_days'] = zero_volume
            
            # æ£€æŸ¥å¼‚å¸¸ä»·æ ¼ï¼ˆå¦‚è´Ÿä»·æ ¼ï¼‰
            abnormal_price = ((df['open'] <= 0) | (df['high'] <= 0) | 
                            (df['low'] <= 0) | (df['close'] <= 0)).sum()
            stock_report['abnormal_price_days'] = abnormal_price
            
            # è®¡ç®—è´¨é‡å¾—åˆ†
            total_issues = missing_data + zero_volume + abnormal_price
            if len(df) > 0:
                quality_score = max(0, 100 - (total_issues / len(df)) * 100)
                stock_report['quality_score'] = quality_score
                
                if quality_score < 90:
                    issues.append(f"{stock_code}: è´¨é‡å¾—åˆ† {quality_score:.1f}")
            
            report['stock_details'][stock_code] = stock_report
        
        # æ•´ä½“è´¨é‡è¯„ä¼°
        avg_quality = np.mean([details['quality_score'] for details in report['stock_details'].values()])
        if avg_quality >= 95:
            report['overall_quality'] = 'excellent'
        elif avg_quality >= 90:
            report['overall_quality'] = 'good'
        elif avg_quality >= 80:
            report['overall_quality'] = 'fair'
        else:
            report['overall_quality'] = 'poor'
        
        report['avg_quality_score'] = avg_quality
        report['issues'] = issues
        
        return report
    
    def _merge_financial_data(self, result_df: pd.DataFrame, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """åˆå¹¶è´¢åŠ¡æ•°æ®åˆ°è‚¡ç¥¨æ•°æ®ä¸­ - ç”¨äºé€‰è‚¡è€Œéäº¤æ˜“ä¿¡å·"""
        try:
            # è·å–è´¢åŠ¡æ•°æ®é›†åˆ
            fina_collection = self.db_handler.get_collection(self.db_config.financial_indicator_collection)
            
            # æŸ¥è¯¢è´¢åŠ¡æ•°æ®ï¼ˆè·å–å†å²è´¢åŠ¡æ•°æ®ç”¨äºé€‰è‚¡ï¼‰
            from datetime import datetime, timedelta
            # ç»Ÿä¸€ä½¿ç”¨%Y%m%dæ ¼å¼
            start_date_fmt = start_date.replace('-', '') if '-' in start_date else start_date
            start_dt = datetime.strptime(start_date_fmt, '%Y%m%d')
            # å‘å‰æ‰©å±•1å¹´ä»¥è·å–è¶³å¤Ÿçš„è´¢åŠ¡æ•°æ®ç”¨äºé€‰è‚¡
            extended_start = start_dt - timedelta(days=365)
            
            extended_start_str = extended_start.strftime('%Y%m%d')
            
            # æŸ¥è¯¢é€»è¾‘ï¼šè·å–åœ¨å›æµ‹å¼€å§‹å‰å·²å…¬å‘Šçš„æ‰€æœ‰è´¢åŠ¡æ•°æ®
            query = {
                'ts_code': stock_code,
                'ann_date': {'$lt': start_date.replace('-', '')}  # åªè¦å›æµ‹å¼€å§‹å‰å·²å…¬å‘Šçš„æ•°æ®
            }
            
            # è°ƒè¯•è¾“å‡º
            if stock_code in ['000012.SZ', '002003.SZ']:
                print(f"ğŸ” {stock_code} è´¢åŠ¡æŸ¥è¯¢: {query}")
                # æŸ¥çœ‹æœ‰å¤šå°‘æ•°æ®
                count = fina_collection.count_documents(query)
                print(f"   åŒ¹é…è´¢åŠ¡è®°å½•æ•°: {count}")
                # æŸ¥çœ‹æ‰€æœ‰æ•°æ®çš„ann_dateèŒƒå›´
                all_query = {'ts_code': stock_code}
                sample = fina_collection.find(all_query, {'ann_date': 1, 'end_date': 1}).sort('ann_date', -1).limit(3)
                print(f"   æœ€æ–°3æ¡ann_date: {[doc for doc in sample]}")
            
            # è´¢åŠ¡æŒ‡æ ‡å­—æ®µæ˜ å°„ - åŸºäºæ•°æ®åº“å› å­ç»¼åˆæŠ¥å‘Šçš„å…¨é‡è´¢åŠ¡å­—æ®µ
            financial_fields = {
                # ==================== æ¯è‚¡æŒ‡æ ‡ ====================
                'eps': 'eps',                          # æ¯è‚¡æ”¶ç›Š
                'diluted2_eps': 'diluted2_eps',        # ç¨€é‡Šæ¯è‚¡æ”¶ç›Š
                'dt_eps': 'dt_eps',                    # æ‰£éæ¯è‚¡æ”¶ç›Š
                'bvps': 'bps',                         # æ¯è‚¡å‡€èµ„äº§
                'cfps': 'cfps',                        # æ¯è‚¡ç°é‡‘æµ
                'ocfps': 'ocfps',                      # æ¯è‚¡ç»è¥ç°é‡‘æµ
                'revenue_ps': 'revenue_ps',            # æ¯è‚¡è¥æ”¶
                'total_revenue_ps': 'total_revenue_ps', # æ¯è‚¡è¥ä¸šæ€»æ”¶å…¥
                'capital_rese_ps': 'capital_rese_ps',  # æ¯è‚¡èµ„æœ¬å…¬ç§¯
                'surplus_rese_ps': 'surplus_rese_ps',  # æ¯è‚¡ç›ˆä½™å…¬ç§¯
                'undist_profit_ps': 'undist_profit_ps', # æ¯è‚¡æœªåˆ†é…åˆ©æ¶¦
                'retainedps': 'retainedps',            # æ¯è‚¡ç•™å­˜æ”¶ç›Š
                
                # ==================== ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡ ====================
                'roe': 'roe',                          # å‡€èµ„äº§æ”¶ç›Šç‡
                'roe_waa': 'roe_waa',                  # åŠ æƒå¹³å‡å‡€èµ„äº§æ”¶ç›Šç‡
                'roe_dt': 'roe_dt',                    # æ‰£éå‡€èµ„äº§æ”¶ç›Šç‡
                'roe_avg': 'roe_avg',                  # å¹³å‡å‡€èµ„äº§æ”¶ç›Šç‡
                'roe_yearly': 'roe_yearly',            # å¹´åŒ–å‡€èµ„äº§æ”¶ç›Šç‡
                'roa_dp': 'roa_dp',                    # æ€»èµ„äº§æŠ¥é…¬ç‡
                'roa_yearly': 'roa_yearly',            # å¹´åŒ–æ€»èµ„äº§æ”¶ç›Šç‡
                'netprofit_margin': 'netprofit_margin', # é”€å”®å‡€åˆ©ç‡
                # æ³¨æ„: grossprofit_marginå­—æ®µåœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨ï¼Œå·²ç§»é™¤
                # 'grossprofit_margin': 'grossprofit_margin', # é”€å”®æ¯›åˆ©ç‡
                'profit_to_gr': 'profit_to_gr',        # å‡€åˆ©æ¶¦/è¥ä¸šæ€»æ”¶å…¥
                'profit_to_op': 'profit_to_op',        # å‡€åˆ©æ¶¦/è¥ä¸šåˆ©æ¶¦
                
                # ==================== è¥è¿èƒ½åŠ›æŒ‡æ ‡ ====================
                'assets_turn': 'assets_turn',          # èµ„äº§å‘¨è½¬ç‡
                'total_fa_trun': 'total_fa_trun',      # å›ºå®šèµ„äº§å‘¨è½¬ç‡
                
                # ==================== å¿å€ºèƒ½åŠ›æŒ‡æ ‡ ====================
                'debt_to_assets': 'debt_to_assets',    # èµ„äº§è´Ÿå€ºç‡
                'debt_to_eqt': 'debt_to_eqt',          # äº§æƒæ¯”ç‡
                'eqt_to_debt': 'eqt_to_debt',          # æƒç›Šä¹˜æ•°
                'assets_to_eqt': 'assets_to_eqt',      # èµ„äº§æƒç›Šæ¯”
                # æ³¨æ„: current_ratio, quick_ratioå­—æ®µåœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨ï¼Œå·²ç§»é™¤
                # 'current_ratio': 'current_ratio',    # æµåŠ¨æ¯”ç‡
                # 'quick_ratio': 'quick_ratio',        # é€ŸåŠ¨æ¯”ç‡
                'ocf_to_debt': 'ocf_to_debt',          # ç»è¥ç°é‡‘æµé‡å¯¹è´Ÿå€ºæ¯”ç‡
                'op_to_debt': 'op_to_debt',            # è¥ä¸šåˆ©æ¶¦å¯¹è´Ÿå€ºæ¯”ç‡
                
                # ==================== ç°é‡‘æµæŒ‡æ ‡ ====================
                'ocf_to_profit': 'ocf_to_profit',      # ç»è¥ç°é‡‘å‡€æµé‡å¯¹å‡€åˆ©æ¶¦æ¯”ç‡
                'ocf_to_opincome': 'ocf_to_opincome',  # ç»è¥ç°é‡‘å‡€æµé‡å¯¹è¥ä¸šæ”¶å…¥æ¯”ç‡
                'ocf_to_or': 'ocf_to_or',              # ç»è¥ç°é‡‘å‡€æµé‡è¥ä¸šæ”¶å…¥æ¯”
                
                # ==================== æˆé•¿èƒ½åŠ›æŒ‡æ ‡ ====================
                'revenue_yoy': 'or_yoy',               # è¥ä¸šæ”¶å…¥åŒæ¯”å¢é•¿ç‡
                'profit_yoy': 'netprofit_yoy',         # å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡
                'dt_netprofit_yoy': 'dt_netprofit_yoy', # æ‰£éå‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡
                'eps_yoy': 'basic_eps_yoy',            # æ¯è‚¡æ”¶ç›ŠåŒæ¯”å¢é•¿ç‡
                'dt_eps_yoy': 'dt_eps_yoy',            # æ‰£éæ¯è‚¡æ”¶ç›ŠåŒæ¯”å¢é•¿ç‡
                'bps_yoy': 'bps_yoy',                  # æ¯è‚¡å‡€èµ„äº§åŒæ¯”å¢é•¿ç‡
                'cfps_yoy': 'cfps_yoy',                # æ¯è‚¡ç»è¥ç°é‡‘æµåŒæ¯”å¢é•¿ç‡
                'roe_yoy': 'roe_yoy',                  # ROEåŒæ¯”å˜åŒ–
                'assets_yoy': 'assets_yoy',            # èµ„äº§åŒæ¯”å¢é•¿ç‡
                'equity_yoy': 'equity_yoy',            # è‚¡ä¸œæƒç›ŠåŒæ¯”å¢é•¿ç‡
                'ebt_yoy': 'ebt_yoy',                  # åˆ©æ¶¦æ€»é¢åŒæ¯”å¢é•¿ç‡
                'op_yoy': 'op_yoy',                    # è¥ä¸šåˆ©æ¶¦åŒæ¯”å¢é•¿ç‡
                'ocf_yoy': 'ocf_yoy',                  # ç»è¥ç°é‡‘æµåŒæ¯”å¢é•¿ç‡
                
                # ==================== å­£åº¦æŒ‡æ ‡ ====================
                'q_eps': 'q_eps',                      # å•å­£æ¯è‚¡æ”¶ç›Š
                'q_roe': 'q_roe',                      # å•å­£ROE
                'q_dt_roe': 'q_dt_roe',                # å•å­£æ‰£éROE
                'q_netprofit_margin': 'q_netprofit_margin', # å•å­£é”€å”®å‡€åˆ©ç‡
                'q_netprofit_yoy': 'q_netprofit_yoy',  # å•å­£å‡€åˆ©æ¶¦åŒæ¯”
                'q_netprofit_qoq': 'q_netprofit_qoq',  # å•å­£å‡€åˆ©æ¶¦ç¯æ¯”
                'q_profit_yoy': 'q_profit_yoy',        # å•å­£åˆ©æ¶¦åŒæ¯”
                'q_profit_qoq': 'q_profit_qoq',        # å•å­£åˆ©æ¶¦ç¯æ¯”
                'q_profit_to_gr': 'q_profit_to_gr',    # å•å­£å‡€åˆ©æ¶¦/è¥ä¸šæ€»æ”¶å…¥
                'q_dtprofit': 'q_dtprofit',            # å•å­£æ‰£éå‡€åˆ©æ¶¦
                'q_dtprofit_to_profit': 'q_dtprofit_to_profit', # å•å­£æ‰£éå‡€åˆ©æ¶¦/å‡€åˆ©æ¶¦
                'q_opincome': 'q_opincome',            # å•å­£è¥ä¸šæ”¶å…¥
                'q_investincome': 'q_investincome',    # å•å­£æŠ•èµ„æ”¶ç›Š
                'q_investincome_to_ebt': 'q_investincome_to_ebt', # å•å­£æŠ•èµ„æ”¶ç›Š/åˆ©æ¶¦æ€»é¢
                'q_opincome_to_ebt': 'q_opincome_to_ebt', # å•å­£è¥ä¸šæ”¶å…¥/åˆ©æ¶¦æ€»é¢
                
                # ==================== å…¶ä»–è´¢åŠ¡æŒ‡æ ‡ ====================
                'op_income': 'op_income',              # è¥ä¸šæ”¶å…¥
                'profit_dedt': 'profit_dedt',          # åˆ©æ¶¦æ€»é¢
                'retained_earnings': 'retained_earnings', # ç•™å­˜æ”¶ç›Š
                'fixed_assets': 'fixed_assets',        # å›ºå®šèµ„äº§
                'non_op_profit': 'non_op_profit',      # è¥ä¸šå¤–æ”¶æ”¯å‡€é¢
                'valuechange_income': 'valuechange_income', # å…¬å…ä»·å€¼å˜åŠ¨æ”¶ç›Š
                'investincome_of_ebt': 'investincome_of_ebt', # æŠ•èµ„æ”¶ç›Š/åˆ©æ¶¦æ€»é¢
                'opincome_of_ebt': 'opincome_of_ebt',  # è¥ä¸šæ”¶å…¥/åˆ©æ¶¦æ€»é¢
                'n_op_profit_of_ebt': 'n_op_profit_of_ebt', # è¥ä¸šå¤–æ”¶æ”¯å‡€é¢/åˆ©æ¶¦æ€»é¢
                'dtprofit_to_profit': 'dtprofit_to_profit', # æ‰£éå‡€åˆ©æ¶¦/å‡€åˆ©æ¶¦
                'nop_to_ebt': 'nop_to_ebt',            # è¥ä¸šå¤–æ”¶æ”¯å‡€é¢/åˆ©æ¶¦æ€»é¢
                'op_of_gr': 'op_of_gr',                # è¥ä¸šåˆ©æ¶¦/è¥ä¸šæ€»æ”¶å…¥
                'op_to_ebt': 'op_to_ebt',              # è¥ä¸šåˆ©æ¶¦/åˆ©æ¶¦æ€»é¢
                # æ³¨æ„: adminexp_of_grå­—æ®µåœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨ï¼Œæš‚æ—¶ç§»é™¤
                # 'adminexp_of_gr': 'adminexp_of_gr',  # ç®¡ç†è´¹ç”¨/è¥ä¸šæ€»æ”¶å…¥
                'extra_item': 'extra_item',            # éç»å¸¸æ€§æŸç›Š
                'npta': 'npta',                        # æ€»èµ„äº§å‡€åˆ©æ¶¦
                'dp_assets_to_eqt': 'dp_assets_to_eqt', # å¸¦æ¯è´Ÿå€º/å…¨éƒ¨æŠ•å…¥èµ„æœ¬
            }
            
            # æ„å»ºæŸ¥è¯¢å­—æ®µ
            projection = {'ts_code': 1, 'end_date': 1, 'ann_date': 1}
            for alias, field in financial_fields.items():
                projection[field] = 1
            
            cursor = fina_collection.find(query, projection).sort('end_date', -1).limit(1)
            financial_data = list(cursor)
            
            if not financial_data:
                self.logger.debug(f"è‚¡ç¥¨ {stock_code} æ— è´¢åŠ¡æ•°æ®ç”¨äºé€‰è‚¡")
                # å¦‚æœæ²¡æœ‰è´¢åŠ¡æ•°æ®ï¼Œæ·»åŠ ç©ºåˆ—
                for alias in financial_fields.keys():
                    result_df[alias] = np.nan
                return result_df
            
            # è·å–æœ€æ–°çš„è´¢åŠ¡æ•°æ®ï¼ˆç”¨äºæ•´ä¸ªå›æµ‹æœŸé—´çš„é€‰è‚¡ï¼‰
            latest_financial = financial_data[0]
            
            # å°†è´¢åŠ¡æ•°æ®å¡«å……åˆ°æ‰€æœ‰äº¤æ˜“æ—¥ï¼ˆå› ä¸ºåªç”¨äºé€‰è‚¡ï¼Œä¸éœ€è¦æ—¶é—´å˜åŒ–ï¼‰
            for alias, field in financial_fields.items():
                if field in latest_financial:
                    value = latest_financial[field]
                    if value is not None:
                        result_df[alias] = pd.to_numeric(value, errors='coerce')
                    else:
                        result_df[alias] = np.nan
                else:
                    result_df[alias] = np.nan
            
            self.logger.debug(f"è‚¡ç¥¨ {stock_code} è´¢åŠ¡æ•°æ®å·²åŠ è½½ï¼Œç”¨äºé€‰è‚¡")
            return result_df
            
        except Exception as e:
            self.logger.warning(f"åˆå¹¶è´¢åŠ¡æ•°æ®å¤±è´¥ {stock_code}: {e}")
            # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œæ·»åŠ ç©ºçš„è´¢åŠ¡æ•°æ®åˆ—
            financial_fields = ['eps', 'bps', 'roe', 'roa', 'debt_to_assets', 'revenue_ps', 
                              'netprofit_margin', 'assets_turn']  # ç§»é™¤ä¸å­˜åœ¨çš„å­—æ®µ
            for field in financial_fields:
                result_df[field] = np.nan
            return result_df
    
    def clear_cache(self):
        """æ¸…ç†æ•°æ®ç¼“å­˜"""
        self.data_cache.clear()
        self.logger.info("æ•°æ®ç¼“å­˜å·²æ¸…ç†")
    
    def load_index_data(self, index_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        åŠ è½½æŒ‡æ•°æ•°æ®
        
        Args:
            index_code: æŒ‡æ•°ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            æŒ‡æ•°æ•°æ®DataFrame
        """
        try:
            collection = self.db_handler.get_collection(self.db_config.index_daily_collection)
            
            query = {
                'ts_code': index_code,
                'trade_date': {
                    '$gte': start_date.replace('-', ''),
                    '$lte': end_date.replace('-', '')
                }
            }
            
            cursor = collection.find(query).sort('trade_date', 1)
            data = list(cursor)
            
            if not data:
                return pd.DataFrame()
            
            df = pd.DataFrame(data)
            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
            df.set_index('trade_date', inplace=True)
            
            # åº”ç”¨å­—æ®µæ˜ å°„
            field_mapping = self.db_config.field_mapping
            mapped_data = {}
            for target_field, source_field in field_mapping.items():
                if target_field.startswith('idx_') and source_field in df.columns:
                    mapped_data[target_field] = df[source_field]
            
            result_df = pd.DataFrame(mapped_data)
            return result_df
            
        except Exception as e:
            self.logger.error(f"åŠ è½½æŒ‡æ•° {index_code} æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def load_money_flow_data(self, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        åŠ è½½èµ„é‡‘æµå‘æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            èµ„é‡‘æµå‘æ•°æ®DataFrame
        """
        try:
            collection = self.db_handler.get_collection(self.db_config.money_flow_collection)
            
            query = {
                'ts_code': stock_code,
                'trade_date': {
                    '$gte': start_date.replace('-', ''),
                    '$lte': end_date.replace('-', '')
                }
            }
            
            cursor = collection.find(query).sort('trade_date', 1)
            data = list(cursor)
            
            if not data:
                return pd.DataFrame()
            
            df = pd.DataFrame(data)
            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
            df.set_index('trade_date', inplace=True)
            
            # åº”ç”¨å­—æ®µæ˜ å°„
            field_mapping = self.db_config.field_mapping
            mapped_data = {}
            money_flow_fields = [k for k in field_mapping.keys() if any(
                prefix in k for prefix in ['buy_', 'sell_', 'net_mf_']
            )]
            
            for target_field in money_flow_fields:
                source_field = field_mapping[target_field]
                if source_field in df.columns:
                    mapped_data[target_field] = df[source_field]
            
            result_df = pd.DataFrame(mapped_data)
            return result_df
            
        except Exception as e:
            self.logger.error(f"åŠ è½½è‚¡ç¥¨ {stock_code} èµ„é‡‘æµå‘æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def load_dividend_data(self, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        åŠ è½½åˆ†çº¢æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            åˆ†çº¢æ•°æ®DataFrame
        """
        try:
            collection = self.db_handler.get_collection(self.db_config.dividend_collection)
            
            query = {
                'ts_code': stock_code,
                'end_date': {
                    '$gte': start_date.replace('-', ''),
                    '$lte': end_date.replace('-', '')
                }
            }
            
            cursor = collection.find(query).sort('end_date', 1)
            data = list(cursor)
            
            if not data:
                return pd.DataFrame()
            
            df = pd.DataFrame(data)
            if 'end_date' in df.columns:
                df['end_date'] = pd.to_datetime(df['end_date'], format='%Y%m%d')
                df.set_index('end_date', inplace=True)
            
            # åº”ç”¨å­—æ®µæ˜ å°„
            field_mapping = self.db_config.field_mapping
            mapped_data = {}
            dividend_fields = [k for k in field_mapping.keys() if k.startswith('div_') or k in ['cash_div', 'stk_div']]
            
            for target_field in dividend_fields:
                source_field = field_mapping[target_field]
                if source_field in df.columns:
                    mapped_data[target_field] = df[source_field]
            
            result_df = pd.DataFrame(mapped_data)
            return result_df
            
        except Exception as e:
            self.logger.error(f"åŠ è½½è‚¡ç¥¨ {stock_code} åˆ†çº¢æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def load_margin_data(self, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        åŠ è½½èèµ„èåˆ¸æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            èèµ„èåˆ¸æ•°æ®DataFrame
        """
        try:
            collection = self.db_handler.get_collection(self.db_config.margin_detail_collection)
            
            query = {
                'ts_code': stock_code,
                'trade_date': {
                    '$gte': start_date.replace('-', ''),
                    '$lte': end_date.replace('-', '')
                }
            }
            
            cursor = collection.find(query).sort('trade_date', 1)
            data = list(cursor)
            
            if not data:
                return pd.DataFrame()
            
            df = pd.DataFrame(data)
            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
            df.set_index('trade_date', inplace=True)
            
            # åº”ç”¨å­—æ®µæ˜ å°„
            field_mapping = self.db_config.field_mapping
            mapped_data = {}
            margin_fields = ['rzye', 'rzmre', 'rzche', 'rqye', 'rqmcl', 'rqchl']
            
            for target_field in margin_fields:
                source_field = field_mapping.get(target_field, target_field)
                if source_field in df.columns:
                    mapped_data[target_field] = df[source_field]
            
            result_df = pd.DataFrame(mapped_data)
            return result_df
            
        except Exception as e:
            self.logger.error(f"åŠ è½½è‚¡ç¥¨ {stock_code} èèµ„èåˆ¸æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def load_trading_calendar(self, start_date: str, end_date: str, exchange: str = 'SSE') -> pd.DataFrame:
        """
        åŠ è½½äº¤æ˜“æ—¥å†æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            exchange: äº¤æ˜“æ‰€ä»£ç 
            
        Returns:
            äº¤æ˜“æ—¥å†DataFrame
        """
        try:
            collection = self.db_handler.get_collection(self.db_config.trading_calendar_collection)
            
            query = {
                'exchange': exchange,
                'cal_date': {
                    '$gte': start_date.replace('-', ''),
                    '$lte': end_date.replace('-', '')
                }
            }
            
            cursor = collection.find(query).sort('cal_date', 1)
            data = list(cursor)
            
            if not data:
                return pd.DataFrame()
            
            df = pd.DataFrame(data)
            df['cal_date'] = pd.to_datetime(df['cal_date'], format='%Y%m%d')
            df.set_index('cal_date', inplace=True)
            
            return df
            
        except Exception as e:
            self.logger.error(f"åŠ è½½äº¤æ˜“æ—¥å†æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
